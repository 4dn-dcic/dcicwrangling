{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29e1cd-dfd0-4acb-bb65-7db2461b2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GEO submission update (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aceeca6c-ecc6-4156-b74b-0ef4b98bdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.cleanup import get_workflow_details, delete_wfrs\n",
    "import time\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf65ed2-c0ab-404c-9991-d09785ae3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add key and blank GEO submission template\n",
    "\n",
    "my_auth = get_key('default', keyfile='~/keypairs.json')  #add_key\n",
    "GEO_metadata_template_file = '/Users/rahinavelkar/Library/CloudStorage/OneDrive-HarvardUniversity/harvard/geo_submission_v2/test/seq_template.xlsx' #https://www.ncbi.nlm.nih.gov/geo/info/seq.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3f76e3-8a17-4ea0-88c1-e921ad8249cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples 2\n"
     ]
    }
   ],
   "source": [
    "#Add datasets to be uploaded. All datasets should be from one publication or study and filter for one organism at a time.\n",
    "\n",
    "sets_list = [] \n",
    "\n",
    "search_url  = 'https://data.4dnucleome.org/browse/?dataset_label=sciRNA-seq+on+mixed+species+and+organs&experiments_in_set.biosample.biosource.organism.name=mouse&experiments_in_set.experiment_type.experiment_category=Sequencing&experimentset_type=replicate&lab.display_title=Xinxian+Deng%2C+UW&type=ExperimentSetReplicate'\n",
    "if sets_list:\n",
    "    esets = [ff_utils.get_metadata(i, my_auth) for i in sets_list]\n",
    "elif search_url:\n",
    "    esets = [i for i in ff_utils.search_metadata(search_url, my_auth)]\n",
    "    \n",
    "print(\"No. of samples {}\".format(len(esets))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de52e67-4c20-4090-be4c-d3a8819451d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No publication present, add manually\n"
     ]
    }
   ],
   "source": [
    "## Extracting STUDY SECTION \n",
    "user_input = []\n",
    "\n",
    "for eset in esets[0:1]:\n",
    "    if eset.get(\"produced_in_pub\") == None:\n",
    "        print(\"No publication present, add manually\")\n",
    "        has_pub = False\n",
    "        user_input.append(\"title\")\n",
    "        user_input.append(\"summary\")\n",
    "        user_input.append(\"author list\")\n",
    "    else:\n",
    "        has_pub = True\n",
    "        pub_details = eset.get(\"produced_in_pub\")\n",
    "        pub_title = pub_details.get(\"title\")\n",
    "        summary = pub_details.get(\"abstract\")\n",
    "        authors = pub_details.get(\"authors\")\n",
    "        full_name = []\n",
    "\n",
    "        for author in authors:\n",
    "            name = author.split(\" \")\n",
    "            surname = name[0]\n",
    "            if len(name) > 2:\n",
    "                firstname = name[-1]\n",
    "            else:\n",
    "                firstname = name[1]\n",
    "            author_name = firstname + \", \" + surname\n",
    "            full_name.append([author_name])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbaf2136-0307-4483-98f8-aaafa010ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists and dictionaries\n",
    "\n",
    "\n",
    "extracted_molecule = [\"polyA RNA\", \"total RNA\", \"nuclear RNA\", \"cytoplasmic RNA\" ,\"genomic DNA\",\"protein\",\"other\"]\n",
    "\n",
    "instrument_models = [\"454 GS\", \"454 GS 20\", \"454 GS FLX\", \"454 GS FLX+\", \"454 GS FLX Titanium\", \"454 GS Junior\", \"AB 5500 Genetic Analyzer\", \"AB 5500xl Genetic Analyzer\", \"AB 5500xl-W Genetic Analysis System\", \"AB SOLiD 3 Plus System\", \"AB SOLiD 4hq System\", \"AB SOLiD 4 System\", \"AB SOLiD PI System\", \"AB SOLiD System\", \"AB SOLiD System 2.0\", \"AB SOLiD System 3.0\", \"BGISEQ-500\", \"Complete Genomics\", \"DNBSEQ-G400\", \"DNBSEQ-G400 FAST\", \"DNBSEQ-G50\", \"DNBSEQ-T7\", \"Element AVITI\", \"FASTASeq 300\", \"GenoCare 1600\", \"GenoLab M\", \"GridION\", \"GS111\", \"Helicos HeliScope\", \"HiSeq X Five\", \"HiSeq X Ten\", \"Illumina Genome Analyzer\", \"Illumina Genome Analyzer II\", \"Illumina Genome Analyzer IIx\", \"Illumina HiScanSQ\", \"Illumina HiSeq 1000\", \"Illumina HiSeq 1500\", \"Illumina HiSeq 2000\", \"Illumina HiSeq 2500\", \"Illumina HiSeq 3000\", \"Illumina HiSeq 4000\", \"Illumina iSeq 100\", \"Illumina MiniSeq\", \"Illumina MiSeq\", \"Illumina NextSeq 500\", \"Illumina NovaSeq 6000\", \"Illumina NovaSeq X\", \"Illumina NovaSeq X Plus\", \"Ion GeneStudio S5\", \"Ion GeneStudio S5 plus\", \"Ion GeneStudio S5 prime\", \"Ion Torrent Genexus\", \"Ion Torrent PGM\", \"Ion Torrent Proton\", \"Ion Torrent S5\", \"Ion Torrent S5 XL\", \"MGISEQ-2000RS\", \"MinION\", \"NextSeq 1000\", \"NextSeq 2000\", \"NextSeq 550\", \"Onso\", \"PacBio RS\", \"PacBio RS II\", \"PromethION\", \"Revio\", \"Sentosa SQ301\", \"Sequel\", \"Sequel II\", \"Sequel IIe\", \"Tapestri\", \"UG 100\"]\n",
    "\n",
    "experiment_type = [\"16S rRNA-seq\", \"4C-Seq\", \"ATAC-seq\", \"BCR-Seq\", \"Bisulfite-Seq\", \"Bisulfite-Seq (reduced representation)\", \"BRU-Seq\", \"Capture-C\", \"ChEC-seq\", \"ChIA-PET\", \"ChIP-Seq\", \"ChIRP-seq\", \"CITE-seq\", \"CRISPR Screen\", \"CUT&Run\", \"CUT&Tag\", \"DamID-Seq\", \"DNase-Hypersensitivity\", \"EM-seq\", \"FAIRE-seq\", \"GRO-Seq\", \"Hi-C\", \"HiChIP\", \"iCLIP\", \"MBD-Seq\", \"MeDIP-Seq\", \"MeRIP-Seq\", \"miRNA-Seq\", \"MNase-Seq\", \"MRE-Seq\", \"ncRNA-Seq\", \"OTHER\", \"PRO-Seq\", \"Ribo-Seq\", \"RIP-Seq\", \"RNAmethylation\", \"RNA-Seq\", \"RNA-Seq (CAGE)\", \"RNA-Seq (RACE)\", \"scATAC-seq\", \"scRNA-seq\", \"SELEX\", \"smallRNA-Seq\", \"snRNA-Seq\", \"Spatial Transcriptomics\", \"ssRNA-Seq\", \"TCR-Seq\", \"Tn-Seq\"]\n",
    "\n",
    "organism_name_dic = {'C. jacchus': 'Callithrix jacchus',\n",
    " 'M. mulatta': 'Macaca mulatta',\n",
    " 'M. domestica': 'Monodelphis domestica',\n",
    " 'S. pyogenes': 'S. pyogenes',\n",
    " 'M. auratus': 'Mesocricetus auratus',\n",
    " 'D. rerio': 'Danio rerio',\n",
    " 'C. sabaeus': 'Chlorocebus sabaeus',\n",
    " 'G. gallus': 'Gallus gallus',\n",
    " 'C. elegans': 'Caenorhabditis elegans',\n",
    " 'D. melanogaster': 'Drosophila melanogaster',\n",
    " 'R. norvegicus': 'Rattus norvegicus',\n",
    " 'M. musculus': 'Mus musculus',\n",
    " 'H. sapiens': 'Homo sapiens'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4beca-bf19-4469-908e-a531c98a5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "##User input\n",
    "\n",
    "#add file type\n",
    "processed_files= [\"Gene-cell Expression Matrix\"]\n",
    "\n",
    "#Add which supplementary files\n",
    "supplementary_file_type = []\n",
    "\n",
    "#If you would like to add supplementary files from 4DN as processed files for GEO\n",
    "add_supp_as_proc = True\n",
    "\n",
    "molecule = \"genomic DNA\"  #add extracted molecule choices [\"polyA RNA\", \"total RNA\", \"nuclear RNA\", \"cytoplasmic RNA\", \"genomic DNA\", \"protein\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2089a4-e559-4e34-93e3-57b343f39920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Extracting SAMPLES details\n",
    "\n",
    "\n",
    "#Don't edit below\n",
    "portal_url = \"https://data.4dnucleome.org\"\n",
    "replicate_desc = {}\n",
    "replicate_desc_short = {}\n",
    "md5sums_raw = {}\n",
    "md5sums_proc = {}\n",
    "paired_raw_files = {}\n",
    "all_raw_files = {}\n",
    "all_proc_files = {}\n",
    "total_supplementary_files = []\n",
    "proc_file_description = {}\n",
    "\n",
    "dataset_labels = []\n",
    "conditions = []\n",
    "organisms = []\n",
    "all_tissues = []\n",
    "\n",
    "tissue_name = \"\"\n",
    "cell_line_name = \"\"\n",
    "cell_type = \"\"\n",
    "treatment = \"\"\n",
    "batch = \"\"\n",
    "\n",
    "samples_rows = []\n",
    "\n",
    "for eset in esets:\n",
    "    if add_supp_as_proc:\n",
    "                    total_supplementary_files = []\n",
    "    supplementary_files = eset.get(\"other_processed_files\")\n",
    "    for sup_file_info in supplementary_files:\n",
    "        s_files = sup_file_info.get(\"files\")\n",
    "        for sfile in s_files:\n",
    "            s_file_type = sfile.get(\"file_type\")\n",
    "            if s_file_type in supplementary_file_type:\n",
    "                sfile_acc = sfile.get(\"accession\")\n",
    "                sfile_name = sfile.get('display_title')\n",
    "                sfile_md5sum = sfile.get(\"md5sum\")\n",
    "                proc_file_description[s_file_type] = sfile_name.split(\".\", 1)[1]\n",
    "                total_supplementary_files.append(sfile_name)\n",
    "                if add_supp_as_proc:\n",
    "                    md5sums_proc[sfile_name] = sfile_md5sum\n",
    "    if eset.get(\"dataset_label\") not in dataset_labels:\n",
    "        dataset_label = eset.get(\"dataset_label\")\n",
    "        dataset_labels.append(dataset_label)\n",
    "    condition = eset.get(\"condition\")\n",
    "    genotype = condition\n",
    "    if genotype not in conditions:\n",
    "        conditions.append(genotype)\n",
    "    replicate_info = eset.get(\"replicate_exps\")\n",
    "    for reps in replicate_info:\n",
    "            biorep = reps.get(\"bio_rep_no\")     \n",
    "            techrep = reps.get(\"tec_rep_no\")\n",
    "            rep_description = \"Biological replicate \" +  str(biorep) + \", Technical replicate \" + str(techrep)\n",
    "            rep_description_short = \"B\" +  str(biorep) + \" T\" + str(techrep)\n",
    "            rep_info = reps.get(\"replicate_exp\")\n",
    "            rep_info_acc = rep_info.get(\"accession\")\n",
    "            replicate_desc[rep_info_acc] = rep_description\n",
    "            replicate_desc_short[rep_info_acc] = rep_description_short\n",
    "    exps = eset.get('experiments_in_set')\n",
    "    for exp in exps:\n",
    "        raw_files_per_exp = []\n",
    "        proc_files_per_exp = []\n",
    "        exp_id = exp.get(\"@id\")\n",
    "        exp_url = portal_url + exp_id\n",
    "        exp_acc = exp.get(\"accession\")\n",
    "        library_name = exp.get(\"display_title\")\n",
    "        exp_details = exp.get(\"experiment_type\")\n",
    "        library_strategy = exp_details.get('display_title')\n",
    "        files = exp.get(\"files\")\n",
    "        for file in files:\n",
    "            file_acc = file.get(\"accession\")\n",
    "            file_type = file.get(\"file_type\")\n",
    "            file_name = file.get(\"display_title\")\n",
    "            if file_type == \"reads\":\n",
    "                raw_files_per_exp.append(file.get('display_title'))\n",
    "                file_metadata = ff_utils.get_metadata(file_acc, my_auth)\n",
    "                instrument = file_metadata.get('instrument')\n",
    "                md5sum = file_metadata.get('md5sum')\n",
    "                md5sums_raw[file_name] = md5sum\n",
    "                if file.get(\"paired_end\"):\n",
    "                    paired = \"paired-end\"\n",
    "                    related_files = file.get(\"related_files\")\n",
    "                    for rf in related_files:\n",
    "                        if rf.get(\"relationship_type\") == \"paired with\":\n",
    "                            paired_acc = rf.get(\"accession\")\n",
    "                            paired_raw_files[file_acc] = paired_acc\n",
    "                else:\n",
    "                    paired = \"single\"\n",
    "        if exp.get(\"processed_files\"):\n",
    "            proc_files = exp.get(\"processed_files\")\n",
    "            for pfile in proc_files:\n",
    "                file_acc = pfile.get(\"accession\")\n",
    "                file_type = pfile.get(\"file_type\")\n",
    "                file_name = pfile.get(\"display_title\")\n",
    "                if file_type in processed_files:\n",
    "                    proc_files_per_exp.append(file_name)\n",
    "                    pfile_metadata = ff_utils.get_metadata(file_acc, my_auth)\n",
    "                    pmd5sum = pfile_metadata.get('md5sum')\n",
    "                    md5sums_proc[file_name] = pmd5sum\n",
    "        else:    \n",
    "            proc_files_per_exp.append('')\n",
    "        biosample = exp.get(\"biosample\")\n",
    "        biosample_id = biosample.get(\"@id\")\n",
    "        biosample_url = portal_url + biosample_id\n",
    "        biosample_type = biosample.get(\"biosample_type\")\n",
    "        biosources = biosample.get(\"biosource\")\n",
    "        for biosource in biosources:\n",
    "            organism = biosource.get(\"organism\")\n",
    "            organism_name = organism.get(\"display_title\")\n",
    "            organism_uuid = organism.get(\"uuid\")\n",
    "            organism_metadata = ff_utils.get_metadata(organism_uuid, my_auth)\n",
    "            if organism_metadata.get(\"genome_assembly\"):\n",
    "                 organism_genome_assembly = organism_metadata.get(\"genome_assembly\")\n",
    "            else:\n",
    "                 user_input.append(\"organism_genome_assembly\")\n",
    "            if organism_name not in organisms:\n",
    "                organisms.append(organism_name)\n",
    "            biosource_type = biosource.get(\"biosource_type\")\n",
    "            if biosource_type == \"tissue\":\n",
    "                tissue = biosource.get('tissue')\n",
    "                tissue_name = tissue.get('term_name')\n",
    "                all_tissues.append(tissue_name)\n",
    "                bname = tissue_name\n",
    "            else:\n",
    "                cell_type = biosource_type\n",
    "                cell_line = biosource.get(\"cell_line\")\n",
    "                cell_line_name = cell_line.get(\"term_name\")\n",
    "                bname = cell_line_name\n",
    "        proc_files_desc_exp = []\n",
    "        for file_type, ext in proc_file_description.items():\n",
    "            description = '{} ({})'.format(file_type, ext)\n",
    "            proc_files_desc_exp.append(description)\n",
    "        processed_data_files_format_content_per_exp  = ', '.join(proc_files_desc_exp)        \n",
    "        title =  exp_acc + \", \" + organism_name + \" - \" + bname + \", \" +condition + \", \" + replicate_desc_short[exp_acc]\n",
    "        description = library_strategy + \" in \" + bname + \" (\" + organism_name + \")\" +\", \" + condition + \", \" + replicate_desc[exp_acc] + \", 4DN experiment: \" + exp_url + \", 4DN Biosample: \" + biosample_url + ', Results include ' + processed_data_files_format_content_per_exp\n",
    "        samples_rows.append([exp_acc,title,library_strategy,organism_name_dic[organism_name],tissue_name,cell_line_name, cell_type, genotype, treatment, batch, molecule, paired,instrument,description])\n",
    "        all_raw_files[exp_acc] = raw_files_per_exp\n",
    "        if add_supp_as_proc:\n",
    "            all_proc_files[exp_acc] = total_supplementary_files\n",
    "        else:    \n",
    "            all_proc_files[exp_acc] = proc_files_per_exp\n",
    "\n",
    "#Add experimental design        \n",
    "genotypes = ', '.join(conditions)\n",
    "experiment_design = 'Total {} samples generated using {} in {} on {}'.format(len(samples_rows),library_strategy,organism_name, genotypes)\n",
    "\n",
    "#Add processed data files format and content\n",
    "proc_descriptions = []\n",
    "for file_type, ext in proc_file_description.items():\n",
    "    desc = ext + \":\" + file_type\n",
    "    proc_descriptions.append(desc)\n",
    "processed_data_files_format_content  = ', '.join(proc_descriptions)\n",
    "\n",
    "#Warnings                                         \n",
    "if len(all_proc_files) == 0:\n",
    "    print(\"No processed files for any samples - cannot submit to GEO\")\n",
    "if len(organisms) > 1:\n",
    "    print(\"Samples for more than one organisms added, please filter the search query for one organism.\")\n",
    "                                         \n",
    "                                         \n",
    "print(\"done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218636cf-a4ee-4744-8328-3ee637dde560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnaullay add missing data\n",
    "\n",
    "missing = ', '.join(user_input)\n",
    "if len(missing) > 0:\n",
    "    print(\"Add the following manually: {}\".format(missing))\n",
    "\n",
    "if 'organism_genome_assembly' not in user_input:\n",
    "    print(\"Genome assembly added {}\".format(organism_genome_assembly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad03dc-be9a-47cd-90fa-1768fbebf93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_genome_assembly = False\n",
    "\n",
    "if has_pub == False:\n",
    "    pub_title = \"Cross-species imputation and comparison of single-cell transcriptomic profiles\"\n",
    "    summary = \"Cross-species comparison and prediction of gene expression profiles are important to understand regulatory changes during evolution and to transfer knowledge learned from model organisms to humans. Single-cell RNA-seq (scRNA-seq) profiles enable us to capture gene expression profiles with respect to variations among indi- vidual cells; however, cross-species comparison of scRNA-seq profiles is challenging because of data sparsity, batch effects, and the lack of one-to-one cell matching across species. Moreover, single-cell profiles are challenging to obtain in certain biological contexts, limiting the scope of hypothesis generation. Here we developed Icebear, a neural network framework that decomposes single-cell measurements into factors representing cell identity, species, and batch factors. Icebear enables accurate prediction of single-cell gene expression profiles across species, thereby pro- viding high-resolution cell type and disease profiles in under-characterized contexts. Icebear also facilitates direct cross-species comparison of single-cell expression profiles for conserved genes that are located on the X chromosome in eutherian mammals but on autosomes in chicken. This comparison, for the first time, revealed evolutionary and diverse adaptations of X-chromosome upregulation in mammals\"\n",
    "    full_name = [[\"Ran, Zhang\"] ,[\"Mu, Yang\"], [\"Jacob, Schreiber\"], [\"Diana, Oâ€™Day\"], [\"James, Turner\"], [\"Jay, Shendure\"], [\"William, Noble\"], [\"Christine, Disteche\"], [\"Xinxian, Deng\"]]\n",
    "\n",
    "if override_genome_assembly:\n",
    "    organism_genome_assembly = \"ASM229v1\"\n",
    "    \n",
    "extract_protocol = \"H1, HCT116, and HFF cells were cultured according to standard operation protocols established by the NIH 4D Nucleome Consortium (https://www.4dnucleome.org/cell-lines.html). K562 cells were cultured according to the ENCODE Consortium protocol (http://genome.ucsc.edu/ENCODE/protocols/cell/human/K562_protocol.pdf).\"\n",
    "library_construction_protocol = \"SON and MKI67IP TSA-Seq was performed using Condition E (labeling with 1:300 tyramide biotin, 50% sucrose and 0.0015% hydrogen peroxide) (Zhang et al., 2020) with the following minor modification: 150ul of Dynabeads M-270 streptavidin (Invitrogen, catalog no. 65306) was used to purify the biotinylated DNA. For LMNB1 TSA-Seq, Condition A2 (Zhang et al., 2020) (labeling with 1:10000 tyramide biotin, 50% sucrose, 0.0015% hydrogen peroxide and reaction time 20 min at RT) was used.\"\n",
    "data_processing_step = \"For detecting SON TSA-seq Type I and Type II peaks, the SON TSA-seq score (25 kb bins) first was smoothed using locally weighted regression (LOESS). Next, a local maximum filter with window size (w) was applied, which recorded the maximum SON TSA-seq score within this window for each genomic locus. Then the data after the maximum filter were subtracted from the original smoothed data. Peaks were retained only if they showed a reduction in value, which indicates true local peaks. A parameter optimization procedure was conducted in order to maximize the peak agreement between two SON TSA-seq replicates. As a result, a smoothing factor (span=0.005) and a window size (w=50) were selected. To distinguish local peaks into Type I and Type II, we overlapped them with Hi-C subcompartments (Rao et. al, 2014). Genomic loci overlapping A1 subcompartments were classified as Type I peaks, while those overlapping A2/B1 were designated as Type II peaks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e83d-f6f8-4fb1-a09d-1aadce202b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate STUDY, SAMPLES and PROTOCOLS section in template file\n",
    "\n",
    "workbook = openpyxl.load_workbook(GEO_metadata_template_file)\n",
    "sheet = workbook['Metadata']\n",
    "\n",
    "#STUDY section\n",
    "\n",
    "start_row = 39\n",
    "sheet[\"B12\"] = pub_title\n",
    "sheet[\"B13\"] = summary\n",
    "sheet[\"B14\"] = experiment_design\n",
    "\n",
    "#author names\n",
    "if len(full_name) > 7:\n",
    "    sheet.insert_rows(22, amount=len(full_name)-6)\n",
    "    start_row = 39 + len(full_name) - 6\n",
    "\n",
    "    for row in range(22, 22+(len(full_name)-6)):\n",
    "        sheet[f\"A{row}\"] = 'contributor'\n",
    "\n",
    "for i, row_data in enumerate(full_name, start=15):\n",
    "    for j, value in enumerate(row_data, start=2):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "        \n",
    "\n",
    "#SAMPLES section\n",
    "\n",
    "if len(samples_rows) > 16:\n",
    "    add_no_rows = len(samples_rows) - 16    \n",
    "    sheet.insert_rows(start_row + 16, add_no_rows + 1)\n",
    "                \n",
    "for i, row_data in enumerate(samples_rows, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=1):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "\n",
    "# SAMPLES section - files metadata        \n",
    "edit_file_headers = False\n",
    "\n",
    "no_of_raw_files = []\n",
    "no_of_processed_files = []\n",
    "raw_files = []\n",
    "proc_files = []\n",
    "        \n",
    "for key, value in all_proc_files.items():\n",
    "    no_of_processed_files.append(len(value))\n",
    "    proc_files.append(value)\n",
    "    \n",
    "for key, value in all_raw_files.items():\n",
    "    no_of_raw_files.append(len(value))\n",
    "    raw_files.append(value)    \n",
    "    \n",
    "max_raw = max(no_of_raw_files)\n",
    "max_proc = max(no_of_processed_files)\n",
    "\n",
    "if max_proc > 2 or max_raw > 5:\n",
    "    print(\"Updating column headers for files\")\n",
    "    edit_file_headers = True\n",
    "\n",
    "if edit_file_headers:\n",
    "    file_headers =  []\n",
    "    for i in range(max_proc):\n",
    "        file_headers.append('processed data file')\n",
    "    file_headers.append('*raw file')    \n",
    "    for i in range(max_raw-1):\n",
    "        file_headers.append('raw file')  \n",
    "\n",
    "    start_row_files = start_row - 1\n",
    "    for col_num, value in enumerate(file_headers, start=15):\n",
    "        sheet.cell(row=start_row_files, column=col_num, value=value)\n",
    "        \n",
    "    start_row_files = start_row\n",
    "    start_column_proc = 15\n",
    "    \n",
    "    for i, row_data in enumerate(proc_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "    \n",
    "    for i, row_data in enumerate(raw_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc + max_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)   \n",
    "\n",
    "else:\n",
    "    start_row_files = start_row\n",
    "    start_column_proc = 15\n",
    "    \n",
    "    for i, row_data in enumerate(proc_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "    \n",
    "    for i, row_data in enumerate(raw_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc + 2):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "            \n",
    "            \n",
    "#Populate protocol section                \n",
    "for row in sheet.iter_rows():\n",
    "    for cell in row:\n",
    "        if cell.value == \"*extract protocol\":\n",
    "            sheet[f\"B{cell.row}\"] = extract_protocol\n",
    "        if cell.value == \"*library construction protocol\":\n",
    "            sheet[f\"B{cell.row}\"] = library_construction_protocol\n",
    "        if cell.value == \"*data processing step\":\n",
    "            sheet[f\"B{cell.row}\"] = data_processing_step\n",
    "        if cell.value == \"*genome build/assembly\":\n",
    "            sheet[f\"B{cell.row}\"] = organism_genome_assembly\n",
    "        if cell.value == \"*processed data files format and content\":\n",
    "            sheet[f\"B{cell.row}\"] = processed_data_files_format_content\n",
    "            \n",
    "#Populate Paired-end experiment    \n",
    "if len(paired_raw_files) > 0:\n",
    "    for row in sheet.iter_rows():\n",
    "        for cell in row:\n",
    "            if cell.value == \"file name 1\":\n",
    "                paired_files_start_row = cell.row\n",
    "    \n",
    "    paired_per_exp = []\n",
    "    for r1, r2 in paired_raw_files.items():\n",
    "        paired_per_exp.append([r1, r2])\n",
    "\n",
    "    for i, row_data in enumerate(paired_per_exp, start=paired_files_start_row+1):\n",
    "        for j, value in enumerate(row_data, start=1):\n",
    "            sheet.cell(row=i, column=j, value=value)                        \n",
    "workbook.save(GEO_metadata_template_file)  \n",
    "\n",
    "print(\"Metadata sheet updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394cef3-2a2e-48cb-a5f9-44d269faf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate MD5 Checksums sheet.\n",
    "\n",
    "add_md5sum_raw = []\n",
    "add_md5sum_proc = []\n",
    "\n",
    "for filename, md5sum in md5sums_raw.items():\n",
    "    add_md5sum_raw.append([filename,md5sum ])\n",
    "\n",
    "add_md5sum_proc = []\n",
    "\n",
    "for filename, md5sum in md5sums_proc.items():\n",
    "    add_md5sum_proc.append([filename,md5sum ])\n",
    "\n",
    "\n",
    "workbook = openpyxl.load_workbook(GEO_metadata_template_file)\n",
    "sheet = workbook['MD5 Checksums']\n",
    "\n",
    "start_row = 9\n",
    "for i, row_data in enumerate(add_md5sum_raw, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=1):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "        \n",
    "for i, row_data in enumerate(add_md5sum_proc, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=6):\n",
    "        sheet.cell(row=i, column=j, value=value)        \n",
    "        \n",
    "workbook.save(GEO_metadata_template_file)\n",
    "\n",
    "print(\"MD5sum sheet updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8341b-6267-4d1e-a28c-94d39bdf95fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
