{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digest data sets to simplified json objects for GEO submission\n",
    "\n",
    "This notebook exports ExperimentSets and related Experiments and Biosamples as json files, compatible with GEO submission. Important metadata from other item types is recorded in the relevant file (e.g. Biosource info is condensed in the exported Biosample json).\n",
    "\n",
    "* Part 0. Initialize all functions.\n",
    "* Part 1. List all sets to export. **IMPORTANT**: make sure that the sets do not have **restricted files** (e.g. from HeLa cells).\n",
    "* Part 2. Generate simplified dictionaries for each ExpSet, Experiment and Biosample.\n",
    "* Part 3. Save dictionaries as json files.\n",
    "* Part 4. Patch items with date of export for external submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import get_key\n",
    "from functions.geo_minimization import *\n",
    "\n",
    "my_auth = get_key('andrea_data')\n",
    "DB = 'GEO'\n",
    "FORMATS = ['fastq', 'mcool', 'pairs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use_static_section = ff_utils.get_metadata(\"621e8359-3885-40ce-965d-91894aa7b758\", key=my_auth)\n",
    "data_use_guidelines = data_use_static_section['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files (get from store)\n",
    "def boildown_files(files_list):\n",
    "    '''Takes list of raw files and produces list of runs.\n",
    "    Each run is a pair of files (if paired end) or a single file (if single end).'''\n",
    "    files = [boildown_file(store[f['@id']]) for f in files_list]\n",
    "    runs = []\n",
    "    for a_file in files:\n",
    "        if a_file.get('paired_end') is None:\n",
    "            runs.append([a_file])\n",
    "        elif a_file.get('paired_end') == '1':\n",
    "            pe1 = a_file\n",
    "            for another_file in files:\n",
    "                if another_file['accession'] == a_file['related_files']:\n",
    "                    pe2 = another_file\n",
    "                    break\n",
    "            runs.append([pe1, pe2])\n",
    "    return runs\n",
    "\n",
    "\n",
    "def boildown_processed_files(processed_files_list):\n",
    "    '''Specific for HiC pipeline'''\n",
    "    output_list = []\n",
    "    for pf in processed_files_list:\n",
    "        if pf['file_format']['display_title'] in FORMATS:\n",
    "            file = store[pf['@id']]\n",
    "            file_dict = boildown_file(file)\n",
    "            file_dict['data_processing'] = 'https://data.4dnucleome.org/resources/data-analysis/hi_c-processing-pipeline'\n",
    "            output_list.append(file_dict)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Set\n",
    "expset_simple_values = [\n",
    "    'accession', 'description', 'dataset_label',\n",
    "    'condition', 'public_release', 'number_of_experiments'\n",
    "]\n",
    "\n",
    "expset_function_dispatch = {\n",
    "    '@id': boildown_at_id,\n",
    "    'lab': boildown_title,\n",
    "    'contributing_labs': boildown_list_to_titles,\n",
    "    'submitted_by': boildown_title,\n",
    "    'award': boildown_award,\n",
    "#     'last_modified': boildown_date_modified,\n",
    "    'experiments_in_set': boildown_experiments_in_set,\n",
    "#     'documents': boildown_protocols,  # get_metadata for each protocol\n",
    "    'replicate_exps': boildown_replicate_exps,\n",
    "    'processed_files': boildown_processed_files,\n",
    "    'external_references': boildown_external_references,  # use instead of dbxrefs because it is validated\n",
    "    'produced_in_pub': boildown_publication,  # returns also !Series_citation\n",
    "}\n",
    "\n",
    "\n",
    "def simplify_expset(expset_object):\n",
    "    ''' Keys are explicitly declared. Keys not present are ignored.'''\n",
    "    expset_dict = {}\n",
    "    for key, value in expset_object.items():\n",
    "        if key in expset_simple_values:\n",
    "            add_value_to_output_dict(key, value, expset_dict)\n",
    "        elif key in expset_function_dispatch:\n",
    "            result = expset_function_dispatch[key](value)\n",
    "            add_value_to_output_dict(key, result, expset_dict)\n",
    "    if not expset_dict.get('produced_in_pub'):\n",
    "        expset_dict['data_use_guidelines'] = data_use_guidelines\n",
    "    return expset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocols\n",
    "def boildown_experimental_protocol(experiment_object):\n",
    "    ''' Return experimental_protocol (list), by combining protocol and protocol_variations'''\n",
    "    protocols = []\n",
    "    if experiment_object.get('protocol'):\n",
    "        protocol = store[experiment_object['protocol']['@id']]\n",
    "        protocols.append(protocol)\n",
    "    if experiment_object.get('protocol_variations'):\n",
    "        protocol_variations = [p['@id'] for p in store[experiment_object['protocol_variations']]]\n",
    "        protocols.extend(protocol_variations)\n",
    "    protocols_list = boildown_protocols(protocols)\n",
    "    return {'experimental_protocol': protocols_list}\n",
    "\n",
    "\n",
    "def boildown_cell_culture_details(biosample_object):\n",
    "    ''' Return cell_culture_protocols (list), by combining SOP_cell_culture from Biosource, and\n",
    "    'protocols_additional' and 'authentication_protocols' from BCC\n",
    "    '''\n",
    "    protocols = []\n",
    "    biosources = biosample_object['biosource']\n",
    "    for bsr in biosources:\n",
    "        biosource = store[bsr['@id']]\n",
    "        if biosource.get('SOP_cell_line'):\n",
    "            protocol = biosource['SOP_cell_line']\n",
    "            protocols.append(protocol)\n",
    "    cell_culture_details = biosample_object.get('cell_culture_details', [])\n",
    "    for bs_cc in cell_culture_details:\n",
    "        protocols_add = [store[protocol['@id']] for protocol in bs_cc.get('protocols_additional', [])] \n",
    "        protocols.extend(protocols_add)\n",
    "#         protocols_auth = [store[protocol['@id']] for protocol in bs_cc.get('authentication_protocols', [])] \n",
    "#         protocols.extend(protocols_auth)\n",
    "    protocols_list = boildown_protocols(protocols)\n",
    "    return {'cell_culture_protocols': protocols_list}\n",
    "\n",
    "\n",
    "def boildown_biosample_protocols(biosample_object):\n",
    "    ''' Get each protocol object from store'''\n",
    "    protocols = [store[protocol['@id']] for protocol in biosample_object.get('biosample_protocols', [])]\n",
    "    protocols_list = boildown_protocols(protocols)\n",
    "    return protocols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment #### specific for ExperimentHiC\n",
    "experiment_simple_values = [\n",
    "    'accession', 'description', 'public_release', 'experiment_summary',\n",
    "    'digestion_temperature', 'digestion_time', 'ligation_temperature',\n",
    "    'ligation_time', 'ligation_volume', 'tagging_method', 'average_fragment_size',\n",
    "    'biotin_removed', 'crosslinking_method', 'crosslinking_temperature',\n",
    "    'crosslinking_time', 'enzyme_lot_number', 'fragment_size_range',\n",
    "    'fragment_size_selection_method', 'fragmentation_method',\n",
    "    'library_prep_kit', 'pcr_cycles',\n",
    "]\n",
    "\n",
    "experiment_function_dispatch = {\n",
    "    '@id': boildown_at_id,\n",
    "    'lab': boildown_title,\n",
    "    'contributing_labs': boildown_list_to_titles,\n",
    "    'submitted_by': boildown_title,\n",
    "    'award': boildown_award,\n",
    "    'display_title': boildown_exp_display_title,\n",
    "#     'last_modified': boildown_date_modified,\n",
    "    'experiment_type': boildown_title,\n",
    "    'experiment_categorizer': boildown_exp_categorizer,  # 'combined' key (enzyme or target) + value\n",
    "    'biosample': boildown_title, # boildown_biosample,\n",
    "    'biosample_quantity': boildown_biosample_quantity,  # includes units\n",
    "    'digestion_enzyme': boildown_title,\n",
    "    'protocol': boildown_experimental_protocol,  # includes protocol_variation # !Sample_extract_protocol,\n",
    "    'protocol_variation': boildown_experimental_protocol,  # includes protocol # !Sample_extract_protocol,\n",
    "#     'documents': boildown_protocols,  # get_metadata for each protocol\n",
    "#     'external_references': boildown_external_references,\n",
    "    'files': boildown_files,  # get_metadata for each file\n",
    "    'processed_files': boildown_processed_files,\n",
    "}\n",
    "\n",
    "def simplify_experiment(experiment_object):\n",
    "    ''' Keys are explicitly declared. Keys not present are ignored.'''\n",
    "    experiment_dict = {}\n",
    "    for key, value in experiment_object.items():\n",
    "        if key in experiment_simple_values:\n",
    "            add_value_to_output_dict(key, value, experiment_dict)\n",
    "        elif key in ['biosample_quantity', 'protocol']:  # pass the entire object\n",
    "            result = experiment_function_dispatch[key](experiment_object)\n",
    "            add_value_to_output_dict(key, result, experiment_dict)\n",
    "        elif key in experiment_function_dispatch:  # pass only the value\n",
    "            result = experiment_function_dispatch[key](value)\n",
    "            add_value_to_output_dict(key, result, experiment_dict)\n",
    "    return experiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_interesting_values = [\n",
    "    'age', 'age_units', 'sex', 'life_stage', 'mouse_life_stage',\n",
    "    'mouse_strain', 'ethnicity', 'health_status',\n",
    "]\n",
    "\n",
    "def boildown_individual(biosample_object):\n",
    "    '''GET metadata from individual id and return all keys in interesting values'''\n",
    "    individual_dict = {}\n",
    "    individual = store[biosample_object['biosource'][0]['individual']['@id']]\n",
    "    for key, value in individual.items():\n",
    "        if key in individual_interesting_values:\n",
    "            individual_dict[key] = value\n",
    "        elif key == 'organism':\n",
    "            organism_object = store[individual['organism']['@id']]\n",
    "            result = boildown_organism(organism_object)\n",
    "            add_value_to_output_dict(key, result, individual_dict)\n",
    "    return individual_dict\n",
    "\n",
    "\n",
    "biosource_function_dispatch = {\n",
    "    'biosource_vendor': boildown_title,\n",
    "    'cell_line': boildown_title,\n",
    "    'individual': boildown_individual,\n",
    "    'SOP_cell_line': boildown_cell_culture_details,  # also retrieved from Biosample if cell_culture_details exists\n",
    "}\n",
    "\n",
    "def minimize_biosource(biosample_object):\n",
    "    ''' Biosources list is obtained from biosample.\n",
    "    Often (always?) there is just one Biosource. Return list of accessions otherwise.\n",
    "    Most of the interesting values are embedded fields, apart from SOP_cell_line\n",
    "    which requires to get_metadata.'''\n",
    "    biosources_list = biosample_object['biosource']\n",
    "    if len(biosources_list) > 1:\n",
    "        return ', '.join([bsr['accession'] for bsr in biosources_list])\n",
    "    # most cases have only 1 biosource\n",
    "    biosource = biosources_list[0]\n",
    "    biosource_dict = {}\n",
    "    for key, value in biosource.items():\n",
    "        if key in ['individual', 'SOP_cell_line']:\n",
    "            result = biosource_function_dispatch[key](biosample_object)\n",
    "        elif key in biosource_function_dispatch:\n",
    "            result = biosource_function_dispatch[key](value)\n",
    "        add_value_to_output_dict(key, result, biosource_dict)\n",
    "    return biosource_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_simple_values = [\n",
    "    'accession', 'biosource_summary', 'biosample_type', 'description',\n",
    "    'modifications_summary', 'treatments_summary',\n",
    "]\n",
    "\n",
    "biosample_function_dispatch = {\n",
    "    '@id': boildown_at_id,\n",
    "    'tissue_organ_info': boildown_tissue_organ_info,  # OK also with multiple biosources\n",
    "    'biosource': minimize_biosource,\n",
    "    'biosample_protocols': boildown_biosample_protocols,\n",
    "    'cell_culture_details': boildown_cell_culture_details,  # returns cell_culture_protocols\n",
    "#     'last_modified': boildown_date_modified,\n",
    "#     'documents': boildown_protocols,\n",
    "#     'external_references': boildown_external_references,  # dbxrefs\n",
    "}\n",
    "\n",
    "\n",
    "def simplify_biosample(biosample_object):\n",
    "    ''' Keys are explicitly declared. Keys not present are ignored.'''\n",
    "    biosample_dict = {}\n",
    "    for key, value in biosample_object.items():\n",
    "        if key in biosample_simple_values:\n",
    "            add_value_to_output_dict(key, value, biosample_dict)\n",
    "        elif key in ['cell_culture_details', 'biosource']:\n",
    "            result = biosample_function_dispatch[key](biosample_object)\n",
    "            add_value_to_output_dict(key, result, biosample_dict)\n",
    "        elif key in biosample_function_dispatch:\n",
    "            result = biosample_function_dispatch[key](value)\n",
    "            add_value_to_output_dict(key, result, biosample_dict)\n",
    "    return biosample_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List ExpSets (or a search query) to export for GEO submission\n",
    "\n",
    "sets_list = ['4DNESRJ8KV4Q']  # ['4DNESACCCCCC', '4DNESACCCCCC']\n",
    "search_url = ''  # '/search/?type=ExperimentSetReplicate&condition=Enzyme%20DpnII%20-%20in%20situ%20Hi-C%20on%20cells%20cultured%20prior%20to%204DN%20SOP'\n",
    "\n",
    "sets_to_submit = []\n",
    "if sets_list:\n",
    "    sets_to_submit.extend([ff_utils.get_metadata(set_id, key=my_auth) for set_id in sets_list])\n",
    "elif search_url:\n",
    "    sets_to_submit = ff_utils.search_metadata(search_url, my_auth)\n",
    "\n",
    "print(len(sets_to_submit), 'Experiment Sets to export for GEO submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the items\n",
    "store = {}  # key is @id, value is the object with frame=embedded\n",
    "\n",
    "def _get_if_not_in_store(item):\n",
    "    at_id = item['@id']\n",
    "    if at_id not in store:\n",
    "        store[at_id] = ff_utils.get_metadata(at_id, key=my_auth)\n",
    "    return\n",
    "\n",
    "time1 = time.time()\n",
    "for expset in sets_to_submit:\n",
    "    store[expset['@id']] = expset\n",
    "    \n",
    "    # Experiment, Biosample, Exp. Protocol + variations, Biosample Protocols\n",
    "    for experiment in expset.get('experiments_in_set'):\n",
    "        _get_if_not_in_store(experiment)\n",
    "        _get_if_not_in_store(experiment['biosample'])\n",
    "        for protocol in ([store[experiment['@id']].get('protocol', '')]\n",
    "                         + store[experiment['@id']].get('protocol_variations', [])\n",
    "                         + store[experiment['biosample']['@id']].get('biosample_protocols', [])):\n",
    "            _get_if_not_in_store(protocol)\n",
    "\n",
    "        # BiosampleCellCulture, Protocols\n",
    "        for cell_culture in experiment['biosample'].get('cell_culture_details', []):  # maybe not necessary\n",
    "            _get_if_not_in_store(cell_culture)\n",
    "            for protocol in (store[cell_culture['@id']].get('protocols_additional', [])\n",
    "                             + store[cell_culture['@id']].get('authentication_protocols', [])):\n",
    "                _get_if_not_in_store(protocol)\n",
    "\n",
    "        # Biosource, Individual, Organism\n",
    "        for biosource in experiment['biosample']['biosource']:\n",
    "            _get_if_not_in_store(biosource)\n",
    "            _get_if_not_in_store(biosource['individual'])\n",
    "            # insert somewhere here some control on HeLa or other restricted files\n",
    "            _get_if_not_in_store(biosource['individual']['organism'])\n",
    "\n",
    "        # Raw and Processed Files (in experiment)\n",
    "        for file in experiment.get('files', []) + experiment.get('processed_files', []):\n",
    "            if file['file_format']['display_title'] in FORMATS:\n",
    "                _get_if_not_in_store(file)\n",
    "\n",
    "    # Processed Files (in experiment set)\n",
    "    for file in expset.get('processed_files', []):\n",
    "        if file['file_format']['display_title'] in FORMATS:\n",
    "            _get_if_not_in_store(file)\n",
    "\n",
    "time2 = time.time()\n",
    "print(round((time2-time1), 1), 'sec for collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export simplified dictionaries for each ExpSet, Experiment, Biosample\n",
    "\n",
    "date_dict = {}  # record date of export\n",
    "\n",
    "def _get_date_exported():\n",
    "    '''get date of metadata export (to be reported in the external_submissions)'''\n",
    "    date = datetime.now(timezone.utc).isoformat()\n",
    "    return {'date_exported': date, 'database': DB}\n",
    "\n",
    "# Experiment Sets\n",
    "es_dicts = []\n",
    "experiments_to_submit = []\n",
    "for es in sets_to_submit:\n",
    "    es_dictionary = simplify_expset(es)\n",
    "    es_dicts.append(es_dictionary)\n",
    "    date_dict[es['@id']] = _get_date_exported\n",
    "    \n",
    "    # get Experiments from the exported ExpSet\n",
    "    experiments_to_submit.extend([ex['replicate'] for ex in es_dictionary['replicate_exps']])\n",
    "\n",
    "# Experiments\n",
    "ex_dicts = []\n",
    "biosamples_to_submit = []\n",
    "for ex_id in list(set(experiments_to_submit)):\n",
    "    ex_dictionary = simplify_experiment(store[ex_id])\n",
    "    ex_dicts.append(ex_dictionary)\n",
    "    date_dict[ex_id] = _get_date_exported\n",
    "    \n",
    "    # get Biosample from the exported Experiment\n",
    "    biosamples_to_submit.append('/biosamples/' + ex_dictionary['biosample'] + '/')\n",
    "\n",
    "# Biosamples\n",
    "bs_dicts = []\n",
    "for bs_id in list(set(biosamples_to_submit)):\n",
    "    bs_dictionary = simplify_biosample(store[bs_id])\n",
    "    bs_dicts.append(bs_dictionary)\n",
    "    date_dict[bs_id] = _get_date_exported\n",
    "\n",
    "print('Exp Sets exported:\\t', [es['@id'] for es in sets_to_submit])\n",
    "print('Experiments exported:\\t', list(set(experiments_to_submit)))\n",
    "print('Biosamples exported:\\t', list(set(biosamples_to_submit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save json files\n",
    "\n",
    "directory = Path(\"~/Documents/GEO/submissions\").expanduser()\n",
    "overwrite = False  # overwrites existing files if set to True\n",
    "\n",
    "for dictionary in (es_dicts + ex_dicts + bs_dicts):\n",
    "    file_name = dictionary['accession'] + '.json'\n",
    "    full_path = Path.joinpath(directory, file_name)\n",
    "    if full_path.exists() and not overwrite:\n",
    "        print(file_name, 'already exists in the folder', directory)\n",
    "    else:\n",
    "        with open(full_path, 'w') as fp:\n",
    "            json.dump(dictionary, fp, indent=4)\n",
    "        print(file_name, 'file saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. patch export date for each item in external_submission\n",
    "action = False\n",
    "\n",
    "count = 0\n",
    "for item_id, patch_body in date_dict.items():\n",
    "    if action:\n",
    "        res = ff_utils.patch_metadata({\"external_submission\": patch_body}, item_id, key=my_auth)\n",
    "        if res['status'] != 'success':\n",
    "            print(res)\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        print(item_id, patch_body)\n",
    "print('patched {} items'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
