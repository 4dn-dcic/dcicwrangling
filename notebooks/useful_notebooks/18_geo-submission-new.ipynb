{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646b6377-145b-459c-8cf6-a779cf14ccef",
   "metadata": {},
   "source": [
    "## This is the updated version to automatically update the GEO metadata sheet for GEO submission\n",
    "### Important notes:\n",
    "#### 1. Please add information only in the B (USER INPUT) section. \n",
    "#### 2. Verify all the information added to the sheet. \n",
    "#### 3. To make any corrections or to add any missing data, please run the entire notebook first and then make any necassary changes manually at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a391d7-3927-462f-8a0b-c8b7202558e2",
   "metadata": {},
   "source": [
    "## A) Initialization and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceeca6c-ecc6-4156-b74b-0ef4b98bdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.cleanup import get_workflow_details, delete_wfrs\n",
    "import time\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from rapidfuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf2136-0307-4483-98f8-aaafa010ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists and dictionaries\n",
    "\n",
    "\n",
    "extracted_molecule = [\"polyA RNA\", \"total RNA\", \"nuclear RNA\", \"cytoplasmic RNA\" ,\"genomic DNA\",\"protein\",\"other\"]\n",
    "\n",
    "instrument_models = [\"454 GS\", \"454 GS 20\", \"454 GS FLX\", \"454 GS FLX+\", \"454 GS FLX Titanium\", \"454 GS Junior\", \"AB 5500 Genetic Analyzer\", \"AB 5500xl Genetic Analyzer\", \"AB 5500xl-W Genetic Analysis System\", \"AB SOLiD 3 Plus System\", \"AB SOLiD 4hq System\", \"AB SOLiD 4 System\", \"AB SOLiD PI System\", \"AB SOLiD System\", \"AB SOLiD System 2.0\", \"AB SOLiD System 3.0\", \"BGISEQ-500\", \"Complete Genomics\", \"DNBSEQ-G400\", \"DNBSEQ-G400 FAST\", \"DNBSEQ-G50\", \"DNBSEQ-T7\", \"Element AVITI\", \"FASTASeq 300\", \"GenoCare 1600\", \"GenoLab M\", \"GridION\", \"GS111\", \"Helicos HeliScope\", \"HiSeq X Five\", \"HiSeq X Ten\", \"Illumina Genome Analyzer\", \"Illumina Genome Analyzer II\", \"Illumina Genome Analyzer IIx\", \"Illumina HiScanSQ\", \"Illumina HiSeq 1000\", \"Illumina HiSeq 1500\", \"Illumina HiSeq 2000\", \"Illumina HiSeq 2500\", \"Illumina HiSeq 3000\", \"Illumina HiSeq 4000\", \"Illumina iSeq 100\", \"Illumina MiniSeq\", \"Illumina MiSeq\", \"Illumina NextSeq 500\", \"Illumina NovaSeq 6000\", \"Illumina NovaSeq X\", \"Illumina NovaSeq X Plus\", \"Ion GeneStudio S5\", \"Ion GeneStudio S5 plus\", \"Ion GeneStudio S5 prime\", \"Ion Torrent Genexus\", \"Ion Torrent PGM\", \"Ion Torrent Proton\", \"Ion Torrent S5\", \"Ion Torrent S5 XL\", \"MGISEQ-2000RS\", \"MinION\", \"NextSeq 1000\", \"NextSeq 2000\", \"NextSeq 550\", \"Onso\", \"PacBio RS\", \"PacBio RS II\", \"PromethION\", \"Revio\", \"Sentosa SQ301\", \"Sequel\", \"Sequel II\", \"Sequel IIe\", \"Tapestri\", \"UG 100\"]\n",
    "\n",
    "experiment_type_dic = {'2-stage Repli-seq': 'OTHER',\n",
    " '4C-seq': '4C-Seq',\n",
    " 'ATAC-seq': 'ATAC-seq',\n",
    " 'BLISS': 'OTHER',\n",
    " 'Bru-seq': 'BRU-Seq',\n",
    " 'Capture Hi-C': 'Capture-C',\n",
    " 'ChIA-Drop': 'ChIA-PET',\n",
    " 'ChIA-PET': 'ChIA-PET',\n",
    " 'ChIP-exo': 'OTHER',\n",
    " 'ChIP-seq': 'ChIP-Seq',\n",
    " 'CUT&RUN': 'CUT&Run',\n",
    " 'CUT&Tag': 'CUT&Tag',\n",
    " 'DamID-seq': 'DamID-Seq',\n",
    " 'Dilution Hi-C': 'OTHER',\n",
    " 'DNA FISH': 'OTHER',\n",
    " 'DNA SPRITE': 'OTHER',\n",
    " 'DNase Hi-C': 'OTHER',\n",
    " 'Droplet paired-tag': 'OTHER',\n",
    " 'Electron Tomography': 'OTHER',\n",
    " 'GAM': 'OTHER',\n",
    " 'HiCAR': 'OTHER',\n",
    " 'HiChIP': 'HiChIP',\n",
    " 'Immunofluorescence': 'OTHER',\n",
    " 'in situ ChIA-PET': 'ChIA-PET',\n",
    " 'in situ Hi-C': 'Hi-C',\n",
    " 'MARGI': 'OTHER',\n",
    " 'MC-3C': 'OTHER',\n",
    " 'MC-Hi-C': 'OTHER',\n",
    " 'Methyl Hi-C': 'OTHER',\n",
    " 'Micro-C': 'OTHER',\n",
    " 'Multi-stage Repli-seq': 'OTHER',\n",
    " 'multiplexed FISH': 'OTHER',\n",
    " 'NAD-seq': 'OTHER',\n",
    " 'OptoDroplet': 'OTHER',\n",
    " 'pA-DamID': 'OTHER',\n",
    " 'PLAC-seq': 'OTHER',\n",
    " 'RE-seq': 'OTHER',\n",
    " 'RNA FISH': 'OTHER',\n",
    " 'RNA-DNA SPRITE': 'OTHER',\n",
    " 'RNA-seq': 'RNA-Seq',\n",
    " 'sci-ATAC-seq': 'OTHER',\n",
    " 'sci-Hi-C': 'OTHER',\n",
    " 'sci-RNA-seq': 'scRNA-seq',\n",
    " 'single cell ATAC-seq': 'scATAC-seq',\n",
    " 'single cell Hi-C': 'OTHER',\n",
    " 'single cell Methyl Hi-C': 'OTHER',\n",
    " 'single cell RNA-seq': 'OTHER',\n",
    " 'SLAM-seq': 'OTHER',\n",
    " 'sn-Hi-C': 'OTHER',\n",
    " 'SPT': 'OTHER',\n",
    " 'TCC': 'OTHER',\n",
    " 'TrAC-loop': 'OTHER',\n",
    " 'TRIP': 'OTHER',\n",
    " 'TSA-seq': 'OTHER',\n",
    " 'WGBS': 'OTHER'}\n",
    "\n",
    "\n",
    "organism_name_dic = {'C. jacchus': 'Callithrix jacchus',\n",
    " 'M. mulatta': 'Macaca mulatta',\n",
    " 'M. domestica': 'Monodelphis domestica',\n",
    " 'S. pyogenes': 'S. pyogenes',\n",
    " 'M. auratus': 'Mesocricetus auratus',\n",
    " 'D. rerio': 'Danio rerio',\n",
    " 'C. sabaeus': 'Chlorocebus sabaeus',\n",
    " 'G. gallus': 'Gallus gallus',\n",
    " 'C. elegans': 'Caenorhabditis elegans',\n",
    " 'D. melanogaster': 'Drosophila melanogaster',\n",
    " 'R. norvegicus': 'Rattus norvegicus',\n",
    " 'M. musculus': 'Mus musculus',\n",
    " 'H. sapiens': 'Homo sapiens'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e426577-7d89-40a9-8ba5-9fa4d4c0de4c",
   "metadata": {},
   "source": [
    "### B) USER INPUT: Please add necessary text and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf65ed2-c0ab-404c-9991-d09785ae3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add key and path to blank GEO submission template\n",
    "\n",
    "my_auth = get_key('', keyfile='')  #add_key\n",
    "GEO_metadata_template_file = '' #https://www.ncbi.nlm.nih.gov/geo/info/seq.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4beca-bf19-4469-908e-a531c98a5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add file type(s) for processed files associated with experiments (not experiment sets)\n",
    "processed_files= [] #file_types should be be lower case as in file_type value json metadata e.g \"gene expression\"\n",
    "\n",
    "#add file type(s) for processed files associated with experiment-sets i.e. linked to multiple experiments (leave empty if you don't want to include). These will be added as supplementary files and will be associated to the entire GEO series\n",
    "add_expset_proc_as_supp_names = []\n",
    "\n",
    "#Add file type for supplementary files tagged as \"other processed files\" in 4DN(leave empty if you don't want to include). These will be added as supplementary files and linked to entire GEO series.\n",
    "supplementary_file_type = []\n",
    "\n",
    "molecule = \"\"  #add extracted molecule, choices [\"polyA RNA\", \"total RNA\", \"nuclear RNA\", \"cytoplasmic RNA\", \"genomic DNA\", \"protein\", \"other\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f76e3-8a17-4ea0-88c1-e921ad8249cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add datasets to be uploaded. All datasets should be from one publication or study and filter for one organism at a time.\n",
    "\n",
    "sets_list = [] #4DN experiment set Ids 4DNESxxx\n",
    "\n",
    "#or\n",
    "\n",
    "search_url  = '' #complete URL from the browse page on 4DN\n",
    "\n",
    "if sets_list:\n",
    "    esets = [ff_utils.get_metadata(i, my_auth) for i in sets_list]\n",
    "elif search_url:\n",
    "    esets = [i for i in ff_utils.search_metadata(search_url, my_auth)]\n",
    "    \n",
    "print(\"No. of experiments/samples collected: {}\".format(len(esets))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8ae4e-5bca-4af7-975f-84d6375b9c9a",
   "metadata": {},
   "source": [
    "## c) Extracting data (Don't edit below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de52e67-4c20-4090-be4c-d3a8819451d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting STUDY SECTION \n",
    "user_input = []\n",
    "\n",
    "for eset in esets[0:1]:\n",
    "    if eset.get(\"produced_in_pub\") == None:\n",
    "        print(\"No publication present, add manually\")\n",
    "        has_pub = False\n",
    "        user_input.append(\"title\")\n",
    "        user_input.append(\"summary\")\n",
    "        user_input.append(\"author list\")\n",
    "    else:\n",
    "        has_pub = True\n",
    "        pub_details = eset.get(\"produced_in_pub\")\n",
    "        pub_title = pub_details.get(\"title\")\n",
    "        summary = pub_details.get(\"abstract\")\n",
    "        authors = pub_details.get(\"authors\")\n",
    "        full_name = []\n",
    "\n",
    "        for author in authors:\n",
    "            name = author.split(\" \")\n",
    "            surname = name[0]\n",
    "            if len(name) > 2:\n",
    "                firstname = name[-1]\n",
    "            else:\n",
    "                firstname = name[1]\n",
    "            author_name = firstname + \", \" + surname\n",
    "            full_name.append([author_name])\n",
    "        print(\"publication details collected\")\n",
    "        \n",
    "if has_pub == False:\n",
    "    print(\"No publication details in 4DN, add information manually in the sheet at the end\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2089a4-e559-4e34-93e3-57b343f39920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Extracting SAMPLES details\n",
    "\n",
    "portal_url = \"https://data.4dnucleome.org\"\n",
    "replicate_desc = {}\n",
    "replicate_desc_short = {}\n",
    "md5sums_raw = {}\n",
    "md5sums_proc = {}\n",
    "paired_raw_files = {}\n",
    "all_raw_files = {}\n",
    "all_proc_files = {}\n",
    "total_supplementary_files = []\n",
    "proc_file_description = {}\n",
    "\n",
    "dataset_labels = []\n",
    "conditions = []\n",
    "organisms = []\n",
    "all_tissues = []\n",
    "raw_file_warning = []\n",
    "\n",
    "tissue_name = \"\"\n",
    "cell_line_name = \"\"\n",
    "cell_type = \"\"\n",
    "treatment = \"\"\n",
    "batch = \"\"\n",
    "\n",
    "threshold = 80 #To match instrument model name to GEO's model name list.\n",
    "all_matches = ()\n",
    "matched = {}\n",
    "best_matched = ()\n",
    "best_matched_bt = ()\n",
    "\n",
    "samples_rows = []\n",
    "\n",
    "for eset in esets:\n",
    "    if eset.get(\"other_processed_files\"):\n",
    "        supplementary_files = eset.get(\"other_processed_files\")\n",
    "        for sup_file_info in supplementary_files:\n",
    "            s_files = sup_file_info.get(\"files\")\n",
    "            for sfile in s_files:\n",
    "                s_file_type = sfile.get(\"file_type\")\n",
    "                if s_file_type in supplementary_file_type:\n",
    "                    sfile_acc = sfile.get(\"accession\")\n",
    "                    sfile_name = sfile.get('display_title')\n",
    "                    sfile_md5sum = sfile.get(\"md5sum\")\n",
    "                    proc_file_description[s_file_type] = sfile_name.split(\".\", 1)[1]\n",
    "                    total_supplementary_files.append(sfile_name)\n",
    "    if len(add_expset_proc_as_supp_names) > 0:\n",
    "        if eset.get('processed_files'):\n",
    "            eset_proc = eset.get('processed_files')\n",
    "            for eset_f in eset_proc:\n",
    "                    eset_proc_acc = eset_f.get(\"accession\")\n",
    "                    eset_proc_name = eset_f.get('display_title')\n",
    "                    eset_proc_md5sum = eset_f.get(\"md5sum\")\n",
    "                    eset_proc_filetype = eset_f.get('file_type')\n",
    "                    if eset_proc_filetype in add_expset_proc_as_supp_names:\n",
    "                        total_supplementary_files.append(eset_proc_name)            \n",
    "    if eset.get(\"dataset_label\") not in dataset_labels:\n",
    "        dataset_label = eset.get(\"dataset_label\")\n",
    "        dataset_labels.append(dataset_label)\n",
    "    condition = eset.get(\"condition\")\n",
    "    genotype = condition\n",
    "    if genotype not in conditions:\n",
    "        conditions.append(genotype)\n",
    "    replicate_info = eset.get(\"replicate_exps\")\n",
    "    for reps in replicate_info:\n",
    "            biorep = reps.get(\"bio_rep_no\")     \n",
    "            techrep = reps.get(\"tec_rep_no\")\n",
    "            rep_description = \"Biological replicate \" +  str(biorep) + \", Technical replicate \" + str(techrep)\n",
    "            rep_description_short = \"B\" +  str(biorep) + \" T\" + str(techrep)\n",
    "            rep_info = reps.get(\"replicate_exp\")\n",
    "            rep_info_acc = rep_info.get(\"accession\")\n",
    "            replicate_desc[rep_info_acc] = rep_description\n",
    "            replicate_desc_short[rep_info_acc] = rep_description_short\n",
    "    exps = eset.get('experiments_in_set')\n",
    "    for exp in exps:\n",
    "        raw_files_per_exp = []\n",
    "        proc_files_per_exp = []\n",
    "        exp_id = exp.get(\"@id\")\n",
    "        exp_url = portal_url + exp_id\n",
    "        exp_acc = exp.get(\"accession\")\n",
    "        library_name = exp.get(\"display_title\")\n",
    "        exp_details = exp.get(\"experiment_type\")\n",
    "        experiment_assay = exp_details.get('display_title')\n",
    "        library_strategy = experiment_type_dic[experiment_assay]\n",
    "        files = exp.get(\"files\")\n",
    "        for file in files:\n",
    "            file_acc = file.get(\"accession\")\n",
    "            file_type = file.get(\"file_type\")\n",
    "            file_name = file.get(\"display_title\")\n",
    "            if file_type == \"reads\":\n",
    "                raw_files_per_exp.append(file.get('display_title'))\n",
    "                file_metadata = ff_utils.get_metadata(file_acc, my_auth)\n",
    "                first_line = file_metadata.get('file_first_line')\n",
    "                if \"@SRR\" in first_line:\n",
    "                    raw_file_warning.append(file_acc)\n",
    "                    print('Raw file already deposited in SRA')\n",
    "                instrument_name = file_metadata.get('instrument')\n",
    "                best_match, score, index = process.extractOne(instrument_name, instrument_models)\n",
    "                all_matches = (instrument_name,best_match,score)\n",
    "                if score >= threshold:\n",
    "                    best_matched = (instrument_name,best_match,score)\n",
    "                    instrument = best_match\n",
    "                else:\n",
    "                    best_matched_bt = (instrument_name,best_match,score)\n",
    "                    instrument = instrument_name\n",
    "                matched[instrument_name] = instrument    \n",
    "                md5sum = file_metadata.get('md5sum')\n",
    "                md5sums_raw[file_name] = md5sum\n",
    "                if file.get(\"paired_end\"):\n",
    "                    paired = \"paired-end\"\n",
    "                    related_files = file.get(\"related_files\")\n",
    "                    for rf in related_files:\n",
    "                        if rf.get(\"relationship_type\") == \"paired with\":\n",
    "                            rff = rf.get('file')\n",
    "                            paired_acc = rff.get(\"accession\")\n",
    "                            paired_end = rff.get(\"paired_end\")\n",
    "                            paired_name = rff.get('display_title')\n",
    "                            if paired_end == \"2\":\n",
    "                                paired_raw_files[file_name] = paired_name\n",
    "                else:\n",
    "                    paired = \"single\"\n",
    "        if exp.get(\"processed_files\"):\n",
    "            proc_files = exp.get(\"processed_files\")\n",
    "            for pfile in proc_files:\n",
    "                file_acc = pfile.get(\"accession\")\n",
    "                file_type = pfile.get(\"file_type\")\n",
    "                file_name = pfile.get(\"display_title\")\n",
    "                if file_type in processed_files:\n",
    "                    proc_files_per_exp.append(file_name)\n",
    "                    pfile_metadata = ff_utils.get_metadata(file_acc, my_auth)\n",
    "                    pmd5sum = pfile_metadata.get('md5sum')\n",
    "                    md5sums_proc[file_name] = pmd5sum\n",
    "        else:    \n",
    "            proc_files_per_exp.append('')\n",
    "        biosample = exp.get(\"biosample\")\n",
    "        biosample_id = biosample.get(\"@id\")\n",
    "        biosample_url = portal_url + biosample_id\n",
    "        biosample_type = biosample.get(\"biosample_type\")\n",
    "        biosources = biosample.get(\"biosource\")\n",
    "        for biosource in biosources:\n",
    "            organism = biosource.get(\"organism\")\n",
    "            organism_name_dt = organism.get(\"display_title\")\n",
    "            organism_name = organism_name_dic[organism_name_dt]\n",
    "            organism_uuid = organism.get(\"uuid\")\n",
    "            organism_metadata = ff_utils.get_metadata(organism_uuid, my_auth)\n",
    "            if organism_metadata.get(\"genome_assembly\"):\n",
    "                 organism_genome_assembly = organism_metadata.get(\"genome_assembly\")\n",
    "            else:\n",
    "                 user_input.append(\"organism_genome_assembly\")\n",
    "            if organism_name not in organisms:\n",
    "                organisms.append(organism_name)\n",
    "            biosource_type = biosource.get(\"biosource_type\")\n",
    "            if biosource_type == \"tissue\":\n",
    "                tissue = biosource.get('tissue')\n",
    "                tissue_name = tissue.get('term_name')\n",
    "                all_tissues.append(tissue_name)\n",
    "                bname = tissue_name\n",
    "            else:\n",
    "                cell_type = biosource_type\n",
    "                cell_line = biosource.get(\"cell_line\")\n",
    "                cell_line_name = cell_line.get(\"term_name\")\n",
    "                bname = cell_line_name\n",
    "        proc_files_desc_exp = []\n",
    "        for file_type, ext in proc_file_description.items():\n",
    "            desc = '{} ({})'.format(file_type, ext)\n",
    "            proc_files_desc_exp.append(desc)\n",
    "            \n",
    "        processed_data_files_format_content_per_exp  = ', '.join(proc_files_desc_exp)        \n",
    "        title =  exp_acc + \", \" + organism_name + \" - \" + bname + \", \" +condition + \", \" + replicate_desc_short[exp_acc]\n",
    "        if len(processed_data_files_format_content_per_exp) > 0:\n",
    "            description = experiment_assay + \" in \" + bname + \" (\" + organism_name + \")\" +\", \" + condition + \", \" + replicate_desc[exp_acc] + \", 4DN experiment: \" + exp_url + \", 4DN Biosample: \" + biosample_url + ', Results include ' + processed_data_files_format_content_per_exp\n",
    "        else:\n",
    "            description = experiment_assay + \" in \" + bname + \" (\" + organism_name + \")\" +\", \" + condition + \", \" + replicate_desc[exp_acc] + \", 4DN experiment: \" + exp_url + \", 4DN Biosample: \" + biosample_url\n",
    "        samples_rows.append([exp_acc,title,library_strategy,organism_name,tissue_name,cell_line_name, cell_type, genotype, treatment, batch, molecule, paired,instrument,description])\n",
    "        all_raw_files[exp_acc] = raw_files_per_exp   \n",
    "        all_proc_files[exp_acc] = proc_files_per_exp\n",
    "\n",
    "#Add experimental design        \n",
    "genotypes = ', '.join(conditions)\n",
    "experiment_design = 'Total {} samples generated using {} in {} on {} with {}.'.format(len(samples_rows),library_strategy,organism_name, bname, genotypes)\n",
    "\n",
    "#Add processed data files format and content\n",
    "proc_descriptions = []\n",
    "for file_type, ext in proc_file_description.items():\n",
    "    desc = ext + \":\" + file_type\n",
    "    proc_descriptions.append(desc)\n",
    "processed_data_files_format_content  = ', '.join(proc_descriptions)\n",
    "\n",
    "#Warnings                                         \n",
    "if len(all_proc_files) == 0:\n",
    "    print(\"Warning: No processed files for any samples - cannot submit to GEO\")\n",
    "if len(organisms) > 1:\n",
    "    print(\"Warning: Samples for more than one organisms added, please filter the search query for one organism.\")\n",
    "if len(raw_file_warning) > 0:\n",
    "    print(\"Warning: Some or all raw files already deposited in SRA. See list here: {}\".format(raw_file_warning))\n",
    "if len(best_matched_bt) > 0:\n",
    "    print(\"Warning: {} match found below set threshold, check manually\".format(best_matched_bt))\n",
    "    \n",
    "                                         \n",
    "                                         \n",
    "print(\"Total samples (4DN experiments) collected: {}\".format(len(samples_rows)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a3225-57a4-4924-a3d3-9d6886004d9c",
   "metadata": {},
   "source": [
    "## D) Verify important information collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218636cf-a4ee-4744-8328-3ee637dde560",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = ', '.join(user_input)\n",
    "if len(missing) > 0:\n",
    "    print(\"Add the following manually: {}\".format(missing))\n",
    "\n",
    "if 'organism_genome_assembly' not in user_input:\n",
    "    print(\"Genome assembly collected {}, if that is incorrect please correct it manually in the sheet\".format(organism_genome_assembly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1abf03-51c0-49f6-bfd1-90a7120ba987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check collected instrument model. \n",
    "#GEO has a vocabulary for instrument names, It has to match correctly for submission to be successful\n",
    "#This script uses a package to do a best match but please verifiy the original and instrument name and edit in the metadata sheet directly\n",
    "\n",
    "for original, match in matched.items():\n",
    "    print(\"original = {}, matched = {}\".format(original, match))\n",
    "    \n",
    "print(\"If not matched correctly see the instrument_models list to select manually and update in the sheet directly\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96e41c-ffda-4846-9c9c-9d9bd5bfadc8",
   "metadata": {},
   "source": [
    "## E) Populates metadata with extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e83d-f6f8-4fb1-a09d-1aadce202b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populates metadata sheet i.e. STUDY, SAMPLES and PROTOCOLS sections.\n",
    "\n",
    "workbook = openpyxl.load_workbook(GEO_metadata_template_file)\n",
    "sheet = workbook['Metadata']\n",
    "\n",
    "#STUDY section\n",
    "\n",
    "start_row = 39\n",
    "\n",
    "if len(total_supplementary_files) > 0:\n",
    "    supp_files = ' '.join(total_supplementary_files)\n",
    "\n",
    "for row in sheet.iter_rows():\n",
    "    for cell in row:\n",
    "        if cell.value == \"*title\":\n",
    "            sheet[f\"B{cell.row}\"] = pub_title\n",
    "        if cell.value == \"*summary (abstract)\":\n",
    "            sheet[f\"B{cell.row}\"] = summary\n",
    "        if cell.value == \"*experimental design\":\n",
    "            sheet[f\"B{cell.row}\"] = experiment_design\n",
    "        if cell.value == \"*genome build/assembly\":\n",
    "            sheet[f\"B{cell.row}\"] = organism_genome_assembly\n",
    "        if cell.value == \"*processed data files format and content\":\n",
    "            sheet[f\"B{cell.row}\"] = processed_data_files_format_content\n",
    "        if len(total_supplementary_files) > 0:\n",
    "            if cell.value == \"supplementary file\":\n",
    "                sheet[f\"B{cell.row}\"] = supp_files\n",
    "\n",
    "#author names\n",
    "if len(full_name) > 7:\n",
    "    sheet.insert_rows(22, amount=len(full_name)-6)\n",
    "    start_row = 39 + len(full_name) - 6\n",
    "\n",
    "    for row in range(22, 22+(len(full_name)-6)):\n",
    "        sheet[f\"A{row}\"] = 'contributor'\n",
    "\n",
    "for i, row_data in enumerate(full_name, start=15):\n",
    "    for j, value in enumerate(row_data, start=2):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "        \n",
    "\n",
    "#SAMPLES section\n",
    "\n",
    "if len(samples_rows) > 16:\n",
    "    add_no_rows = len(samples_rows) - 16    \n",
    "    sheet.insert_rows(start_row + 16, add_no_rows + 1)\n",
    "                \n",
    "for i, row_data in enumerate(samples_rows, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=1):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "\n",
    "# SAMPLES section - files metadata        \n",
    "edit_file_headers = False\n",
    "\n",
    "no_of_raw_files = []\n",
    "no_of_processed_files = []\n",
    "raw_files = []\n",
    "proc_files = []\n",
    "        \n",
    "for key, value in all_proc_files.items():\n",
    "    no_of_processed_files.append(len(value))\n",
    "    proc_files.append(value)\n",
    "    \n",
    "for key, value in all_raw_files.items():\n",
    "    no_of_raw_files.append(len(value))\n",
    "    raw_files.append(value)    \n",
    "    \n",
    "max_raw = max(no_of_raw_files)\n",
    "max_proc = max(no_of_processed_files)\n",
    "\n",
    "if max_proc > 2 or max_raw > 5:\n",
    "    print(\"Updating column headers for files\")\n",
    "    edit_file_headers = True\n",
    "\n",
    "if edit_file_headers:\n",
    "    file_headers =  []\n",
    "    for i in range(max_proc):\n",
    "        file_headers.append('processed data file')\n",
    "    file_headers.append('*raw file')    \n",
    "    for i in range(max_raw-1):\n",
    "        file_headers.append('raw file')  \n",
    "\n",
    "    start_row_files = start_row - 1\n",
    "    for col_num, value in enumerate(file_headers, start=15):\n",
    "        sheet.cell(row=start_row_files, column=col_num, value=value)\n",
    "        \n",
    "    start_row_files = start_row\n",
    "    start_column_proc = 15\n",
    "    \n",
    "    for i, row_data in enumerate(proc_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "    \n",
    "    for i, row_data in enumerate(raw_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc + max_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)   \n",
    "\n",
    "else:\n",
    "    start_row_files = start_row\n",
    "    start_column_proc = 15\n",
    "    \n",
    "    for i, row_data in enumerate(proc_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "    \n",
    "    for i, row_data in enumerate(raw_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc + 2):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "                          \n",
    "            \n",
    "#Populate Paired-end experiment    \n",
    "if len(paired_raw_files) > 0:\n",
    "    for row in sheet.iter_rows():\n",
    "        for cell in row:\n",
    "            if cell.value == \"file name 1\":\n",
    "                paired_files_start_row = cell.row\n",
    "    \n",
    "    paired_per_exp = []\n",
    "    for r1, r2 in paired_raw_files.items():\n",
    "        paired_per_exp.append([r1, r2])\n",
    "\n",
    "    for i, row_data in enumerate(paired_per_exp, start=paired_files_start_row+1):\n",
    "        for j, value in enumerate(row_data, start=1):\n",
    "            sheet.cell(row=i, column=j, value=value)                        \n",
    "workbook.save(GEO_metadata_template_file)  \n",
    "\n",
    "print(\"Metadata sheet updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394cef3-2a2e-48cb-a5f9-44d269faf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populates MD5 Checksums sheet.\n",
    "\n",
    "add_md5sum_raw = []\n",
    "add_md5sum_proc = []\n",
    "\n",
    "for filename, md5sum in md5sums_raw.items():\n",
    "    add_md5sum_raw.append([filename,md5sum ])\n",
    "\n",
    "add_md5sum_proc = []\n",
    "\n",
    "for filename, md5sum in md5sums_proc.items():\n",
    "    add_md5sum_proc.append([filename,md5sum ])\n",
    "\n",
    "\n",
    "workbook = openpyxl.load_workbook(GEO_metadata_template_file)\n",
    "sheet = workbook['MD5 Checksums']\n",
    "\n",
    "start_row = 9\n",
    "for i, row_data in enumerate(add_md5sum_raw, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=1):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "        \n",
    "for i, row_data in enumerate(add_md5sum_proc, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=6):\n",
    "        sheet.cell(row=i, column=j, value=value)        \n",
    "        \n",
    "workbook.save(GEO_metadata_template_file)\n",
    "\n",
    "print(\"MD5sum sheet updated\")\n",
    "\n",
    "print('Please verify information added in the sheets!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f4d3c-a1ff-4820-903c-f4b86627b02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "20a8c46b2d59997a99db768ec2ffdd239be0b4d0dbcd8c0fa58604f5ac848087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
