{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.cleanup import *\n",
    "import time\n",
    "time1 = time.time()\n",
    "\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# Please Modify the following accordingly \n",
    "change_status = ''\n",
    "sets_in_scope = [\"4DNESTZWFM9F\"]\n",
    "search_url = \"\"  # \"/search/type=AAAAAAAA\"\n",
    "\n",
    "if sets_in_scope:\n",
    "    set_to_release = [ff_utils.get_metadata(i, my_auth)['uuid'] for i in sets_in_scope]\n",
    "elif search_url:\n",
    "    set_to_release = [i['uuid'] for i in ff_utils.search_metadata(search_url, my_auth)]\n",
    "\n",
    "store={}\n",
    "item_uuids=[]\n",
    "store, uuids = ff_utils.expand_es_metadata(set_to_release, my_auth, store_frame='object',add_pc_wfr=True, ignore_field = ['experiment_relation', 'biosample_relation', 'references'])\n",
    "\n",
    "print(len(store['experiment_set_replicate']), 'exp sets for status change')\n",
    "print(len(uuids), 'items collected')\n",
    "time2 = time.time()\n",
    "print(round((time2-time1), 1), 'sec for collection')\n",
    "\n",
    "common_types = ['lab', 'user', 'award','ontology', 'ontology_term', \n",
    "                'file_format', 'software', 'workflow', 'static_section',\n",
    "                'organism', 'vendor', 'file_reference', 'individual_human', \n",
    "                'enzyme', 'biosource', 'file_format']\n",
    "\n",
    "skip_status = ['replaced', 'restricted', 'archived', 'revoked', 'deleted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Check audits\n",
    "\n",
    "# do you want to check for duplicate/problematic runs on files?\n",
    "# it will take some time\n",
    "check_wfrs = True\n",
    "delete_problematic = False\n",
    "\n",
    "# check expsets\n",
    "print('EXPSET CHECK')\n",
    "for a_set in store['experiment_set_replicate']:\n",
    "    if not a_set.get('completed_processes'):\n",
    "        print(a_set['accession'], 'missing processing tag', a_set['description'][:50])\n",
    "\n",
    "# check exps \n",
    "print('\\nEXP CHECK')\n",
    "# check for experiment numbers\n",
    "exp_names = [i for i in store if i.startswith('experiment') and not i.startswith('experiment_set')]\n",
    "all_exps_on_sets = [a for i in store['experiment_set_replicate'] for a in i['experiments_in_set']]\n",
    "all_exps = [a['uuid'] for i in store.keys() for a in store[i] if i in exp_names]\n",
    "if len(all_exps_on_sets) != len(all_exps):\n",
    "    print('Number of experiments is not same as experiments associated with sets')\n",
    "    print('# of exps: {}. # of exps on sets: {}'.format(len(all_exps), len(all_exps_on_sets)))\n",
    "        \n",
    "print('\\nFILE FASTQ CHECK')\n",
    "for a_file in store['file_fastq']:\n",
    "    if not a_file.get('quality_metric'):\n",
    "        print(a_file['accession'], 'missing fastqc')\n",
    "    if not a_file.get('content_md5sum') or not a_file.get('md5sum'):\n",
    "        print(a_file['accession'], 'problems with md5')\n",
    "    if check_wfrs:\n",
    "        try:\n",
    "            # to do skip sbg runs\n",
    "            dw = delete_wfrs(a_file, my_auth, delete=delete_problematic)\n",
    "        except:\n",
    "            print('sbg run skipping')\n",
    "\n",
    "# check processed files\n",
    "print('\\nFILE PROCESSED CHECK')\n",
    "if store.get('file_processed'):\n",
    "    for a_file in store['file_processed']:\n",
    "        if a_file['file_format'] == '/file-formats/pairs/':\n",
    "            if not a_file.get('quality_metric'):\n",
    "                print(a_file['accession'], 'missing Pairsqc')\n",
    "        if not a_file.get('source_experiments'):\n",
    "            print(a_file['accession'], 'missing source experiments')\n",
    "        if check_wfrs:\n",
    "            dw = delete_wfrs(a_file, my_auth, delete=delete_problematic)   \n",
    "\n",
    "# check wfrs\n",
    "print('\\nWFR CHECK')\n",
    "if store.get('workflow_run_awsem'):\n",
    "    for wfr in store['workflow_run_awsem']:\n",
    "        if wfr['run_status'] != 'complete':\n",
    "            print('problematic wfr', wfr['uuid'], wfr['run_status'])\n",
    "        \n",
    "# check for weird status\n",
    "print('\\nREPORT NUMBERS AND CHECK STATUS')\n",
    "for i in store:\n",
    "    print(i, len(store[i]))\n",
    "    weird = [[i,x['uuid'],x['status']] for x in store[i] if x['status'] in skip_status]\n",
    "    if weird:\n",
    "        for case in weird:\n",
    "            print(case)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status\n",
    "print_each = False\n",
    "print('COMMON ITEMS')\n",
    "for a_type in store:\n",
    "    if a_type in common_types:\n",
    "        for raw_data in store[a_type]:\n",
    "            if raw_data['status'] not in ['released', 'current']:\n",
    "                print('COMMON ITEM NOT RELEASED', a_type,raw_data['status'], raw_data['uuid'])\n",
    "print('---------------------------------\\n')\n",
    "counter = 0\n",
    "for a_type in store:\n",
    "    total = len(store[a_type])\n",
    "    change = 0\n",
    "    released = 0\n",
    "    matching = 0\n",
    "    unusual = 0\n",
    "    if a_type in common_types:\n",
    "        continue\n",
    "    for raw_data in store[a_type]:\n",
    "        if raw_data['status'] in ['released', 'current']:\n",
    "            released += 1\n",
    "            msg = ('ALREADY RELEASED ITEM', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        elif raw_data['status'] == change_status:\n",
    "            matching += 1\n",
    "            msg = ('ALREADY TARGET STATUS', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        elif raw_data['status'] in skip_status:\n",
    "            unusual += 1\n",
    "            msg = ('SKIP UNUSUAL STATUS  ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        else:\n",
    "            change += 1\n",
    "            msg = ('       CHANGE        ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        if print_each:\n",
    "            print(' '.join(msg))\n",
    "    print('{:<25} Out of {t}, {r} released, {m} matching, {u} unusual, and {c}needs change'.format(a_type, t=total, r=released, m=matching, u=unusual, c=change))\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to patch the status, change action to True\n",
    "action = False\n",
    "\n",
    "# Check status\n",
    "print_each = False\n",
    "print('COMMON ITEMS')\n",
    "for a_type in store:\n",
    "    if a_type in common_types:\n",
    "        for raw_data in store[a_type]:\n",
    "            if raw_data['status'] not in ['released', 'current']:\n",
    "                print('COMMON ITEM NOT RELEASED', a_type,raw_data['status'], raw_data['uuid'])\n",
    "print('---------------------------------\\n')\n",
    "counter = 0\n",
    "for a_type in store:\n",
    "    total = len(store[a_type])\n",
    "    change = 0\n",
    "    released = 0\n",
    "    matching = 0\n",
    "    unusual = 0\n",
    "    if a_type in common_types:\n",
    "        continue\n",
    "    for raw_data in store[a_type]:\n",
    "        if raw_data['status'] in ['released', 'current']:\n",
    "            released += 1\n",
    "            msg = ('ALREADY RELEASED ITEM', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        elif raw_data['status'] == change_status:\n",
    "            matching += 1\n",
    "            msg = ('ALREADY TARGET STATUS', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        elif raw_data['status'] in skip_status:\n",
    "            unusual += 1\n",
    "            msg = ('SKIP UNUSUAL STATUS  ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        else:\n",
    "            change += 1\n",
    "            msg = ('       CHANGE        ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "            if action:\n",
    "                patch_data = {'status': change_status}\n",
    "                if change_status == 'released':\n",
    "                    if a_type in ['publication']:\n",
    "                        ff_utils.patch_metadata({'status': 'current'}, obj_id=raw_data['uuid'] ,key=my_auth)\n",
    "                    else:\n",
    "                        ff_utils.patch_metadata(patch_data, obj_id=raw_data['uuid'] ,key=my_auth)\n",
    "                else:\n",
    "                    ff_utils.patch_metadata(patch_data, obj_id=raw_data['uuid'] ,key=my_auth)    \n",
    "        if print_each:\n",
    "            print(' '.join(msg))\n",
    "    print('{:<25} Out of {t}, {r} released, {m} matching, {u} unusual, and {c} UPDATED with status'.format(a_type, t=total, r=released, m=matching, u=unusual, c=change))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
