{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6e347c-6d64-40cf-bb68-f8f058a1b227",
   "metadata": {},
   "source": [
    "### Replace uploaded files\n",
    "Use this notebook when you want to replace a (set of) file(s) that had not yet been released.\n",
    "Replacement consists in setting the correct file status, deleting some properties on the File item that refer to the previously uploaded file,\n",
    "and deleting wfr items and related quality metrics that the previously uploaded file was input for.\n",
    "\n",
    "The deletion of old file(s) from s3 is OPTIONAL and needs to be handled separately. See NOTE 2 below.\n",
    "\n",
    "The upload of new file(s) is REQUIRED and needs to be handled separately, e.g. via Submit4DN.\n",
    "\n",
    "The notebook checks the status of items before patching.\n",
    "\n",
    "**NOTE 1:** only use this when the Files to replace are not yet released.\n",
    "\n",
    "**NOTE 2:** you need to delete files from S3 if you don't immediately proceed with uploading a new file,\n",
    "since the hourly md5 check reverts the effect of running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7989d-0373-4ce2-b242-ce38a8145207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "my_auth = get_key('andrea_data')\n",
    "\n",
    "# indicate files to reset\n",
    "files_acc = '''\n",
    "4DNFIXXXXXX1\n",
    "4DNFIXXXXXX2\n",
    "'''\n",
    "\n",
    "files_acc = [f for f in files_acc.split('\\n') if f]\n",
    "for file_accession in files_acc:\n",
    "    assert file_accession.startswith('4DNFI'), f\"{file_accession} is not a file accession\"\n",
    "print(f\"{len(files_acc)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691ba6a-10e1-4333-86cf-9ea2eae9c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions\n",
    "def find_attached_items(file):\n",
    "    \"\"\"Given a File, list @id and status of all wfr inputs and linked quality metrics\"\"\"\n",
    "    def _get_id_status(item):\n",
    "        return item['@id'], item['status']\n",
    "\n",
    "    if file['@type'][0] in ['FileFastq', 'FileProcessed']:\n",
    "        wfr_inputs = file.get('workflow_run_inputs', [])\n",
    "    else:\n",
    "        # exception for File types that do not have workflow_run_inputs\n",
    "        wfr_inputs = search_wfrs_with_input_file(file)\n",
    "\n",
    "    item_ids = []\n",
    "    for wfr_input in wfr_inputs:\n",
    "        # append wfr that has the file as input\n",
    "        item_ids.append(_get_id_status(wfr_input))\n",
    "        wfr_input_object = ff_utils.get_metadata(wfr_input['@id'], key=my_auth)\n",
    "        # append any qc of the wfr\n",
    "        if wfr_input_object.get('quality_metric'):\n",
    "            item_ids.append(_get_id_status(wfr_input_object['quality_metric']))\n",
    "\n",
    "    return item_ids\n",
    "\n",
    "\n",
    "def search_wfrs_with_input_file(file):\n",
    "    \"\"\"Returns wfr items that have a given file as input.\n",
    "    This is helpful when handling FileReference or others that do not have workflow_run_inputs\"\"\"\n",
    "    query = '/search/?type=WorkflowRunAwsem&input_files.value.accession=' + file['accession']\n",
    "    wfr_items = ff_utils.search_metadata(query, key=my_auth)\n",
    "    return wfr_items\n",
    "\n",
    "\n",
    "def delete_item(item_id, status):\n",
    "    \"\"\"Delete item if status allows\"\"\"\n",
    "    assert status in ['in review by lab', 'pre-release'], \"Item status is incompatible with this change\"\n",
    "    if ACTION:\n",
    "        res = ff_utils.patch_metadata({\"status\": \"deleted\"}, item_id, key=my_auth)\n",
    "        if res.get('status') == 'success':\n",
    "            print(f\"Deleted {item_id}\")\n",
    "    else:\n",
    "        print(f\"{item_id} will be deleted\")\n",
    "    return\n",
    "\n",
    "\n",
    "def delete_file_fields(file, delete_extrafiles=False):\n",
    "    \"\"\"Reset file to uploading if status allows\"\"\"\n",
    "    assert file['status'] in ['uploaded', 'pre-release'], \"File status is incompatible with this change\"\n",
    "    fields_to_be_removed = ['filename', 'md5sum', 'content_md5sum', 'file_size']\n",
    "    if file.get('extra_files') and delete_extrafiles is True:\n",
    "        assert len(file['extra_files']) == 1, \"There is > 1 extra file, handle manually\"\n",
    "        fields_to_be_removed.append('extra_files')\n",
    "    del_add_on = 'delete_fields=' + ','.join(fields_to_be_removed)\n",
    "\n",
    "    if ACTION:\n",
    "        res = ff_utils.patch_metadata({\"status\": \"uploading\"}, file['@id'], key=my_auth, add_on=del_add_on)\n",
    "        if res.get('status') == 'success':\n",
    "            print(f\"Reset {file['@id']} to uploading\")\n",
    "        else:\n",
    "            print(res)\n",
    "    else:\n",
    "        print(f\"{file['@id']} will be reset to uploading\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcada955-e0f1-4d6f-bb17-b703e22082e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "# set action to True to patch items, otherwise a dry run will be executed\n",
    "ACTION = False\n",
    "\n",
    "# this erases extra_files completely, if there is just one extra file\n",
    "# use with caution\n",
    "DELETE_EXTRAFILES = True\n",
    "\n",
    "files_query = '/search/?type=File' + ''.join(['&accession=' + f for f in files_acc])\n",
    "files_result = ff_utils.search_metadata(files_query, key=my_auth)\n",
    "for file in files_result:\n",
    "    # Find and delete items linked to the file\n",
    "    additional_items = find_attached_items(file)\n",
    "    for (item_id, status) in additional_items:\n",
    "        delete_item(item_id, status)\n",
    "    # Reset file\n",
    "    delete_file_fields(file, DELETE_EXTRAFILES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
