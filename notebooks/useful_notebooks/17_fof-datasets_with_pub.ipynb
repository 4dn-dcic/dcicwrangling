{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59048945-4b66-4494-bd64-6b6ace00d1b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generates statistics for FOF-CT datasets\n",
    "\n",
    "### Generates excel file with columns: \n",
    "#### year, project, no_papers, no_datasets, no_files, cumulative_papers, cumulative_datasets, cumulative_files\n",
    "\n",
    "## Instructions:\n",
    "1. Log in to https://data.4dnucleome.org\n",
    "2. Go to link: https://data.4dnucleome.org/browse/?experiments_in_set.experiment_type.display_title=DNA+FISH&experiments_in_set.experiment_type.display_title=multiplexed+FISH&experiments_in_set.experiment_type.display_title=RNA+FISH&experimentset_type=replicate&type=ExperimentSetReplicate\n",
    "3. Select status = 'released'\n",
    "4. Press \"Select All\"\n",
    "5. Under \"all file types\" select all FOF-CT* file types\n",
    "6. Download the metadata file copy the \"Experiment Accession\" column and unique the accessions and use it as a sets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ac130-9394-4db7-ae21-f6726f969524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.cleanup import get_workflow_details, delete_wfrs\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819f8c8-d14f-4936-9336-1a8e6fe2bb40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_auth = get_key('', keyfile='')\n",
    "graph_stats_outfile = \"\" #Add name of output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a89cf5-5160-4805-970a-e05b8dad6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_list = []\n",
    "\n",
    "if sets_list:\n",
    "    esets = [ff_utils.get_metadata(i, my_auth) for i in sets_list]\n",
    "    \n",
    "    print(\"No. of objects {}\".format(len(esets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795a8b0-32d6-447e-bf41-0236a9a46b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting expset metadata : no. of processed files, associated publication ref\n",
    "files_per_expset = []\n",
    "pubs_id = []\n",
    "pubs_ref = []\n",
    "expset_acc = []\n",
    "na = 1\n",
    "\n",
    "\n",
    "for eset in esets:\n",
    "    eset_acc = eset.get('accession')\n",
    "    expset_acc.append(eset_acc)\n",
    "    total_files = []\n",
    "    file_types = []\n",
    "    if eset.get('processed_files'):\n",
    "        proc_files = eset.get('processed_files')\n",
    "        for file in proc_files:\n",
    "            file_type = file.get('file_type')\n",
    "            file_acc = file.get('accession')\n",
    "            total_files.append(file_acc)\n",
    "            file_types.append(file_type)       \n",
    "    else:        \n",
    "        exps = eset.get('experiments_in_set')\n",
    "        for exp in exps:\n",
    "            if exp.get('processed_files'):\n",
    "                proc_files_inexp = exp.get('processed_files')\n",
    "                for file in proc_files_inexp:\n",
    "                    file_type = file.get('file_type')\n",
    "                    file_acc = file.get('accession')\n",
    "                    total_files.append(file_acc)\n",
    "                    file_types.append(file_type)\n",
    "            else:\n",
    "                print(eset_acc, 'does not have any procfiles')\n",
    "    files_per_expset.append(len(total_files))\n",
    "    for ftype in file_types:\n",
    "        if 'FOF' not in ftype:\n",
    "            print(eset_acc, 'this expset has proc files other than fof-ct')\n",
    "    if eset.get('produced_in_pub'):     \n",
    "        pub = eset.get('produced_in_pub')\n",
    "        pubs_id.append(pub.get('@id'))\n",
    "        pubs_ref.append(pub.get('uuid'))\n",
    "    else:\n",
    "        eset_public_release = eset.get('public_release')\n",
    "        eset_award = eset.get('award')\n",
    "        eset_project = eset_award.get('project')\n",
    "        pub_id = 'N/A' + ' released on ' + eset_public_release + ' ' + eset_project\n",
    "        pubs_id.append(pub_id)\n",
    "        pubs_ref.append(pub_id)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1409067-ba4c-48b9-8360-cdfe06c6a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding lists to dictionary and then to datafram\n",
    "expset_dic = {}\n",
    "expset_dic['expset_acc']=expset_acc\n",
    "expset_dic['publication_ref']=pubs_ref\n",
    "expset_dic['total_files']=files_per_expset\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame.from_dict(expset_dic)\n",
    "\n",
    "#Aggregating the table based on publication id by counting the number of expsets and summing the total no. of files for each expset\n",
    "new = stats_df.groupby('publication_ref').agg({'expset_acc': 'count', 'total_files': 'sum'})\n",
    "\n",
    "#Get a list of publication references\n",
    "pub_refs = new.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86271d-72d6-4efc-81fb-5abd60e542be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting publication metadata\n",
    "\n",
    "refs = []\n",
    "ids=[]\n",
    "released_date =[]\n",
    "published_date=[]\n",
    "project=[]\n",
    "data_portal_ref = []\n",
    "\n",
    "for ref in pub_refs:\n",
    "    if ref not in refs:\n",
    "        if 'N/A' not in ref:\n",
    "            refs.append(ref)\n",
    "            pub_metadata = ff_utils.get_metadata(ref, my_auth)\n",
    "            ids.append(pub_metadata.get('ID'))\n",
    "            data_portal_id = pub_metadata.get('@id').split('/')[2]\n",
    "            data_portal_ref.append(data_portal_id)\n",
    "            released_date.append(pub_metadata.get('public_release'))\n",
    "            published_date.append(pub_metadata.get('date_published'))\n",
    "            award = pub_metadata.get('award')\n",
    "            project.append(award.get('project'))\n",
    "        else:\n",
    "            ids.append('N/A')\n",
    "            released_date.append(ref.split(' ')[3])\n",
    "            published_date.append('N/A')\n",
    "            project.append(ref.split(' ')[4])\n",
    "            data_portal_ref.append(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb353cd8-2fae-4e97-86cb-7e6c83f10dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding lists to dictionary and then to dataframe, merging two dataframes and calculating cumulative values\n",
    "paper_dic = {}\n",
    "paper_dic['ids']=ids\n",
    "paper_dic['released_date']=released_date\n",
    "paper_dic['published_date']=published_date\n",
    "paper_dic['project']=project\n",
    "paper_dic['publication_ref']=data_portal_ref\n",
    "\n",
    "paper_df = pd.DataFrame.from_dict(paper_dic)\n",
    "\n",
    "# merging two dataframes together based on pub_id\n",
    "\n",
    "merged = pd.merge(paper_df, new, on=\"publication_ref\", how=\"outer\" )\n",
    "merged['year'] = merged['released_date'].str.split('-', expand=True)[0]\n",
    "merged.to_excel('/Users/rahinavelkar/Desktop/fof-ct-stats/updated-new2.xlsx', index=False)\n",
    "\n",
    "final = merged.groupby(['year','project']).agg({'publication_ref':'count','expset_acc': 'sum', 'total_files': 'sum'}).reset_index()\n",
    "final.to_excel('/Users/rahinavelkar/Desktop/fof-ct-stats/updated_final.xlsx')\n",
    "\n",
    "final.loc[9] = ['2023', 'External', 0,0,0]\n",
    "final_sorted = final.sort_values(by='year', ignore_index=True).reset_index()\n",
    "final_sorted\n",
    "\n",
    "final_sorted.to_excel('/Users/rahinavelkar/Desktop/fof-ct-stats/updated_final.xlsx', )\n",
    "\n",
    "df = pd.read_excel('/Users/rahinavelkar/Desktop/fof-ct-stats/updated_final.xlsx')\n",
    "fourdn = df[df[\"project\"] == \"4DN\"].copy()\n",
    "\n",
    "# Calculate the cumulative sum for the filtered DataFrame\n",
    "fourdn['cumulative_papers'] = fourdn[\"publication_ref\"].cumsum()\n",
    "fourdn['cumulative_datasets'] = fourdn[\"expset_acc\"].cumsum()\n",
    "fourdn['cumulative_files'] = fourdn[\"total_files\"].cumsum()\n",
    "\n",
    "# Update original DataFrame with cumulative sum values, where condition is met\n",
    "df.loc[df[\"project\"] == \"4DN\", 'cumulative_papers'] = fourdn['cumulative_papers'].values\n",
    "df.loc[df[\"project\"] == \"4DN\", 'cumulative_datasets'] = fourdn['cumulative_datasets'].values\n",
    "df.loc[df[\"project\"] == \"4DN\", 'cumulative_files'] = fourdn['cumulative_files'].values\n",
    "\n",
    "external = df[df[\"project\"] == \"External\"].copy()\n",
    "\n",
    "# Calculate the cumulative sum for the filtered DataFrame\n",
    "external['cumulative_papers'] = external[\"publication_ref\"].cumsum()\n",
    "external['cumulative_datasets'] = external[\"expset_acc\"].cumsum()\n",
    "external['cumulative_files'] = external[\"total_files\"].cumsum()\n",
    "\n",
    "# Update original DataFrame with cumulative sum values, where condition is met\n",
    "df.loc[df[\"project\"] == \"External\", 'cumulative_papers'] = external['cumulative_papers'].values\n",
    "df.loc[df[\"project\"] == \"External\", 'cumulative_datasets'] = external['cumulative_datasets'].values\n",
    "df.loc[df[\"project\"] == \"External\", 'cumulative_files'] = external['cumulative_files'].values\n",
    "\n",
    "# Update original DataFrame with cumulative sum values, where condition is met\n",
    "#df.loc[df[\"project\"] == \"External\", 'Cumulative Sum'] = external['Cumulative Sum'].values\n",
    "\n",
    "df[\"cumulative_papers\"] = df[\"cumulative_papers\"].astype(int)\n",
    "df[\"cumulative_datasets\"] = df[\"cumulative_datasets\"].astype(int)\n",
    "df[\"cumulative_files\"] = df[\"cumulative_files\"].astype(int)\n",
    "\n",
    "df.to_excel(graph_stats_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b7f92-8cde-48d8-bc0f-a1282580887b",
   "metadata": {},
   "source": [
    "### Optional: To generate plot year vs papers by overlaying datasets and files information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6220f-f530-4b27-a47a-635613ed00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting data for stacked bar chart\n",
    "df_pivot = df.pivot(index=\"year\", columns=\"project\", values=\"Cumulative Sum\").fillna(0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "df_pivot.plot(kind=\"bar\", stacked=True, ax=ax, colormap=\"Set2\")  #change color here, color map options in the last block\n",
    "\n",
    "\n",
    "#create separate dataframes for plot lines\n",
    "\n",
    "df_intfiles = df[df['project']=='4DN']\n",
    "plot_intfiles = df_intfiles[['year','datasets','files']].reset_index()\n",
    "\n",
    "df_extfiles = df[df['project']=='External']\n",
    "plot_extfiles = df_extfiles[['year','datasets','files']].reset_index()\n",
    "\n",
    "\n",
    "#creating cumsum for files and datasets\n",
    "plot4dn = generate_cumsum_datasets(plot_intfiles)\n",
    "plotext = generate_cumsum_datasets(plot_extfiles)\n",
    "\n",
    "# Overlay line plots for 'datasets' and 'files'\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(plot4dn['cumsum_datasets'], color=\"red\", marker=\"o\", linestyle=\"-\", label=\"4DN datasets\")  #change color here\n",
    "ax2.plot(plot4dn['cumsum_files'], color=\"maroon\", marker=\"o\", linestyle=\"-\", label=\"4DN files\") #change color here\n",
    "ax2.plot(plotext['cumsum_datasets'], color=\"purple\", marker=\"s\", linestyle=\"--\", label=\"External datasets\") #change color here\n",
    "ax2.plot(plotext['cumsum_files'], color=\"blue\", marker=\"s\", linestyle=\"--\", label=\"External files\") #change color here\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Number of Papers (cumulative)\")\n",
    "ax2.set_ylabel(\"Number of Datasets & Files (cumulative)\")\n",
    "ax.set_title(\"FOF-CT adopted papers deposited in 4DN\")\n",
    "\n",
    "# Legends\n",
    "ax.legend(title=\"Project\", loc=\"upper left\")\n",
    "ax2.legend(title=\"No. of files and datasets (cumulative)\", bbox_to_anchor=(1.55, 1), fancybox=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.savefig('/Users/rahinavelkar/Desktop/fof-stats.png', dpi=199)\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
