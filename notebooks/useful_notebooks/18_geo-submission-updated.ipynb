{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29e1cd-dfd0-4acb-bb65-7db2461b2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GEO submission update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceeca6c-ecc6-4156-b74b-0ef4b98bdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.cleanup import get_workflow_details, delete_wfrs\n",
    "import time\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from rapidfuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf65ed2-c0ab-404c-9991-d09785ae3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add key and blank GEO submission template\n",
    "\n",
    "my_auth = get_key('', keyfile='')  #add_key\n",
    "GEO_metadata_template_file = '' #https://www.ncbi.nlm.nih.gov/geo/info/seq.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f76e3-8a17-4ea0-88c1-e921ad8249cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add datasets to be uploaded. All datasets should be from one publication or study and filter for one organism at a time.\n",
    "\n",
    "sets_list = [] \n",
    "\n",
    "search_url  = ''\n",
    "\n",
    "if sets_list:\n",
    "    esets = [ff_utils.get_metadata(i, my_auth) for i in sets_list]\n",
    "elif search_url:\n",
    "    esets = [i for i in ff_utils.search_metadata(search_url, my_auth)]\n",
    "    \n",
    "print(\"No. of samples {}\".format(len(esets))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de52e67-4c20-4090-be4c-d3a8819451d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting STUDY SECTION \n",
    "user_input = []\n",
    "\n",
    "for eset in esets[0:1]:\n",
    "    if eset.get(\"produced_in_pub\") == None:\n",
    "        print(\"No publication present, add manually\")\n",
    "        has_pub = False\n",
    "        user_input.append(\"title\")\n",
    "        user_input.append(\"summary\")\n",
    "        user_input.append(\"author list\")\n",
    "    else:\n",
    "        has_pub = True\n",
    "        pub_details = eset.get(\"produced_in_pub\")\n",
    "        pub_title = pub_details.get(\"title\")\n",
    "        summary = pub_details.get(\"abstract\")\n",
    "        authors = pub_details.get(\"authors\")\n",
    "        full_name = []\n",
    "\n",
    "        for author in authors:\n",
    "            name = author.split(\" \")\n",
    "            surname = name[0]\n",
    "            if len(name) > 2:\n",
    "                firstname = name[-1]\n",
    "            else:\n",
    "                firstname = name[1]\n",
    "            author_name = firstname + \", \" + surname\n",
    "            full_name.append([author_name])\n",
    "        print(\"publication details collected\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf2136-0307-4483-98f8-aaafa010ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists and dictionaries\n",
    "\n",
    "\n",
    "extracted_molecule = [\"polyA RNA\", \"total RNA\", \"nuclear RNA\", \"cytoplasmic RNA\" ,\"genomic DNA\",\"protein\",\"other\"]\n",
    "\n",
    "instrument_models = [\"454 GS\", \"454 GS 20\", \"454 GS FLX\", \"454 GS FLX+\", \"454 GS FLX Titanium\", \"454 GS Junior\", \"AB 5500 Genetic Analyzer\", \"AB 5500xl Genetic Analyzer\", \"AB 5500xl-W Genetic Analysis System\", \"AB SOLiD 3 Plus System\", \"AB SOLiD 4hq System\", \"AB SOLiD 4 System\", \"AB SOLiD PI System\", \"AB SOLiD System\", \"AB SOLiD System 2.0\", \"AB SOLiD System 3.0\", \"BGISEQ-500\", \"Complete Genomics\", \"DNBSEQ-G400\", \"DNBSEQ-G400 FAST\", \"DNBSEQ-G50\", \"DNBSEQ-T7\", \"Element AVITI\", \"FASTASeq 300\", \"GenoCare 1600\", \"GenoLab M\", \"GridION\", \"GS111\", \"Helicos HeliScope\", \"HiSeq X Five\", \"HiSeq X Ten\", \"Illumina Genome Analyzer\", \"Illumina Genome Analyzer II\", \"Illumina Genome Analyzer IIx\", \"Illumina HiScanSQ\", \"Illumina HiSeq 1000\", \"Illumina HiSeq 1500\", \"Illumina HiSeq 2000\", \"Illumina HiSeq 2500\", \"Illumina HiSeq 3000\", \"Illumina HiSeq 4000\", \"Illumina iSeq 100\", \"Illumina MiniSeq\", \"Illumina MiSeq\", \"Illumina NextSeq 500\", \"Illumina NovaSeq 6000\", \"Illumina NovaSeq X\", \"Illumina NovaSeq X Plus\", \"Ion GeneStudio S5\", \"Ion GeneStudio S5 plus\", \"Ion GeneStudio S5 prime\", \"Ion Torrent Genexus\", \"Ion Torrent PGM\", \"Ion Torrent Proton\", \"Ion Torrent S5\", \"Ion Torrent S5 XL\", \"MGISEQ-2000RS\", \"MinION\", \"NextSeq 1000\", \"NextSeq 2000\", \"NextSeq 550\", \"Onso\", \"PacBio RS\", \"PacBio RS II\", \"PromethION\", \"Revio\", \"Sentosa SQ301\", \"Sequel\", \"Sequel II\", \"Sequel IIe\", \"Tapestri\", \"UG 100\"]\n",
    "\n",
    "#experiment_type = [\"16S rRNA-seq\", \"4C-Seq\", \"ATAC-seq\", \"BCR-Seq\", \"Bisulfite-Seq\", \"Bisulfite-Seq (reduced representation)\", \"BRU-Seq\", \"Capture-C\", \"ChEC-seq\", \"ChIA-PET\", \"ChIP-Seq\", \"ChIRP-seq\", \"CITE-seq\", \"CRISPR Screen\", \"CUT&Run\", \"CUT&Tag\", \"DamID-Seq\", \"DNase-Hypersensitivity\", \"EM-seq\", \"FAIRE-seq\", \"GRO-Seq\", \"Hi-C\", \"HiChIP\", \"iCLIP\", \"MBD-Seq\", \"MeDIP-Seq\", \"MeRIP-Seq\", \"miRNA-Seq\", \"MNase-Seq\", \"MRE-Seq\", \"ncRNA-Seq\", \"OTHER\", \"PRO-Seq\", \"Ribo-Seq\", \"RIP-Seq\", \"RNAmethylation\", \"RNA-Seq\", \"RNA-Seq (CAGE)\", \"RNA-Seq (RACE)\", \"scATAC-seq\", \"scRNA-seq\", \"SELEX\", \"smallRNA-Seq\", \"snRNA-Seq\", \"Spatial Transcriptomics\", \"ssRNA-Seq\", \"TCR-Seq\", \"Tn-Seq\"]\n",
    "\n",
    "\n",
    "experiment_type_dic = {'2-stage Repli-seq': 'OTHER',\n",
    " '4C-seq': '4C-Seq',\n",
    " 'ATAC-seq': 'ATAC-seq',\n",
    " 'BLISS': 'OTHER',\n",
    " 'Bru-seq': 'BRU-Seq',\n",
    " 'Capture Hi-C': 'Capture-C',\n",
    " 'ChIA-Drop': 'ChIA-PET',\n",
    " 'ChIA-PET': 'ChIA-PET',\n",
    " 'ChIP-exo': 'OTHER',\n",
    " 'ChIP-seq': 'ChIP-Seq',\n",
    " 'CUT&RUN': 'CUT&Run',\n",
    " 'CUT&Tag': 'CUT&Tag',\n",
    " 'DamID-seq': 'DamID-Seq',\n",
    " 'Dilution Hi-C': 'OTHER',\n",
    " 'DNA FISH': 'OTHER',\n",
    " 'DNA SPRITE': 'OTHER',\n",
    " 'DNase Hi-C': 'OTHER',\n",
    " 'Droplet paired-tag': 'OTHER',\n",
    " 'Electron Tomography': 'OTHER',\n",
    " 'GAM': 'OTHER',\n",
    " 'HiCAR': 'OTHER',\n",
    " 'HiChIP': 'HiChIP',\n",
    " 'Immunofluorescence': 'OTHER',\n",
    " 'in situ ChIA-PET': 'ChIA-PET',\n",
    " 'in situ Hi-C': 'Hi-C',\n",
    " 'MARGI': 'OTHER',\n",
    " 'MC-3C': 'OTHER',\n",
    " 'MC-Hi-C': 'OTHER',\n",
    " 'Methyl Hi-C': 'OTHER',\n",
    " 'Micro-C': 'OTHER',\n",
    " 'Multi-stage Repli-seq': 'OTHER',\n",
    " 'multiplexed FISH': 'OTHER',\n",
    " 'NAD-seq': 'OTHER',\n",
    " 'OptoDroplet': 'OTHER',\n",
    " 'pA-DamID': 'OTHER',\n",
    " 'PLAC-seq': 'OTHER',\n",
    " 'RE-seq': 'OTHER',\n",
    " 'RNA FISH': 'OTHER',\n",
    " 'RNA-DNA SPRITE': 'OTHER',\n",
    " 'RNA-seq': 'RNA-Seq',\n",
    " 'sci-ATAC-seq': 'OTHER',\n",
    " 'sci-Hi-C': 'OTHER',\n",
    " 'sci-RNA-seq': 'scRNA-seq',\n",
    " 'single cell ATAC-seq': 'scATAC-seq',\n",
    " 'single cell Hi-C': 'OTHER',\n",
    " 'single cell Methyl Hi-C': 'OTHER',\n",
    " 'single cell RNA-seq': 'OTHER',\n",
    " 'SLAM-seq': 'OTHER',\n",
    " 'sn-Hi-C': 'OTHER',\n",
    " 'SPT': 'OTHER',\n",
    " 'TCC': 'OTHER',\n",
    " 'TrAC-loop': 'OTHER',\n",
    " 'TRIP': 'OTHER',\n",
    " 'TSA-seq': 'OTHER',\n",
    " 'WGBS': 'OTHER'}\n",
    "\n",
    "\n",
    "organism_name_dic = {'C. jacchus': 'Callithrix jacchus',\n",
    " 'M. mulatta': 'Macaca mulatta',\n",
    " 'M. domestica': 'Monodelphis domestica',\n",
    " 'S. pyogenes': 'S. pyogenes',\n",
    " 'M. auratus': 'Mesocricetus auratus',\n",
    " 'D. rerio': 'Danio rerio',\n",
    " 'C. sabaeus': 'Chlorocebus sabaeus',\n",
    " 'G. gallus': 'Gallus gallus',\n",
    " 'C. elegans': 'Caenorhabditis elegans',\n",
    " 'D. melanogaster': 'Drosophila melanogaster',\n",
    " 'R. norvegicus': 'Rattus norvegicus',\n",
    " 'M. musculus': 'Mus musculus',\n",
    " 'H. sapiens': 'Homo sapiens'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4beca-bf19-4469-908e-a531c98a5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "##User input\n",
    "\n",
    "#add file type\n",
    "processed_files= [\"read counts (plus)\", \"read counts (minus)\", \"gene expression\", \"isoform expression\"] #Need to be lower case as in file_type value json metadata e.g \"gene expression\"\n",
    "\n",
    "#Add which supplementary files\n",
    "supplementary_file_type = []\n",
    "\n",
    "#If you would like to add supplementary files from 4DN as processed files for GEO\n",
    "add_supp_as_proc = False\n",
    "\n",
    "molecule = \"total RNA\"  #add extracted molecule choices [\"polyA RNA\", \"total RNA\", \"nuclear RNA\", \"cytoplasmic RNA\", \"genomic DNA\", \"protein\", \"other\"]\n",
    "\n",
    "extract_protocol = \"\"\n",
    "\n",
    "library_construction_protocol = \"\" #\"SON and MKI67IP TSA-Seq was performed using Condition E (labeling with 1:300 tyramide biotin, 50% sucrose and 0.0015% hydrogen peroxide) (Zhang et al., 2020) with the following minor modification: 150ul of Dynabeads M-270 streptavidin (Invitrogen, catalog no. 65306) was used to purify the biotinylated DNA. For LMNB1 TSA-Seq, Condition A2 (Zhang et al., 2020) (labeling with 1:10000 tyramide biotin, 50% sucrose, 0.0015% hydrogen peroxide and reaction time 20 min at RT) was used.\"\n",
    "\n",
    "data_processing_step = \"\"\n",
    "#\"For detecting SON TSA-seq Type I and Type II peaks, the SON TSA-seq score (25 kb bins) first was smoothed using locally weighted regression (LOESS). Next, a local maximum filter with window size (w) was applied, which recorded the maximum SON TSA-seq score within this window for each genomic locus. Then the data after the maximum filter were subtracted from the original smoothed data. Peaks were retained only if they showed a reduction in value, which indicates true local peaks. A parameter optimization procedure was conducted in order to maximize the peak agreement between two SON TSA-seq replicates. As a result, a smoothing factor (span=0.005) and a window size (w=50) were selected. To distinguish local peaks into Type I and Type II, we overlapped them with Hi-C subcompartments (Rao et. al, 2014). Genomic loci overlapping A1 subcompartments were classified as Type I peaks, while those overlapping A2/B1 were designated as Type II peaks.\"\n",
    "\n",
    "if has_pub == False:\n",
    "    pub_title = \"\"\n",
    "    summary = \"\"\n",
    "    full_name = [] #list of list\n",
    "    if len(pub_title) or len(summary) or len(full_name) == 0:\n",
    "        print(\"Warning: Add publication details\")\n",
    "    \n",
    "if len(extract_protocol) == 0 or len(library_construction_protocol) == 0 or len(data_processing_step) == 0:\n",
    "    print(\"Protocol and/or data processing step not added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2089a4-e559-4e34-93e3-57b343f39920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Extracting SAMPLES details\n",
    "\n",
    "\n",
    "#Don't edit below\n",
    "portal_url = \"https://data.4dnucleome.org\"\n",
    "replicate_desc = {}\n",
    "replicate_desc_short = {}\n",
    "md5sums_raw = {}\n",
    "md5sums_proc = {}\n",
    "paired_raw_files = {}\n",
    "all_raw_files = {}\n",
    "all_proc_files = {}\n",
    "total_supplementary_files = []\n",
    "proc_file_description = {}\n",
    "\n",
    "dataset_labels = []\n",
    "conditions = []\n",
    "organisms = []\n",
    "all_tissues = []\n",
    "raw_file_warning = []\n",
    "\n",
    "tissue_name = \"\"\n",
    "cell_line_name = \"\"\n",
    "cell_type = \"\"\n",
    "treatment = \"\"\n",
    "batch = \"\"\n",
    "\n",
    "threshold = 80 #To match instrument model name to GEO's model name list.\n",
    "all_matches = ()\n",
    "matched = {}\n",
    "best_matched = ()\n",
    "best_matched_bt = ()\n",
    "\n",
    "samples_rows = []\n",
    "\n",
    "for eset in esets:\n",
    "    if eset.get(\"other_processed_files\"):\n",
    "        if add_supp_as_proc:\n",
    "            total_supplementary_files = []\n",
    "        supplementary_files = eset.get(\"other_processed_files\")\n",
    "        for sup_file_info in supplementary_files:\n",
    "            s_files = sup_file_info.get(\"files\")\n",
    "            for sfile in s_files:\n",
    "                s_file_type = sfile.get(\"file_type\")\n",
    "                if s_file_type in supplementary_file_type:\n",
    "                    sfile_acc = sfile.get(\"accession\")\n",
    "                    sfile_name = sfile.get('display_title')\n",
    "                    sfile_md5sum = sfile.get(\"md5sum\")\n",
    "                    proc_file_description[s_file_type] = sfile_name.split(\".\", 1)[1]\n",
    "                    total_supplementary_files.append(sfile_name)\n",
    "                    if add_supp_as_proc:\n",
    "                        md5sums_proc[sfile_name] = sfile_md5sum\n",
    "    if eset.get(\"dataset_label\") not in dataset_labels:\n",
    "        dataset_label = eset.get(\"dataset_label\")\n",
    "        dataset_labels.append(dataset_label)\n",
    "    condition = eset.get(\"condition\")\n",
    "    genotype = condition\n",
    "    if genotype not in conditions:\n",
    "        conditions.append(genotype)\n",
    "    replicate_info = eset.get(\"replicate_exps\")\n",
    "    for reps in replicate_info:\n",
    "            biorep = reps.get(\"bio_rep_no\")     \n",
    "            techrep = reps.get(\"tec_rep_no\")\n",
    "            rep_description = \"Biological replicate \" +  str(biorep) + \", Technical replicate \" + str(techrep)\n",
    "            rep_description_short = \"B\" +  str(biorep) + \" T\" + str(techrep)\n",
    "            rep_info = reps.get(\"replicate_exp\")\n",
    "            rep_info_acc = rep_info.get(\"accession\")\n",
    "            replicate_desc[rep_info_acc] = rep_description\n",
    "            replicate_desc_short[rep_info_acc] = rep_description_short\n",
    "    exps = eset.get('experiments_in_set')\n",
    "    for exp in exps:\n",
    "        raw_files_per_exp = []\n",
    "        proc_files_per_exp = []\n",
    "        exp_id = exp.get(\"@id\")\n",
    "        exp_url = portal_url + exp_id\n",
    "        exp_acc = exp.get(\"accession\")\n",
    "        library_name = exp.get(\"display_title\")\n",
    "        exp_details = exp.get(\"experiment_type\")\n",
    "        experiment_assay = exp_details.get('display_title')\n",
    "        library_strategy = experiment_type_dic[experiment_assay]\n",
    "        files = exp.get(\"files\")\n",
    "        for file in files:\n",
    "            file_acc = file.get(\"accession\")\n",
    "            file_type = file.get(\"file_type\")\n",
    "            file_name = file.get(\"display_title\")\n",
    "            if file_type == \"reads\":\n",
    "                raw_files_per_exp.append(file.get('display_title'))\n",
    "                file_metadata = ff_utils.get_metadata(file_acc, my_auth)\n",
    "                first_line = file_metadata.get('file_first_line')\n",
    "                if \"@SRR\" in first_line:\n",
    "                    raw_file_warning.append(file_acc)\n",
    "                    print('Raw file already deposited in SRA')\n",
    "                instrument_name = file_metadata.get('instrument')\n",
    "                best_match, score, index = process.extractOne(instrument_name, instrument_models)\n",
    "                all_matches = (instrument_name,best_match,score)\n",
    "                if score >= threshold:\n",
    "                    best_matched = (instrument_name,best_match,score)\n",
    "                    instrument = best_match\n",
    "                else:\n",
    "                    best_matched_bt = (instrument_name,best_match,score)\n",
    "                    instrument = instrument_name\n",
    "                matched[instrument_name] = instrument    \n",
    "                md5sum = file_metadata.get('md5sum')\n",
    "                md5sums_raw[file_name] = md5sum\n",
    "                if file.get(\"paired_end\"):\n",
    "                    paired = \"paired-end\"\n",
    "                    related_files = file.get(\"related_files\")\n",
    "                    for rf in related_files:\n",
    "                        if rf.get(\"relationship_type\") == \"paired with\":\n",
    "                            rff = rf.get('file')\n",
    "                            paired_acc = rff.get(\"accession\")\n",
    "                            paired_end = rff.get(\"paired_end\")\n",
    "                            if paired_end == \"2\":\n",
    "                                paired_raw_files[file_acc] = paired_acc\n",
    "                else:\n",
    "                    paired = \"single\"\n",
    "        if exp.get(\"processed_files\"):\n",
    "            proc_files = exp.get(\"processed_files\")\n",
    "            for pfile in proc_files:\n",
    "                file_acc = pfile.get(\"accession\")\n",
    "                file_type = pfile.get(\"file_type\")\n",
    "                file_name = pfile.get(\"display_title\")\n",
    "                if file_type in processed_files:\n",
    "                    proc_files_per_exp.append(file_name)\n",
    "                    pfile_metadata = ff_utils.get_metadata(file_acc, my_auth)\n",
    "                    pmd5sum = pfile_metadata.get('md5sum')\n",
    "                    md5sums_proc[file_name] = pmd5sum\n",
    "        else:    \n",
    "            proc_files_per_exp.append('')\n",
    "        biosample = exp.get(\"biosample\")\n",
    "        biosample_id = biosample.get(\"@id\")\n",
    "        biosample_url = portal_url + biosample_id\n",
    "        biosample_type = biosample.get(\"biosample_type\")\n",
    "        biosources = biosample.get(\"biosource\")\n",
    "        for biosource in biosources:\n",
    "            organism = biosource.get(\"organism\")\n",
    "            organism_name_dt = organism.get(\"display_title\")\n",
    "            organism_name = organism_name_dic[organism_name_dt]\n",
    "            organism_uuid = organism.get(\"uuid\")\n",
    "            organism_metadata = ff_utils.get_metadata(organism_uuid, my_auth)\n",
    "            if organism_metadata.get(\"genome_assembly\"):\n",
    "                 organism_genome_assembly = organism_metadata.get(\"genome_assembly\")\n",
    "            else:\n",
    "                 user_input.append(\"organism_genome_assembly\")\n",
    "            if organism_name not in organisms:\n",
    "                organisms.append(organism_name)\n",
    "            biosource_type = biosource.get(\"biosource_type\")\n",
    "            if biosource_type == \"tissue\":\n",
    "                tissue = biosource.get('tissue')\n",
    "                tissue_name = tissue.get('term_name')\n",
    "                all_tissues.append(tissue_name)\n",
    "                bname = tissue_name\n",
    "            else:\n",
    "                cell_type = biosource_type\n",
    "                cell_line = biosource.get(\"cell_line\")\n",
    "                cell_line_name = cell_line.get(\"term_name\")\n",
    "                bname = cell_line_name\n",
    "        proc_files_desc_exp = []\n",
    "        for file_type, ext in proc_file_description.items():\n",
    "            desc = '{} ({})'.format(file_type, ext)\n",
    "            proc_files_desc_exp.append(desc)\n",
    "            \n",
    "        processed_data_files_format_content_per_exp  = ', '.join(proc_files_desc_exp)        \n",
    "        title =  exp_acc + \", \" + organism_name + \" - \" + bname + \", \" +condition + \", \" + replicate_desc_short[exp_acc]\n",
    "        if len(processed_data_files_format_content_per_exp) > 0:\n",
    "            description = experiment_assay + \" in \" + bname + \" (\" + organism_name + \")\" +\", \" + condition + \", \" + replicate_desc[exp_acc] + \", 4DN experiment: \" + exp_url + \", 4DN Biosample: \" + biosample_url + ', Results include ' + processed_data_files_format_content_per_exp\n",
    "        else:\n",
    "            description = experiment_assay + \" in \" + bname + \" (\" + organism_name + \")\" +\", \" + condition + \", \" + replicate_desc[exp_acc] + \", 4DN experiment: \" + exp_url + \", 4DN Biosample: \" + biosample_url\n",
    "        samples_rows.append([exp_acc,title,library_strategy,organism_name,tissue_name,cell_line_name, cell_type, genotype, treatment, batch, molecule, paired,instrument,description])\n",
    "        all_raw_files[exp_acc] = raw_files_per_exp\n",
    "        if add_supp_as_proc:\n",
    "            all_proc_files[exp_acc] = total_supplementary_files\n",
    "        else:    \n",
    "            all_proc_files[exp_acc] = proc_files_per_exp\n",
    "\n",
    "#Add experimental design        \n",
    "genotypes = ', '.join(conditions)\n",
    "experiment_design = 'Total {} samples generated using {} in {} on {} with {}.'.format(len(samples_rows),library_strategy,organism_name, bname, genotypes)\n",
    "\n",
    "#Add processed data files format and content\n",
    "proc_descriptions = []\n",
    "for file_type, ext in proc_file_description.items():\n",
    "    desc = ext + \":\" + file_type\n",
    "    proc_descriptions.append(desc)\n",
    "processed_data_files_format_content  = ', '.join(proc_descriptions)\n",
    "\n",
    "#Warnings                                         \n",
    "if len(all_proc_files) == 0:\n",
    "    print(\"Warning: No processed files for any samples - cannot submit to GEO\")\n",
    "if len(organisms) > 1:\n",
    "    print(\"Warning: Samples for more than one organisms added, please filter the search query for one organism.\")\n",
    "if len(raw_file_warning) > 0:\n",
    "    print(\"Warning: Some or all raw files already deposited in SRA. See list here: {}\".format(raw_file_warning))\n",
    "if len(best_matched_bt) > 0:\n",
    "    print(\"Warning: {} match found below set threshold, check manually\".format(best_matched_bt))\n",
    "    \n",
    "                                         \n",
    "                                         \n",
    "print(\"Total samples included: {}\".format(len(samples_rows)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218636cf-a4ee-4744-8328-3ee637dde560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually add missing data\n",
    "\n",
    "missing = ', '.join(user_input)\n",
    "if len(missing) > 0:\n",
    "    print(\"Add the following manually: {}\".format(missing))\n",
    "\n",
    "if 'organism_genome_assembly' not in user_input:\n",
    "    print(\"Genome assembly collected {}\".format(organism_genome_assembly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad03dc-be9a-47cd-90fa-1768fbebf93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to chnage the genome assembly collected, set override_genome_assembly to True\n",
    "override_genome_assembly = False\n",
    "\n",
    "if override_genome_assembly:\n",
    "    organism_genome_assembly = \"\"\n",
    "    if len(organism_genome_assembly) == 0:\n",
    "        print(\"Warning: genome assembly\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1abf03-51c0-49f6-bfd1-90a7120ba987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check collected instrument model. GEO has a vocabulary for instrument names. It has to match correctly for submission to be successful\n",
    "#This script uses a package to do a best match but please verifiy the original and instrument name and edit in the metadata sheet directly\n",
    "\n",
    "for original, match in matched.items():\n",
    "    print(\"original = {}, matched = {}\".format(original, match))\n",
    "    \n",
    "print(\"If not matched corrected see the instrument_models list to select manually and update in the sheet directly\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e83d-f6f8-4fb1-a09d-1aadce202b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate STUDY, SAMPLES and PROTOCOLS section in template file\n",
    "\n",
    "workbook = openpyxl.load_workbook(GEO_metadata_template_file)\n",
    "sheet = workbook['Metadata']\n",
    "\n",
    "#STUDY section\n",
    "\n",
    "start_row = 39\n",
    "\n",
    "\n",
    "for row in sheet.iter_rows():\n",
    "    for cell in row:\n",
    "        if cell.value == \"*title\":\n",
    "            sheet[f\"B{cell.row}\"] = pub_title\n",
    "        if cell.value == \"*summary (abstract)\":\n",
    "            sheet[f\"B{cell.row}\"] = summary\n",
    "        if cell.value == \"*experimental design\":\n",
    "            sheet[f\"B{cell.row}\"] = experiment_design\n",
    "        if cell.value == \"*extract protocol\":\n",
    "            sheet[f\"B{cell.row}\"] = extract_protocol\n",
    "        if cell.value == \"*library construction protocol\":\n",
    "            sheet[f\"B{cell.row}\"] = library_construction_protocol\n",
    "        if cell.value == \"*data processing step\":\n",
    "            sheet[f\"B{cell.row}\"] = data_processing_step\n",
    "        if cell.value == \"*genome build/assembly\":\n",
    "            sheet[f\"B{cell.row}\"] = organism_genome_assembly\n",
    "        if cell.value == \"*processed data files format and content\":\n",
    "            sheet[f\"B{cell.row}\"] = processed_data_files_format_content            \n",
    "\n",
    "#author names\n",
    "if len(full_name) > 7:\n",
    "    sheet.insert_rows(22, amount=len(full_name)-6)\n",
    "    start_row = 39 + len(full_name) - 6\n",
    "\n",
    "    for row in range(22, 22+(len(full_name)-6)):\n",
    "        sheet[f\"A{row}\"] = 'contributor'\n",
    "\n",
    "for i, row_data in enumerate(full_name, start=15):\n",
    "    for j, value in enumerate(row_data, start=2):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "        \n",
    "\n",
    "#SAMPLES section\n",
    "\n",
    "if len(samples_rows) > 16:\n",
    "    add_no_rows = len(samples_rows) - 16    \n",
    "    sheet.insert_rows(start_row + 16, add_no_rows + 1)\n",
    "                \n",
    "for i, row_data in enumerate(samples_rows, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=1):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "\n",
    "# SAMPLES section - files metadata        \n",
    "edit_file_headers = False\n",
    "\n",
    "no_of_raw_files = []\n",
    "no_of_processed_files = []\n",
    "raw_files = []\n",
    "proc_files = []\n",
    "        \n",
    "for key, value in all_proc_files.items():\n",
    "    no_of_processed_files.append(len(value))\n",
    "    proc_files.append(value)\n",
    "    \n",
    "for key, value in all_raw_files.items():\n",
    "    no_of_raw_files.append(len(value))\n",
    "    raw_files.append(value)    \n",
    "    \n",
    "max_raw = max(no_of_raw_files)\n",
    "max_proc = max(no_of_processed_files)\n",
    "\n",
    "if max_proc > 2 or max_raw > 5:\n",
    "    print(\"Updating column headers for files\")\n",
    "    edit_file_headers = True\n",
    "\n",
    "if edit_file_headers:\n",
    "    file_headers =  []\n",
    "    for i in range(max_proc):\n",
    "        file_headers.append('processed data file')\n",
    "    file_headers.append('*raw file')    \n",
    "    for i in range(max_raw-1):\n",
    "        file_headers.append('raw file')  \n",
    "\n",
    "    start_row_files = start_row - 1\n",
    "    for col_num, value in enumerate(file_headers, start=15):\n",
    "        sheet.cell(row=start_row_files, column=col_num, value=value)\n",
    "        \n",
    "    start_row_files = start_row\n",
    "    start_column_proc = 15\n",
    "    \n",
    "    for i, row_data in enumerate(proc_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "    \n",
    "    for i, row_data in enumerate(raw_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc + max_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)   \n",
    "\n",
    "else:\n",
    "    start_row_files = start_row\n",
    "    start_column_proc = 15\n",
    "    \n",
    "    for i, row_data in enumerate(proc_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "    \n",
    "    for i, row_data in enumerate(raw_files, start=start_row_files):\n",
    "        for j, value in enumerate(row_data, start=start_column_proc + 2):\n",
    "            sheet.cell(row=i, column=j, value=value)\n",
    "                          \n",
    "            \n",
    "#Populate Paired-end experiment    \n",
    "if len(paired_raw_files) > 0:\n",
    "    for row in sheet.iter_rows():\n",
    "        for cell in row:\n",
    "            if cell.value == \"file name 1\":\n",
    "                paired_files_start_row = cell.row\n",
    "    \n",
    "    paired_per_exp = []\n",
    "    for r1, r2 in paired_raw_files.items():\n",
    "        paired_per_exp.append([r1, r2])\n",
    "\n",
    "    for i, row_data in enumerate(paired_per_exp, start=paired_files_start_row+1):\n",
    "        for j, value in enumerate(row_data, start=1):\n",
    "            sheet.cell(row=i, column=j, value=value)                        \n",
    "workbook.save(GEO_metadata_template_file)  \n",
    "\n",
    "print(\"Metadata sheet updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394cef3-2a2e-48cb-a5f9-44d269faf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate MD5 Checksums sheet.\n",
    "\n",
    "add_md5sum_raw = []\n",
    "add_md5sum_proc = []\n",
    "\n",
    "for filename, md5sum in md5sums_raw.items():\n",
    "    add_md5sum_raw.append([filename,md5sum ])\n",
    "\n",
    "add_md5sum_proc = []\n",
    "\n",
    "for filename, md5sum in md5sums_proc.items():\n",
    "    add_md5sum_proc.append([filename,md5sum ])\n",
    "\n",
    "\n",
    "workbook = openpyxl.load_workbook(GEO_metadata_template_file)\n",
    "sheet = workbook['MD5 Checksums']\n",
    "\n",
    "start_row = 9\n",
    "for i, row_data in enumerate(add_md5sum_raw, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=1):\n",
    "        sheet.cell(row=i, column=j, value=value)\n",
    "        \n",
    "for i, row_data in enumerate(add_md5sum_proc, start=start_row):\n",
    "    for j, value in enumerate(row_data, start=6):\n",
    "        sheet.cell(row=i, column=j, value=value)        \n",
    "        \n",
    "workbook.save(GEO_metadata_template_file)\n",
    "\n",
    "print(\"MD5sum sheet updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8341b-6267-4d1e-a28c-94d39bdf95fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "20a8c46b2d59997a99db768ec2ffdd239be0b4d0dbcd8c0fa58604f5ac848087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
