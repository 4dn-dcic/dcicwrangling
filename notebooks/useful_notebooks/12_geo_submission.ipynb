{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digest data sets to simplified json objects for GEO submission\n",
    "\n",
    "This notebook exports (1) ExperimentSets and related (2) Experiments and (3) Biosamples as json files, compatible with GEO submission. Embedded objects and complex data structures are simplified in these output files.\n",
    "\n",
    "* Part 0. Initialize all functions.\n",
    "* Part 1. List all sets to export.\n",
    "* Part 2. Generate simplified dictionaries for each ExpSet, Experiment and Biosample.\n",
    "* Part 3. Save dictionaries as json files.\n",
    "* Part 4. Patch items (ExpSets, Experiments, Biosamples, Files) with date of export for external submission.\n",
    "\n",
    "**NOTES**\n",
    "\n",
    "Things to check manually:\n",
    "* restricted files (e.g. from HeLa) are not exported, but this does not prevent exporting them before release. Be careful!\n",
    "* status only checked for files\n",
    "* if multiple biosources are linked to one biosample, sort things out manually\n",
    "\n",
    "**ToDo**\n",
    "\n",
    "* improve File provenance tracking\n",
    "* support other_processed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0 - Initialize all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import get_key\n",
    "from functions.geo_minimization import *\n",
    "\n",
    "my_auth = get_key('andrea_hs')\n",
    "DB = 'GEO'\n",
    "\n",
    "# this selects the file formats for processed files to be exported\n",
    "FORMATS = ['mcool', 'pairs', 'bw']\n",
    "# this selects the file status for raw and processed files to be exported\n",
    "STATUSES = ['uploaded', 'pre-release', 'released', 'released to project']\n",
    "\n",
    "data_use_guidelines = ff_utils.get_metadata(\"621e8359-3885-40ce-965d-91894aa7b758\", key=my_auth)['content']\n",
    "pmid_4dn_paper = '28905911'\n",
    "\n",
    "\n",
    "def get_item_in_store(item):\n",
    "    '''Gets item with frame=embedded from store. If absent, uses get_metadata and stores it.\n",
    "    Input can be @id or a dictionary with @id as key.'''\n",
    "    if isinstance(item, dict):\n",
    "        item = item['@id']\n",
    "    if item not in store:\n",
    "        store[item] = ff_utils.get_metadata(item, key=my_auth)\n",
    "    return store[item]\n",
    "\n",
    "\n",
    "### Files\n",
    "def boildown_files(files_list):\n",
    "    '''Takes list of raw files and produces list of runs.\n",
    "    Each run is a pair of files (if paired end) or a single file (if single end).\n",
    "    runs = [[pe1, pe2], ..., [se], ...]\n",
    "    '''\n",
    "    files_to_export = [f for f in files_list if f['status'] in STATUSES]\n",
    "    exported_files = [boildown_file(get_item_in_store(f)) for f in files_to_export]\n",
    "    exported_files_ids = [f['@id'] for f in files_to_export]\n",
    "    runs = []\n",
    "    for a_file in exported_files:\n",
    "        if a_file.get('paired_end') is None:\n",
    "            runs.append([a_file])\n",
    "        elif a_file.get('paired_end') == '1':\n",
    "            pe1 = a_file\n",
    "            for another_file in exported_files:\n",
    "                if another_file['accession'] == a_file['related_files']:\n",
    "                    pe2 = another_file\n",
    "                    break\n",
    "            runs.append([pe1, pe2])\n",
    "    return runs, exported_files_ids\n",
    "\n",
    "\n",
    "def boildown_processed_files(processed_files_list):\n",
    "    output_list = []\n",
    "    exported_files_ids = []\n",
    "    for pf in processed_files_list:\n",
    "        if pf['file_format']['display_title'] in FORMATS and pf['status'] in STATUSES:\n",
    "            file_object = get_item_in_store(pf)\n",
    "            file_dict = boildown_file(file_object)\n",
    "            output_list.append(file_dict)\n",
    "            exported_files_ids.append(file_object['@id'])\n",
    "    return output_list, exported_files_ids\n",
    "\n",
    "\n",
    "### Experiment Set\n",
    "expset_simple_values = [\n",
    "    'accession', 'description', 'dataset_label',\n",
    "    'condition', 'public_release', 'number_of_experiments'\n",
    "]\n",
    "\n",
    "expset_function_dispatch = {\n",
    "    '@id': atid2url,\n",
    "    'lab': boildown_title,\n",
    "    'contributing_labs': boildown_list_to_titles,\n",
    "    'submitted_by': boildown_title,\n",
    "    'award': boildown_award,\n",
    "#     'last_modified': boildown_date_modified,\n",
    "    'experiments_in_set': boildown_experiments_in_set,  # gets exps list, replicates, exp type(s), !series_title\n",
    "#     'documents': boildown_protocols,\n",
    "    'external_references': boildown_external_references,  # use instead of dbxrefs because it is validated\n",
    "    'produced_in_pub': boildown_publication,  # returns also !Series_citation if no PMID is available\n",
    "    'processed_files': boildown_processed_files,\n",
    "}\n",
    "\n",
    "\n",
    "def simplify_expset(expset_object):\n",
    "    ''' Keys are explicitly declared. Keys not present are ignored.'''\n",
    "    expset_dict = {}\n",
    "    file_ids = []\n",
    "    exp_ids = []\n",
    "    for key, value in expset_object.items():\n",
    "        export_value = None\n",
    "        if key in expset_simple_values:\n",
    "            export_value = value\n",
    "        elif key == 'processed_files':\n",
    "            export_value, files_list = expset_function_dispatch[key](value)\n",
    "            file_ids.extend(files_list)\n",
    "        elif key == 'experiments_in_set':\n",
    "            export_value, exps_list = expset_function_dispatch[key](value)\n",
    "            exp_ids.extend(exps_list)\n",
    "        elif key in expset_function_dispatch:\n",
    "            export_value = expset_function_dispatch[key](value)\n",
    "\n",
    "        if export_value:\n",
    "            expset_dict = add_to_output_dict(key, export_value, expset_dict)\n",
    "    if not expset_object.get('produced_in_pub'):  # attach data use guidelines and 4DN white paper\n",
    "        expset_dict['data_use_guidelines'] = data_use_guidelines\n",
    "        expset_dict['produced_in_pub'] = pmid_4dn_paper\n",
    "    expset_dict['series_title'] = expset_dict.setdefault('series_title', '') + expset_object['accession']\n",
    "    return expset_dict, file_ids, exp_ids\n",
    "\n",
    "\n",
    "### Protocols\n",
    "def boildown_experimental_protocol(experiment_object):\n",
    "    ''' Return experimental_protocol (list), by combining protocol,\n",
    "    protocol_variations and cell_sorting_protocol'''\n",
    "    protocols = []\n",
    "    if experiment_object.get('protocol'):\n",
    "        protocol = get_item_in_store(experiment_object['protocol'])\n",
    "        protocols.append(protocol)\n",
    "    if experiment_object.get('protocol_variations'):\n",
    "        protocol_variations = [p for p in get_item_in_store(experiment_object['protocol_variations'])]\n",
    "        protocols.extend(protocol_variations)\n",
    "    if experiment_object.get('cell_sorting_protocol'):\n",
    "        protocol_sorting = get_item_in_store(experiment_object['cell_sorting_protocol'])\n",
    "        protocols.append(protocol_sorting)\n",
    "    protocols_list = boildown_protocols(protocols)\n",
    "    return {'experimental_protocol': protocols_list}\n",
    "\n",
    "\n",
    "def boildown_cell_culture_details(biosample_object):\n",
    "    ''' Return cell_culture_protocols (list), by combining SOP_cell_culture from Biosource, and\n",
    "    'protocols_additional' and 'authentication_protocols' from BCC\n",
    "    '''\n",
    "    protocols = []\n",
    "    biosources = biosample_object['biosource']\n",
    "    for bsr in biosources:\n",
    "        biosource = get_item_in_store(bsr)\n",
    "        if biosource.get('SOP_cell_line'):\n",
    "            protocol = get_item_in_store(biosource['SOP_cell_line'])\n",
    "            protocols.append(protocol)\n",
    "    cell_culture_details = biosample_object.get('cell_culture_details', [])\n",
    "    for bs_cc in cell_culture_details:\n",
    "        protocols_add = [get_item_in_store(protocol) for protocol in bs_cc.get('protocols_additional', [])] \n",
    "        protocols.extend(protocols_add)\n",
    "#         protocols_auth = [get_item_in_store(protocol) for protocol in bs_cc.get('authentication_protocols', [])] \n",
    "#         protocols.extend(protocols_auth)\n",
    "    protocols_list = boildown_protocols(protocols)\n",
    "    return {'cell_culture_protocols': protocols_list}\n",
    "\n",
    "\n",
    "def boildown_biosample_protocols(biosample_protocols):\n",
    "    ''' Get each protocol object from store'''\n",
    "    protocols = [get_item_in_store(protocol) for protocol in biosample_protocols if protocol]\n",
    "    protocols_list = boildown_protocols(protocols)\n",
    "    return protocols_list\n",
    "\n",
    "\n",
    "### Experiment\n",
    "\n",
    "# note that some values appear in multiple schemas, but here are only listed once\n",
    "experiment_simple_values = [\n",
    "\n",
    "    ## add? 'other_processed_files'\n",
    "    \n",
    "    # mixins\n",
    "    'public_release',\n",
    "    'library_prep_kit', 'average_fragment_size', 'fragment_size_range', 'fragmentation_method',\n",
    "    'fragment_size_selection_method', 'pcr_cycles', 'spikin_description',\n",
    "    'antibody_lot_id', 'antibody_dilution',\n",
    "\n",
    "    # calcprops\n",
    "    'experiment_summary',\n",
    "    \n",
    "    # experiment (generic)\n",
    "    'accession', 'description',\n",
    "\n",
    "    # experiment_hi_c\n",
    "    'crosslinking_method', 'crosslinking_time', 'crosslinking_temperature',\n",
    "    'enzyme_lot_number', 'digestion_time', 'digestion_temperature', 'tagging_method',\n",
    "    'ligation_time', 'ligation_temperature', 'ligation_volume', 'biotin_removed',\n",
    "    \n",
    "    # experiment_atacseq\n",
    "    'transposase', 'enzyme_incubation_time', 'incubation_temperature', 'primer_removal_method',\n",
    "    \n",
    "    # experiment_capture_c\n",
    "    'rna_tag',\n",
    "    \n",
    "    # experiment_chiapet\n",
    "    \n",
    "    # experiment_damid\n",
    "    'sap_treatment', 'me_pcr_cycles', 'y_ligation_dna_input',\n",
    "    \n",
    "    # experiment_repliseq\n",
    "    'dna_label', 'labeling_time', 'cell_cycle_phase', 'stage_fraction', 'total_fractions_in_exp',\n",
    "    \n",
    "    # experiment_seq\n",
    "    'tagging_rounds', 'reaction_time', '3p_adenylation_time', '3p_adenylation_temperature',\n",
    "    'strandedness', 'molecule',\n",
    "\n",
    "    # experiment_tsaseq\n",
    "    'protocol_version', 'resolution', 'secondary_antibody_lot_id', 'secondary_antibody_dilution',\n",
    "    'tyramide_concentration', 'reaction_buffer', 'reaction_temperature', 'affinity_rounds',\n",
    "    'average_biotin_range', 'biotinylated_spikein_source', 'non_biotinylated_spikein_source',\n",
    "    ## add? 'biotinylated_spikein_sequences', 'non_biotinylated_spikein_sequences' linkTo FileReferences\n",
    "]\n",
    "\n",
    "experiment_function_dispatch = {\n",
    "    '@id': atid2url,\n",
    "    'lab': boildown_title,\n",
    "    'contributing_labs': boildown_list_to_titles,\n",
    "    'submitted_by': boildown_title,\n",
    "    'award': boildown_award,\n",
    "    'display_title': boildown_exp_display_title,\n",
    "    'experiment_type': boildown_experiment_type,\n",
    "    'experiment_relation': boildown_experiment_relations,\n",
    "#     'last_modified': boildown_date_modified,\n",
    "\n",
    "#     'experiment_categorizer': boildown_exp_categorizer,  # 'combined' key (enzyme or target) + value\n",
    "    'targeted_factor': boildown_list_to_titles,\n",
    "    'targeted_regions': boildown_targeted_regions,  # Capture Hi-C Experiment\n",
    "    'digestion_enzyme': boildown_title,\n",
    "    'antibody': boildown_title,\n",
    "    'secondary_antibody': boildown_title,\n",
    "    'reporter_construct': boildown_title,\n",
    "    \n",
    "    'biosample': boildown_biosample_name,\n",
    "    'biosample_quantity': boildown_biosample_quantity,  # includes units\n",
    "    \n",
    "    # experimental protocol\n",
    "    'protocol': boildown_experimental_protocol,  # includes protocol_variation and cell_sorting_protocol # !Sample_extract_protocol,\n",
    "    'protocol_variation': boildown_experimental_protocol,  # includes protocol and cell_sorting_protocol # !Sample_extract_protocol,\n",
    "    'cell_sorting_protocol': boildown_experimental_protocol,  # includes protocol and protocol_variation # !Sample_extract_protocol,\n",
    "\n",
    "    'files': boildown_files,\n",
    "    'processed_files': boildown_processed_files,\n",
    "}\n",
    "\n",
    "def simplify_experiment(experiment_object):\n",
    "    ''' Keys are explicitly declared. Keys not present are ignored.'''\n",
    "    experiment_dict = {}\n",
    "    file_ids = []\n",
    "    biosample_id = ''\n",
    "    for key, value in experiment_object.items():\n",
    "        export_value = None\n",
    "        if key in experiment_simple_values:\n",
    "            export_value = value\n",
    "        elif key in ['biosample_quantity', 'protocol', 'protocol_variation', 'cell_sorting_protocol']:\n",
    "            export_value = experiment_function_dispatch[key](experiment_object)\n",
    "        elif key in ['files', 'processed_files']:\n",
    "            export_value, files_list = experiment_function_dispatch[key](value)\n",
    "            file_ids.extend(files_list)\n",
    "        elif key == 'biosample':\n",
    "            export_value, biosample_id = experiment_function_dispatch[key](value)\n",
    "        elif key in experiment_function_dispatch:\n",
    "            export_value = experiment_function_dispatch[key](value)\n",
    "\n",
    "        if export_value:\n",
    "            experiment_dict = add_to_output_dict(key, export_value, experiment_dict)\n",
    "    return experiment_dict, file_ids, biosample_id\n",
    "\n",
    "\n",
    "### Biosample\n",
    "individual_simple_values = [\n",
    "    'age', 'age_units', 'sex', 'life_stage', 'mouse_life_stage',\n",
    "    'mouse_strain', 'ethnicity', 'health_status',\n",
    "]\n",
    "\n",
    "def boildown_individual(biosample_object):\n",
    "    '''Get individual and return all keys in interesting values'''\n",
    "    individual_dict = {}\n",
    "    individual = get_item_in_store(biosample_object['biosource'][0]['individual'])\n",
    "    for key, value in individual.items():\n",
    "        export_value = None\n",
    "        if key in individual_simple_values:\n",
    "            export_value = value\n",
    "        elif key == 'organism':\n",
    "            organism_object = get_item_in_store(individual['organism'])\n",
    "            export_value = boildown_organism(organism_object)\n",
    "        if export_value:\n",
    "            individual_dict = add_to_output_dict(key, export_value, individual_dict)\n",
    "    return individual_dict\n",
    "\n",
    "\n",
    "biosource_function_dispatch = {\n",
    "    'biosource_vendor': boildown_title,\n",
    "    'cell_line': boildown_title,\n",
    "    'individual': boildown_individual,\n",
    "    'SOP_cell_line': boildown_cell_culture_details,  # also retrieved from Biosample if cell_culture_details exists\n",
    "}\n",
    "\n",
    "def minimize_biosource(biosample_object):\n",
    "    ''' Biosources list is obtained from biosample.\n",
    "    Often (always?) there is just one Biosource. Return list of accessions otherwise.\n",
    "    Most of the interesting values are embedded fields, apart from SOP_cell_line\n",
    "    which requires to get_metadata.'''\n",
    "    biosources_list = biosample_object['biosource']\n",
    "    if len(biosources_list) > 1:\n",
    "        return ', '.join([bsr['accession'] for bsr in biosources_list])\n",
    "    # most cases have only 1 biosource\n",
    "    biosource = biosources_list[0]\n",
    "    biosource_dict = {}\n",
    "    for key, value in biosource.items():\n",
    "        export_value = None\n",
    "        if key in ['individual', 'SOP_cell_line']:  # pass the entire object\n",
    "            export_value = biosource_function_dispatch[key](biosample_object)\n",
    "        elif key in biosource_function_dispatch:\n",
    "            export_value = biosource_function_dispatch[key](value)\n",
    "\n",
    "        if export_value:\n",
    "            biosource_dict = add_to_output_dict(key, export_value, biosource_dict)\n",
    "    return biosource_dict\n",
    "\n",
    "\n",
    "biosample_simple_values = [\n",
    "    'accession', 'biosource_summary', 'biosample_type', 'description',\n",
    "    'modifications_summary', 'treatments_summary',\n",
    "]\n",
    "\n",
    "biosample_function_dispatch = {\n",
    "    '@id': atid2url,\n",
    "    'tissue_organ_info': boildown_tissue_organ_info,  # OK also with multiple biosources\n",
    "    'biosource': minimize_biosource,\n",
    "    'biosample_protocols': boildown_biosample_protocols,\n",
    "    'cell_culture_details': boildown_cell_culture_details,  # returns cell_culture_protocols\n",
    "#     'last_modified': boildown_date_modified,\n",
    "#     'documents': boildown_protocols,\n",
    "#     'external_references': boildown_external_references,  # dbxrefs\n",
    "}\n",
    "\n",
    "\n",
    "def simplify_biosample(biosample_object):\n",
    "    ''' Keys are explicitly declared. Keys not present are ignored.'''\n",
    "    biosample_dict = {}\n",
    "    for key, value in biosample_object.items():\n",
    "        export_value = None\n",
    "        if key in biosample_simple_values:\n",
    "            export_value = value\n",
    "        elif key in ['cell_culture_details', 'biosource']:  # pass the entire object\n",
    "            export_value = biosample_function_dispatch[key](biosample_object)\n",
    "        elif key in biosample_function_dispatch:\n",
    "            export_value = biosample_function_dispatch[key](value)\n",
    "\n",
    "        if export_value:\n",
    "            biosample_dict = add_to_output_dict(key, export_value, biosample_dict)\n",
    "    return biosample_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - List all sets to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List ExpSets (or a search query) to export for GEO submission\n",
    "\n",
    "sets_list = ['4DNESML2L8RP'] # ['4DNESRJ8KV4Q', '4DNESNMAAN97']\n",
    "search_url = '' #'/search/?type=ExperimentSetReplicate&condition=Enzyme%20DpnII%20-%20in%20situ%20Hi-C%20on%20cells%20cultured%20prior%20to%204DN%20SOP'\n",
    "\n",
    "time1 = time.time()\n",
    "if sets_list:\n",
    "    sets_to_export = [ff_utils.get_metadata(set_id, my_auth)['uuid'] for set_id in sets_list]\n",
    "elif search_url:\n",
    "    sets_to_export = [i['uuid'] for i in ff_utils.search_metadata(search_url, my_auth)]\n",
    "    \n",
    "result_expand_es = {}\n",
    "uuids = []\n",
    "result_expand_es, uuids = ff_utils.expand_es_metadata(sets_to_export, my_auth, store_frame='embedded',add_pc_wfr=True, ignore_field = ['experiment_relation', 'biosample_relation', 'references', 'experiment_type'])\n",
    "\n",
    "experiment_sets = result_expand_es.get('experiment_set_replicate', []) + result_expand_es.get('experiment_set', [])\n",
    "print(len(experiment_sets), 'exp sets collected')\n",
    "print(len(uuids), 'items collected')\n",
    "time2 = time.time()\n",
    "print(round((time2-time1), 1), 'sec for collection')\n",
    "\n",
    "# get date of metadata export (to be reported in the external_submissions)\n",
    "date_exported = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "# Reorder result in store, using @id as keys\n",
    "store = {}  # key is @id, value is the object with frame=embedded\n",
    "for item_type, items_list in result_expand_es.items():\n",
    "    if item_type.startswith('experiment'):\n",
    "        # we want to use get_metadata for these, due to the ignore_field in expand_es_metadata \n",
    "        continue\n",
    "    for item in items_list:\n",
    "        store[item['@id']] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Generate simplified dictionaries\n",
    "Export simplified dictionaries for each ExpSet, Experiment, Biosample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_items = []  # list of exported simplified dictionaries (ExpSet, Exp, Biosample)\n",
    "id_exported_items = []  # list of @id of items that need date_exported (ExpSet, Exp, Biosample, FileFastq)\n",
    "\n",
    "# Experiment Sets\n",
    "expsets_to_export = [es['@id'] for es in experiment_sets]\n",
    "experiments_to_export = []\n",
    "for expset in expsets_to_export:\n",
    "    es_dictionary, file_ids, exp_ids = simplify_expset(get_item_in_store(expset))\n",
    "    exported_items.append(es_dictionary)\n",
    "    id_exported_items.append(expset)\n",
    "    id_exported_items.extend(file_ids)\n",
    "    experiments_to_export.extend(exp_ids)\n",
    "\n",
    "# Experiments\n",
    "experiments_to_export = list(set(experiments_to_export))\n",
    "biosamples_to_export = []\n",
    "for exp in experiments_to_export:\n",
    "    ex_dictionary, file_ids, biosample_id = simplify_experiment(get_item_in_store(exp))\n",
    "    exported_items.append(ex_dictionary)\n",
    "    id_exported_items.append(exp)\n",
    "    id_exported_items.extend(file_ids)\n",
    "    biosamples_to_export.append(biosample_id)\n",
    "\n",
    "# Biosamples\n",
    "biosamples_to_export = list(set(biosamples_to_export))\n",
    "for bs in biosamples_to_export:\n",
    "    bs_dictionary = simplify_biosample(get_item_in_store(bs))\n",
    "    exported_items.append(bs_dictionary)\n",
    "    id_exported_items.append(bs)\n",
    "\n",
    "print('Exp Sets exported:\\n', '\\n'.join(expsets_to_export), sep='')\n",
    "print('\\nExperiments exported:\\n', '\\n'.join(experiments_to_export), sep='')\n",
    "print('\\nBiosamples exported:\\n', '\\n'.join(biosamples_to_export), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Save dictionaries as json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set directory for output files\n",
    "directory = Path(\"~/Documents/GEO/tsa_test\").expanduser()\n",
    "overwrite = False  # overwrites existing files if set to True\n",
    "\n",
    "for item in exported_items:\n",
    "    file_name = item['accession'] + '.json'\n",
    "    full_path = Path.joinpath(directory, file_name)\n",
    "    if full_path.exists() and not overwrite:\n",
    "        print(file_name, 'already exists in the folder', directory)\n",
    "    else:\n",
    "        with open(full_path, 'w', encoding='utf-8') as fp:\n",
    "            json.dump(item, fp, indent=4, ensure_ascii=False)\n",
    "        print(file_name, 'file saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Patch export date for each item in external_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not patch unless action is True\n",
    "action = False\n",
    "\n",
    "patch_body = {'external_submission': {'date_exported': date_exported, 'database': DB}}\n",
    "count = 0\n",
    "for item_id in id_exported_items:\n",
    "    if action:\n",
    "        res = ff_utils.patch_metadata(patch_body, item_id, key=my_auth)\n",
    "        if res['status'] != 'success':\n",
    "            print(res)\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        print(item_id)\n",
    "print('patched {} items'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
