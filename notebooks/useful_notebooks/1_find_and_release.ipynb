{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEASE COPY NOTEBOOKS TO YOUR FOLDERS TO PREVENT COMMIT CONFLICTS\n",
    "* If you would like to contribute to this notebook, make changes on it in useful_notebooks folder, run \"Restart and Clear Output\" before commit.\n",
    "\n",
    "#### Unexpected Expansion Cases\n",
    "###### Experiment set fetches unrealated labs and awards\n",
    "Sometimes a fetch will get some unrelated labs and awards, this is because of the multiple awards a lab can have. This multiple awards are visited, which have users linked to them. This users also have labs, so here you go. Hopefully all are released/current already.\n",
    "\n",
    "###### Experiment set fetches unrealted biosmaple/experiment/set\n",
    "This was so far because of the experiment and biosample relation field, or the references field that links to a publication. If you ignore these fields, if should be fine.\n",
    "`ignore_field = ['experiment_relation', 'biosample_relation', 'references']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.cleanup import *\n",
    "import time\n",
    "time1 = time.time()\n",
    "\n",
    "my_auth = get_key('andyprod', keyfile='~/saved_keypairs.json')\n",
    "#my_auth = get_key('koray_data')\n",
    "\n",
    "# Please Modify the following accordingly \n",
    "# do you want to check for duplicate/problematic runs on files?\n",
    "# it will take some time\n",
    "check_wfrs = True\n",
    "delete_problematic = False\n",
    "\n",
    "# Which status to change\n",
    "change_status = 'released'\n",
    "\n",
    "sets_in_scope = [] # ['4DNACCCC', '4DNACCCCC']\n",
    "\n",
    "search_url  = '/search/?award.project=4DN&experiments_in_set.experiment_type=dilution+Hi-C&experimentset_type=replicate&lab.display_title=Bing+Ren%2C+UCSD&status=pre-release&type=ExperimentSetReplicate'\n",
    "\n",
    "if sets_in_scope:\n",
    "    set_to_release = [ff_utils.get_metadata(i, my_auth)['uuid'] for i in sets_in_scope]\n",
    "elif search_url:\n",
    "    set_to_release = [i['uuid'] for i in ff_utils.search_metadata(search_url, my_auth)]\n",
    "\n",
    "store={}\n",
    "item_uuids=[]\n",
    "store, uuids = ff_utils.expand_es_metadata(set_to_release, my_auth, store_frame='embedded',add_pc_wfr=True, ignore_field = ['experiment_relation', 'biosample_relation', 'references'])\n",
    "\n",
    "print(len(store['experiment_set_replicate']), 'exp sets for status change')\n",
    "print(len(uuids), 'items collected')\n",
    "time2 = time.time()\n",
    "print(round((time2-time1), 1), 'sec for collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Check audits\n",
    "\n",
    "# create stash of wfrs to pass to delete_wfrs\n",
    "stash = store.get('workflow_run_sbg', []) + store.get('workflow_run_awsem', [])\n",
    "\n",
    "# to decide which items to ignore as they have a 'higher' status\n",
    "STATUS_LEVEL = {\n",
    "    # standard_status\n",
    "    \"released\": 10, \"current\": 10,\n",
    "    \"released to project\": 9,\n",
    "    \"pre-release\": 8,\n",
    "    \"planned\": 6, \"submission in progress\": 6,\n",
    "    \"in review by lab\": 4,\n",
    "    \"revoked\": 0, \"archived\": 0,\"deleted\": 0, \"obsolete\": 0, \"replaced\": 0, \"archived to project\": 0,\n",
    "    # additional file statuses\n",
    "    'to be uploaded by workflow': 4, 'uploading': 4, 'uploaded': 4, 'upload failed': 4, 'draft': 4, 'released to lab': 4}\n",
    "\n",
    "change_level = STATUS_LEVEL.get(change_status, 1)\n",
    "\n",
    "# check expsets\n",
    "print('EXPSET CHECK')\n",
    "for a_set in store['experiment_set_replicate']:\n",
    "    if not a_set.get('completed_processes'):\n",
    "        print(a_set['accession'], 'missing processing tag', a_set['description'][:50])\n",
    "\n",
    "# check exps \n",
    "print('\\nEXP CHECK')\n",
    "# check for experiment numbers\n",
    "exp_names = [i for i in store if i.startswith('experiment') and not i.startswith('experiment_set')]\n",
    "all_exps_on_sets = [a for i in store['experiment_set_replicate'] for a in i['experiments_in_set']]\n",
    "all_exps = [a['uuid'] for i in store.keys() for a in store[i] if i in exp_names]\n",
    "if len(all_exps_on_sets) != len(all_exps):\n",
    "    print('Number of experiments is not same as experiments associated with sets')\n",
    "    print('# of exps: {}. # of exps on sets: {}'.format(len(all_exps), len(all_exps_on_sets)))\n",
    "        \n",
    "print('\\nFILE FASTQ CHECK')\n",
    "for a_file in store['file_fastq']:\n",
    "    if not a_file.get('quality_metric'):\n",
    "        print(a_file['accession'], 'missing fastqc')\n",
    "    if not a_file.get('content_md5sum'):\n",
    "        print(a_file['accession'], 'missing content md5 sum')\n",
    "    if not a_file.get('md5sum'):\n",
    "        print(a_file['accession'], 'md5 was not calculated during upload, missing md5sum')\n",
    "    if check_wfrs:\n",
    "        dw = delete_wfrs(a_file, my_auth, delete=delete_problematic, stash=stash)\n",
    "\n",
    "# check processed files\n",
    "print('\\nFILE PROCESSED CHECK')\n",
    "if store.get('file_processed'):\n",
    "    for a_file in store['file_processed']:\n",
    "        if a_file['file_format']['file_format'] == '/file-formats/pairs/':\n",
    "            if not a_file.get('quality_metric'):\n",
    "                print(a_file['accession'], 'missing Pairsqc')\n",
    "        if not a_file.get('source_experiments'):\n",
    "            print(a_file['accession'], 'user submitted or produced by sbg runs')\n",
    "        if check_wfrs:\n",
    "            dw = delete_wfrs(a_file, my_auth, delete=delete_problematic, stash=stash)   \n",
    "\n",
    "# check wfrs\n",
    "print('\\nWFR CHECK')\n",
    "# list all wf types found\n",
    "print('  Following run types are found:')\n",
    "for wf in set([i['display_title'].split(' run')[0] for i in store.get('workflow_run_awsem')]):\n",
    "           print('    ' + wf)\n",
    "if store.get('workflow_run_awsem'):\n",
    "    for wfr in store['workflow_run_awsem']:\n",
    "        if wfr['run_status'] != 'complete':\n",
    "            print('problematic wfr', wfr['uuid'], wfr['run_status'])\n",
    "        \n",
    "# check for weird status\n",
    "print('\\nREPORT NUMBERS AND CHECK STATUS')\n",
    "for i in store:\n",
    "    print(i, len(store[i]))\n",
    "    weird = [[i, x['uuid'], x['status']] for x in store[i] if STATUS_LEVEL.get(x['status']) == 0]\n",
    "    if weird:\n",
    "        for case in weird:\n",
    "            print(case)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status\n",
    "print_each = False\n",
    "counter = 0\n",
    "for a_type in store:\n",
    "    total = len(store[a_type])\n",
    "    change = 0\n",
    "    matching = 0\n",
    "    unusual = 0\n",
    "    skipping = 0\n",
    "    for raw_data in store[a_type]:\n",
    "        if STATUS_LEVEL.get(raw_data['status']) > change_level:\n",
    "            skipping += 1\n",
    "            msg = ('{} {} ITEM HAS STATUS {} HIGHER THAN {} - SKIPPING'.format(a_type, raw_data['uuid'], raw_data['status'], change_status))\n",
    "        elif STATUS_LEVEL.get(raw_data['status']) == STATUS_LEVEL.get(change_status):\n",
    "            matching += 1\n",
    "            msg = ('MATCHING ACCESS STATUS', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        elif STATUS_LEVEL.get(raw_data['status']) == 0:\n",
    "            unusual += 1\n",
    "            msg = ('SKIP UNUSUAL STATUS  ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        else:\n",
    "            change += 1\n",
    "            msg = ('       CHANGE        ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        if print_each:\n",
    "            print(msg)\n",
    "    print('{:<25} Out of {t}, {r} skipped, {m} matching, {u} unusual, and {c} needs change'.format(a_type, t=total, r=skipping, m=matching, u=unusual, c=change))\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to patch the status, change action to True\n",
    "action = False\n",
    "\n",
    "reviewed = \"\"\n",
    "reviewed = input('Did another wrangler review this release? (y/n):')\n",
    "if reviewed != 'y':\n",
    "    raise KeyError('A key step is missing!')\n",
    "    \n",
    "print_each = False\n",
    "counter = 0\n",
    "for a_type in store:\n",
    "    total = len(store[a_type])\n",
    "    change = 0\n",
    "    matching = 0\n",
    "    unusual = 0\n",
    "    skipping = 0\n",
    "    for raw_data in store[a_type]:\n",
    "        if STATUS_LEVEL.get(raw_data['status']) > change_level:\n",
    "            skipping += 1\n",
    "            msg = ('{} {} ITEM HAS STATUS {} HIGHER THAN {} - SKIPPING'.format(a_type, raw_data['uuid'], raw_data['status'], change_status))\n",
    "        elif STATUS_LEVEL.get(raw_data['status']) == STATUS_LEVEL.get(change_status):\n",
    "            matching += 1\n",
    "            msg = ('MATCHING ACCESS STATUS', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        elif STATUS_LEVEL.get(raw_data['status']) == 0:\n",
    "            unusual += 1\n",
    "            msg = ('SKIP UNUSUAL STATUS  ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "        else:\n",
    "            change += 1\n",
    "            msg = ('       CHANGE        ', a_type, raw_data['uuid'], raw_data['status'])\n",
    "            if action:\n",
    "                patch_data = {'status': change_status}\n",
    "                if change_status == 'released' and a_type in ['publication']:\n",
    "                    patch_data = {'status': 'current'}\n",
    "                   \n",
    "                ff_utils.patch_metadata(patch_data, obj_id=raw_data['uuid'] ,key=my_auth) \n",
    "\n",
    "        if print_each:\n",
    "            print(msg)\n",
    "    print('{:<25} Out of {t}, {r} skipped, {m} matching, {u} unusual, and {c} UPDATED with status'.format(a_type, t=total, r=skipping, m=matching, u=unusual, c=change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
