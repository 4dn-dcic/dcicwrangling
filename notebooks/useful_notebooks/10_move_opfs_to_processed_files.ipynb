{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script will assume that the files you are moving around have the final status\n",
    "### If you add lower status files to processed_files field, permissions will not work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_key = get_key('')\n",
    "\n",
    "# Use title to map the correct opf items\n",
    "# move_titles = ['HiC Processing Pipeline - Preliminary Files']\n",
    "# move_titles = [\"Repli-Seq Pipeline - Preliminary Files\"]\n",
    "move_titles =  []\n",
    "\n",
    "sets_in_scope = [] # ['4DNACCCC', '4DNACCCCC']\n",
    "\n",
    "search_url  = '' # /search/?type=...\n",
    "\n",
    "#run_sets = ff_utils.search_metadata(set_url , key=my_key)\n",
    "if sets_in_scope:\n",
    "    run_sets = [ff_utils.get_metadata(i, my_key) for i in sets_in_scope]\n",
    "elif search_url:\n",
    "    run_sets = ff_utils.search_metadata(search_url, my_key)\n",
    "\n",
    "# if True do the action, if false just report\n",
    "action = False\n",
    "add_to_existing = True  # if True and there are already proceesed_files will add to them \n",
    "\n",
    "\n",
    "# move other processed files to processed files field\n",
    "def move_opc_to_pc(resp, move_titles, con_key):\n",
    "    opcolls = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files', [])\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # if processed_files field already has values, exit\n",
    "    if not add_to_existing and pc:\n",
    "        print('ERROR: There are files in processed_files field, expected empty')\n",
    "        return False\n",
    "    # see if there are other_processed_files to move\n",
    "    if opcolls:\n",
    "        move_items = []\n",
    "        for opc in opcolls:\n",
    "            if opc.get('title') in move_titles:\n",
    "                move_items.append(opc)\n",
    " \n",
    "        try:\n",
    "            assert len(move_items) == len(move_titles)\n",
    "        except:\n",
    "            print('ERROR: There are more than 1 opf set that has same title')\n",
    "            return False\n",
    "        try:\n",
    "            assert all([mi['type'] == 'preliminary' for mi in move_items])\n",
    "        except:\n",
    "            print('ERROR: OPF set status should be preliminary')\n",
    "            return False\n",
    "        new_pc = []\n",
    "        for mi in move_items:\n",
    "            new_pc.extend(mi.get('files', []))\n",
    "\n",
    "        new_opc = [i for i in opcolls if i['title'] not in move_titles]\n",
    "        # Time to patch\n",
    "        patch_data = {}\n",
    "        add_on = \"\"\n",
    "        #if there is something left in opc, patch it, if not delete field\n",
    "        if new_opc:\n",
    "            patch_data['other_processed_files'] = new_opc\n",
    "        else:\n",
    "            add_on = 'delete_fields=other_processed_files'\n",
    "        # patch with processed files \n",
    "        # add new pfs to existing pc list (which may be empty if no previous processed_files)\n",
    "        pc.extend(new_pc)\n",
    "        patch_data['processed_files'] = pc\n",
    "        # compare the status\n",
    "        set_exp_status = resp['status']\n",
    "        # import pdb; pdb.set_trace()\n",
    "        for a_file in pc:\n",
    "            file_resp = ff_utils.get_metadata(a_file, con_key)\n",
    "            file_status = file_resp['status']\n",
    "            if file_status != set_exp_status:\n",
    "                print('ERROR: File status does not match the set, please use release script to update status for all related items')\n",
    "                return False\n",
    "        if action:\n",
    "            res = ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "            print(len(new_pc), 'files moved to pf')\n",
    "            print(res.get('status'))\n",
    "        else:\n",
    "            print(len(new_pc), 'files will move to pf')\n",
    "            print(patch_data)\n",
    "            if add_on:\n",
    "                print(add_on)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "\n",
    "if not action:\n",
    "    print('\\nTHIS IS JUST A TEST\\n')   \n",
    "        \n",
    "print(len(run_sets), 'experiment sets in scope')\n",
    "        \n",
    "for a_set in run_sets:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_key, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_titles, my_key)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_key, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp, move_titles, my_key)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "    print()\n",
    "\n",
    "print(set_w_apf, 'sets are updated')\n",
    "print(exp_w_apf, 'exps are updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
