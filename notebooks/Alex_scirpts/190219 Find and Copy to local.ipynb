{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON https://data.4dnucleome.org \n",
      "\n",
      "static_section 1\n",
      "file_processed 23\n",
      "file_reference 3\n",
      "file_fastq 20\n",
      "experiment_set_replicate 1\n",
      "organism 1\n",
      "user 17\n",
      "antibody 4\n",
      "lab 9\n",
      "workflow_run_awsem 44\n",
      "software 12\n",
      "experiment_seq 10\n",
      "vendor 4\n",
      "ontology 2\n",
      "workflow 6\n",
      "individual_human 1\n",
      "protocol 2\n",
      "biosource 1\n",
      "ontology_term 10\n",
      "award 8\n",
      "biosample_cell_culture 2\n",
      "file_format 7\n",
      "quality_metric_chipseq 11\n",
      "biosample 2\n",
      "quality_metric_fastqc 16\n",
      "target 4\n",
      "221\n"
     ]
    }
   ],
   "source": [
    "### PLEASE COPY NOTEBOOKS TO YOUR FOLDERS TO PREVENT COMMIT CONFLICTS\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "import json\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_env = 'data'\n",
    "my_key = get_key('koray_data')\n",
    "schema_name = get_schema_names(my_key) \n",
    "print('WORKING ON', my_key['server'], '\\n')\n",
    "\n",
    "find_linked = ['11f207be-ebc4-4622-8b42-02e7841d17db']\n",
    "store, uuids = ff_utils.expand_es_metadata(find_linked, key = my_key, add_pc_wfr = True, ignore_field=['references', 'attachments'])\n",
    "\n",
    "for key in store:\n",
    "    print(key, len(store[key]))\n",
    "print(len([i['uuid'] for key in store for i in store[key]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "17 items exist on source\n",
      "0 items posted, 17 existing items skipped\n",
      "17 items will be patched in second round\n",
      "\n",
      "award\n",
      "8 items exist on source\n",
      "0 items posted, 8 existing items skipped\n",
      "8 items will be patched in second round\n",
      "\n",
      "lab\n",
      "9 items exist on source\n",
      "0 items posted, 9 existing items skipped\n",
      "9 items will be patched in second round\n",
      "\n",
      "static_section\n",
      "1 items exist on source\n",
      "0 items posted, 1 existing items skipped\n",
      "1 items will be patched in second round\n",
      "\n",
      "ontology\n",
      "2 items exist on source\n",
      "0 items posted, 2 existing items skipped\n",
      "2 items will be patched in second round\n",
      "\n",
      "ontology_term\n",
      "10 items exist on source\n",
      "0 items posted, 10 existing items skipped\n",
      "10 items will be patched in second round\n",
      "\n",
      "file_format\n",
      "7 items exist on source\n",
      "0 items posted, 7 existing items skipped\n",
      "7 items will be patched in second round\n",
      "\n",
      "organism\n",
      "1 items exist on source\n",
      "0 items posted, 1 existing items skipped\n",
      "1 items will be patched in second round\n",
      "\n",
      "target\n",
      "4 items exist on source\n",
      "0 items posted, 4 existing items skipped\n",
      "4 items will be patched in second round\n",
      "\n",
      "vendor\n",
      "4 items exist on source\n",
      "0 items posted, 4 existing items skipped\n",
      "4 items will be patched in second round\n",
      "\n",
      "protocol\n",
      "2 items exist on source\n",
      "0 items posted, 2 existing items skipped\n",
      "2 items will be patched in second round\n",
      "\n",
      "biosample_cell_culture\n",
      "2 items exist on source\n",
      "0 items posted, 2 existing items skipped\n",
      "2 items will be patched in second round\n",
      "\n",
      "individual_human\n",
      "1 items exist on source\n",
      "0 items posted, 1 existing items skipped\n",
      "1 items will be patched in second round\n",
      "\n",
      "biosource\n",
      "1 items exist on source\n",
      "0 items posted, 1 existing items skipped\n",
      "1 items will be patched in second round\n",
      "\n",
      "antibody\n",
      "4 items exist on source\n",
      "0 items posted, 4 existing items skipped\n",
      "4 items will be patched in second round\n",
      "\n",
      "biosample\n",
      "2 items exist on source\n",
      "0 items posted, 2 existing items skipped\n",
      "2 items will be patched in second round\n",
      "\n",
      "quality_metric_fastqc\n",
      "16 items exist on source\n",
      "0 items posted, 16 existing items skipped\n",
      "16 items will be patched in second round\n",
      "\n",
      "quality_metric_chipseq\n",
      "11 items exist on source\n",
      "0 items posted, 11 existing items skipped\n",
      "11 items will be patched in second round\n",
      "\n",
      "file_fastq\n",
      "20 items exist on source\n",
      "0 items posted, 20 existing items skipped\n",
      "20 items will be patched in second round\n",
      "\n",
      "file_processed\n",
      "23 items exist on source\n",
      "0 items posted, 23 existing items skipped\n",
      "23 items will be patched in second round\n",
      "\n",
      "file_reference\n",
      "3 items exist on source\n",
      "0 items posted, 3 existing items skipped\n",
      "3 items will be patched in second round\n",
      "\n",
      "experiment_seq\n",
      "10 items exist on source\n",
      "0 items posted, 10 existing items skipped\n",
      "10 items will be patched in second round\n",
      "\n",
      "experiment_set_replicate\n",
      "1 items exist on source\n",
      "0 items posted, 1 existing items skipped\n",
      "1 items will be patched in second round\n",
      "\n",
      "software\n",
      "12 items exist on source\n",
      "0 items posted, 12 existing items skipped\n",
      "12 items will be patched in second round\n",
      "\n",
      "workflow\n",
      "6 items exist on source\n",
      "0 items posted, 6 existing items skipped\n",
      "6 items will be patched in second round\n",
      "\n",
      "workflow_run_awsem\n",
      "44 items exist on source\n",
      "0 items posted, 44 existing items skipped\n",
      "44 items will be patched in second round\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### This part should only run once!\n",
    "\n",
    "transfer_env = 'local'\n",
    "transfer_key = get_key('local')\n",
    "\n",
    "#### This part should only run once!\n",
    "\n",
    "# if the item exist in the target, should it overwrite it (will include user/award etc)\n",
    "overwrite_existing = True\n",
    "\n",
    "# reverse lookup dictionary for schema names\n",
    "rev_schema_name = {}\n",
    "for key, name in schema_name.items():\n",
    "    rev_schema_name[name] = schema_name[key]\n",
    "\n",
    "my_types = [i for i in ORDER if i in store.keys()]\n",
    "\n",
    "second_round_items = {}\n",
    "\n",
    "# Round I - only put the required - skip if exists already\n",
    "for a_type in my_types:\n",
    "    print(a_type)\n",
    "    obj_type = rev_schema_name[a_type]\n",
    "    # find required field\n",
    "    schema_info = ff_utils.get_metadata('/profiles/{}.json'.format(a_type), key=transfer_key)\n",
    "    req_fields = schema_info['required']\n",
    "    ids = schema_info['identifyingProperties']\n",
    "    first_fields = list(set(req_fields+ids))\n",
    "    remove_existing_items = []\n",
    "    \n",
    "    print(len(store[a_type]), 'items exist on source')\n",
    "    posted = 0\n",
    "    skip_exist = 0\n",
    "    for an_item in store[a_type]:\n",
    "        exists = False\n",
    "        try:\n",
    "            # TODO check with all identifiers\n",
    "            existing = ff_utils.get_metadata(an_item['uuid'], key=transfer_key)\n",
    "            exists = True\n",
    "        except:\n",
    "            exists = False\n",
    "        # skip the items that exists, if overwrite is not allowed, they them out from patch list\n",
    "        if exists and existing:\n",
    "            skip_exist += 1\n",
    "            if not overwrite_existing:\n",
    "                remove_existing_items.append(an_item['uuid'])\n",
    "            # print(\"{} {} can not post existing item\".format(obj_type, an_item['uuid']))\n",
    "            continue\n",
    "        posted += 1\n",
    "        post_first = {key:value for (key,value) in an_item.items() if key in first_fields}\n",
    "        ff_utils.post_metadata(post_first, obj_type, key = transfer_key)\n",
    "   \n",
    "    second_round_items[a_type] = [i for i in store[a_type] if i['uuid'] not in remove_existing_items]\n",
    "    print(posted, 'items posted,', skip_exist, 'existing items skipped')\n",
    "    print(len(second_round_items[a_type]), 'items will be patched in second round')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user - patched\n",
      "award - patched\n",
      "lab - patched\n",
      "static_section - patched\n",
      "ontology - patched\n",
      "ontology_term - patched\n",
      "file_format - patched\n",
      "organism - patched\n",
      "target - patched\n",
      "vendor - patched\n",
      "protocol - patched\n",
      "biosample_cell_culture - patched\n",
      "individual_human - patched\n",
      "biosource - patched\n",
      "antibody - patched\n",
      "biosample - patched\n",
      "quality_metric_fastqc - patched\n",
      "quality_metric_chipseq - patched\n",
      "file_fastq - patched\n",
      "file_processed - patched\n",
      "file_reference - patched\n",
      "experiment_seq - patched\n",
      "experiment_set_replicate - patched\n",
      "software - patched\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Bad status code for PATCH request for http://localhost:8000/1f04547b-7d26-43a4-888d-2d8a4595f513: 422. Reason: {'code': 422, 'status': 'error', 'description': 'Failed validation', 'errors': [{'name': ['schema_version'], 'location': 'body', 'description': \"request method 'PATCH' is not one of \"}, {'name': ['category'], 'location': 'body', 'description': \"'Other' is not of type 'array'\"}, {'name': [], 'location': 'body', 'description': \"Additional properties are not allowed ('data_types', 'workflow_diagram', 'workflow_type' were unexpected)\"}], 'title': 'Unprocessable Entity', '@type': ['ValidationFailure', 'Error']}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e4daee7a7588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'extra_files'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0man_item\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0man_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extra_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mff_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0man_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0man_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'- patched'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mpatch_metadata\u001b[0;34m(patch_item, obj_id, key, ff_env, add_on)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# format item to json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mpatch_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthorized_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PATCH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_response_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mauthorized_request\u001b[0;34m(url, auth, ff_env, verb, retry_fxn, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mretry_fxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_request_with_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# use the given retry function. MUST TAKE THESE PARAMS!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mretry_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_verb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mstandard_request_with_retries\u001b[0;34m(request_fxn, url, auth, verb, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfinal_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Bad status code for PATCH request for http://localhost:8000/1f04547b-7d26-43a4-888d-2d8a4595f513: 422. Reason: {'code': 422, 'status': 'error', 'description': 'Failed validation', 'errors': [{'name': ['schema_version'], 'location': 'body', 'description': \"request method 'PATCH' is not one of \"}, {'name': ['category'], 'location': 'body', 'description': \"'Other' is not of type 'array'\"}, {'name': [], 'location': 'body', 'description': \"Additional properties are not allowed ('data_types', 'workflow_diagram', 'workflow_type' were unexpected)\"}], 'title': 'Unprocessable Entity', '@type': ['ValidationFailure', 'Error']}"
     ]
    }
   ],
   "source": [
    "# Round II - patch the rest of the metadata\n",
    "for a_type in my_types:\n",
    "    obj_type = rev_schema_name[a_type]\n",
    "    if not second_round_items[a_type]:\n",
    "        print(a_type, '- no items to patch')\n",
    "        continue \n",
    "    for an_item in second_round_items[a_type]:\n",
    "        if a_type == 'file_fastq':\n",
    "            if 'extra_files' in an_item:\n",
    "                del an_item['extra_files']\n",
    "        ff_utils.patch_metadata(an_item, obj_id = an_item['uuid'], key = transfer_key)\n",
    "    print(a_type, '- patched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
