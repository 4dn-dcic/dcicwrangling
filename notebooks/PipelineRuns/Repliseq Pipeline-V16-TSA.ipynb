{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 total number of sets\n",
      "0 sets completed\n"
     ]
    }
   ],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# url for repliseq exps\n",
    "exp_types = ['TSA-seq']\n",
    "set_url = '/search/?'+'&'.join(['experiments_in_set.experiment_type='+i for i in exp_types])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=pre-release&status=released&status=released%20to%20project'\n",
    "run_sets = ff_utils.search_metadata(set_url ,key=my_auth)\n",
    "\n",
    "\n",
    "all_sets = len(run_sets)\n",
    "print(str(all_sets)+' total number of sets')\n",
    "\n",
    "run_sets = [i for i in run_sets if \"RepliSeq_Pipeline_v13.1_step1\"  not in i.get('completed_processes', [])]\n",
    "run_sets = [i for i in run_sets if \"RepliSeq_Pipeline_v14_step1\"  not in i.get('completed_processes', [])]\n",
    "run_sets = [i for i in run_sets if \"RepliSeq_Pipeline_v16_step1\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "print(str(all_sets-len(run_sets))+ ' sets completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of Input for RNA Pol II TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of RNA Pol II TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for No1 control for RNA Pol II TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of No1 control for RNA Pol II TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for LaminB TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of LaminB TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for No1 control for LaminB TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of No1 control for LaminB TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for LaminA/C TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of LaminA/C TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for No1 control for LaminA/C TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of No1 control for LaminA/C TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for No1 control for LaminA/C TSA-seq version 1  Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Replicates of No1 control for LaminA/C TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Set of Input for pSC35 TSA-seq version 1  Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Replicates of pSC35 TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Set of Input for No1 Control for pSC35 TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Replicates of No1 Control for pSC35 TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Set of Input for SON Ab2 TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of SON Ab2 TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for SON TSA-seq version 1  Reaction Condition 3 10 minute Reaction on K562 cells\n",
      "Replicates of SON TSA-seq version 1 Reaction Condition 3 10 minute Reaction on K562 cells\n",
      "Set of Input for SON TSA-seq version 1  Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Replicates of SON TSA-seq version 1 Reaction Condition 2 10 minute Reaction on K562 cells\n",
      "Set of Input for SON TSA-seq version 1  Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Replicates of SON TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Set of Input for No1 Control for SON TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n",
      "Replicates of No1 Control for SON TSA-seq version 1 Reaction Condition 1 10 minute Reaction on K562 cells\n"
     ]
    }
   ],
   "source": [
    "for i in run_sets:\n",
    "    print(i['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 4DNESURW4RWH None human\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:repliseq-parta_4DNFINV7FHNP' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4DNEXAPYJ8TG has missing Part1 runs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:repliseq-parta_4DNFI7GP3UNJ' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4DNEXI3XYU13 has missing Part1 runs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "add_pc = False\n",
    "add_tag = False\n",
    "add_wfr = True\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for a_set in [run_sets[1]]: \n",
    "    counter += 1\n",
    "\n",
    "    \n",
    "    print()\n",
    "    # run in single mode\n",
    "    paired = \"\"\n",
    "    try:\n",
    "        fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size, lab = find_pairs(a_set, my_env, lookfor = 'single')\n",
    "        paired = 'No'\n",
    "    # run in paired mode\n",
    "    except:\n",
    "        fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size, lab = find_pairs(a_set, my_env)\n",
    "        paired = 'Yes'\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print(counter, a_set['accession'], organism, enzyme, 'skipping set with not chrsize/bwa index')\n",
    "        continue  \n",
    "    print(counter, a_set['accession'], enzyme, organism)      \n",
    "    # cycle through the experiments\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq files')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        # part2 = 'done'\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            if paired == 'No':\n",
    "                pair_resp = ff_utils.get_metadata(pair, key=my_auth)\n",
    "                report = get_wfr_out(pair, 'repliseq-parta', my_auth, ['v13.1', 'v14', 'v16'])\n",
    "            if paired == 'Yes':\n",
    "                pair_resp = ff_utils.get_metadata(pair[0], key=my_auth)\n",
    "                report = get_wfr_out(pair[0], 'repliseq-parta', my_auth, ['v13.1', 'v14', 'v16'])\n",
    "                \n",
    "            attributions = get_attribution(pair_resp)\n",
    "            # if run is not successful\n",
    "            if report['status'].startswith('no'):\n",
    "                part1 = 'not done'\n",
    "                if add_wfr:\n",
    "                    if paired == 'Yes':\n",
    "                        inp_f = {'fastq':pair[0], 'fastq2': pair[1], 'chromsizes':chrsize_ref, 'bwaIndex':bwa_ref}\n",
    "                        name_tag = pair[0].split('/')[2] + '_' + pair[1].split('/')[2]\n",
    "                    if paired == 'No':\n",
    "                        inp_f = {'fastq':pair, 'chromsizes':chrsize_ref, 'bwaIndex':bwa_ref}\n",
    "                        name_tag = pair.split('/')[2]\n",
    "                        \n",
    "                        # run trsa on winsize 50K\n",
    "                        params = {'winsize':50000}\n",
    "                    run_missing_wfr(step_settings('repliseq-parta', organism, attributions, params=params), inp_f, name_tag,my_auth, my_env)\n",
    "            elif report['status'] == 'running':\n",
    "                part1 = 'still running'\n",
    "                print('part1 still running')\n",
    "            # if successful\n",
    "            else:\n",
    "                assert report['status'] == 'complete'\n",
    "                if add_pc:\n",
    "                    # TODO check if the files already in processed files field.\n",
    "                    # don't do it if they are already carried there.\n",
    "                    print('Adding files to preliminary tab')\n",
    "                    add_preliminary_processed_files(exp,\n",
    "                                                    [report['bam'], report['bg']],\n",
    "                                                    my_auth,\n",
    "                                                    run_type='repliseq')\n",
    "                if add_tag:\n",
    "                    # get version\n",
    "                    res_file_resp = ff_utils.get_metadata(report['bam'], my_auth)\n",
    "                    producing_wfr = res_file_resp['workflow_run_outputs'][0]['display_title']\n",
    "                    wfr_type, time_info = producing_wfr.split(' run ')\n",
    "                    wfr_type_base, wfr_version = wfr_type.strip().split(' ')\n",
    "                    assert wfr_version in ['v13.1', 'v14', 'v16']\n",
    "                    tag = 'RepliSeq_Pipeline_{}_step1'.format(wfr_version)\n",
    "                    ff_utils.patch_metadata({\"completed_processes\":[tag]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "                     \n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print(exp, 'has missing Part1 runs')\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print(exp, 'part1 complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4 experiment sets in scope\n",
      "1 4DNESHLNICHQ\n",
      "there are no other processed files, skipping\n",
      "There are files in processed_files field, expected empty\n",
      "4DNEXNZUFKAN files will move\n",
      "4DNEXNZUFKAN moved to pc\n",
      "\n",
      "2 4DNESC15J6HU\n",
      "there are no other processed files, skipping\n",
      "4DNEX56YP5JV files will move\n",
      "4DNEX56YP5JV moved to pc\n",
      "4DNEXC78ZQ5W files will move\n",
      "4DNEXC78ZQ5W moved to pc\n",
      "\n",
      "3 4DNES4WLR8MV\n",
      "there are no other processed files, skipping\n",
      "4DNEXJHA5PYA files will move\n",
      "4DNEXJHA5PYA moved to pc\n",
      "4DNEX17H5YRC files will move\n",
      "4DNEX17H5YRC moved to pc\n",
      "\n",
      "4 4DNESGWKYYWO\n",
      "there are no other processed files, skipping\n",
      "4DNEX3RCXAVO files will move\n",
      "4DNEX3RCXAVO moved to pc\n",
      "4DNEX5WSFYYF files will move\n",
      "4DNEX5WSFYYF moved to pc\n",
      "\n",
      "0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "action = True\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_key = get_key('koray_data')\n",
    "# which sets to move data\n",
    "set_url = '/search/?completed_processes=RepliSeq_Pipeline_V16_step1%27&completed_processes=RepliSeq_Pipeline_v16_step1&experiments_in_set.experiment_type=Repli-seq&limit=all&type=ExperimentSetReplicate'\n",
    "run_sets = ff_utils.search_metadata(set_url, my_key)\n",
    "print(len(run_sets))\n",
    "# move other processed files to processed files field\n",
    "def move_opc_to_pc(resp, move_title, con_key):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        print('There are files in processed_files field, expected empty')\n",
    "        return False\n",
    "    # are there files in opc\n",
    "    if not opc:\n",
    "        print('there are no other processed files, skipping')\n",
    "        return False\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action: \n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "#move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "move_title = \"Repli-Seq Pipeline - Preliminary Files\"\n",
    "\n",
    "print(len(run_sets), 'experiment sets in scope')\n",
    "for a_set in run_sets:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_key, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_key)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_key, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_key)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repliseq pipeline part 1 also produces a qc object on the files.\n",
    "# Change their status to the ones of the files (if the files are in processed files field)\n",
    "\n",
    "# set_url = '/search/?experiments_in_set.experiment_type=Repli-seq&type=ExperimentSetReplicate&limit=all'\n",
    "\n",
    "# set_url = '/search/?type=ExperimentSetReplicate&experiments_in_set.experiment_type=Repli-seq&experiments_in_set.biosample.biosource.individual.organism.name=mouse'\n",
    "\n",
    "\n",
    "# run_sets = ff_utils.search_metadata(set_url , key=my_key)\n",
    "\n",
    "def release_qc(file_id, con_key):\n",
    "    file_resp = ff_utils.get_metadata(file_id, key=con_key, add_on = 'frame=raw')\n",
    "    file_status = file_resp['status']\n",
    "    # skip if file is not released/archived\n",
    "    if file_status not in ['released', 'released to project', 'archived']:\n",
    "        return\n",
    "    qc = file_resp.get('quality_metric')\n",
    "    if qc:\n",
    "        qc_resp = ff_utils.get_metadata(qc, key=con_key)\n",
    "        qc_status = qc_resp['status']\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    if qc_status != file_status:\n",
    "        ff_utils.patch_metadata({'status': file_status}, obj_id=qc, key=con_key)\n",
    "        print(qc, 'qc object updated with status', file_status)\n",
    "        return True\n",
    "    \n",
    "print(len(run_sets), 'experiment sets in scope')\n",
    "for a_set in run_sets:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_key, add_on='frame=raw')\n",
    "    if set_resp.get('processed_files'):\n",
    "        for a_pf in set_resp['processed_files']:\n",
    "            release_qc(a_pf, my_key)\n",
    "            \n",
    "    exps = set_resp['experiments_in_set']\n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_key, add_on='frame=raw')\n",
    "        if exp_resp.get('processed_files'):\n",
    "            for a_pf_e in exp_resp['processed_files']:\n",
    "                release_qc(a_pf_e, my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
