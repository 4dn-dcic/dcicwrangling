{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dcicutils import s3Utils\n",
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "my_s3_util = s3Utils(env=my_env)\n",
    "raw_bucket = my_s3_util.raw_file_bucket\n",
    "out_bucket = my_s3_util.outfile_bucket\n",
    "\n",
    "file_url = '/search/?type=FileFastq&status=uploading&status=upload failed&limit=all'\n",
    "file_url = '/search/?type=FileReference&status=uploading&status=upload failed&limit=all'\n",
    "\n",
    "file_url = '/search/?status=uploading&type=FileProcessed'\n",
    "all_files = ff_utils.search_metadata(file_url, key=my_auth)\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wanna run md5 if missing? (md5/none)md5\n",
      "object 995ec5b2-536e-45c5-8449-f56615f91697/4DNFI8IETQEJ.bed.gz not found on bucket elasticbeanstalk-fourfront-webprod-wfoutput\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFI8IETQEJ cremins-lab:Communities_genomewideHFFc68kbhg38merge_adjust2_PCA_0.25v2_2 does not have a file in S3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_md5 = input(\"Do you wanna run md5 if missing? (md5/none)\")\n",
    "\n",
    "printn = 0\n",
    "counter = 0\n",
    "for a_file in all_files:  \n",
    "    counter += 1\n",
    "    # check for deleted or weird cases\n",
    "    try:\n",
    "        if a_file['status'] == 'deleted':\n",
    "            print(\"Deleted File\", a_file)\n",
    "            continue\n",
    "    except:\n",
    "        print(a_file)\n",
    "        break\n",
    "        \n",
    "    if counter-printn > 100:\n",
    "        print(counter)\n",
    "        printn = counter\n",
    "\n",
    "    if 'FileProcessed' in a_file['@type']:\n",
    "            my_bucket = out_bucket\n",
    "    else:  # covers cases of FileFastq, FileReference, FileMicroscopy\n",
    "            my_bucket = raw_bucket       \n",
    " \n",
    "    # check if file is in s3\n",
    "    head_info = my_s3_util.does_key_exist(a_file['upload_key'], my_bucket)\n",
    "    if not head_info:\n",
    "        print(a_file['accession'], a_file.get('aliases')[0], \"does not have a file in S3\")\n",
    "        print()\n",
    "        continue\n",
    "        \n",
    "    file_id = a_file['accession']\n",
    "    status = a_file.get('status')\n",
    "    attributions = get_attribution(a_file)\n",
    "    \n",
    "    # is there md5sum for gzip\n",
    "    if not a_file.get('md5sum'):\n",
    "        print(file_id,\"does not have the md5sum calculated during upload\")\n",
    "    # Check workflows\n",
    "    md5_status = 'did_not_run'\n",
    "    \n",
    "    # Assumes workflow_runs come in time ordered list, and grabs the last ones for each wf run\n",
    "    md5_report = get_wfr_out(a_file['uuid'], \"md5\", my_auth, md_qc = True, run=1)\n",
    "    \n",
    "    if md5_report['status'] == 'running':\n",
    "        print(file_id, 'still running')\n",
    "        continue \n",
    "\n",
    "    if status in [\"uploading\", \"upload failed\"] and md5_report['status'] != 'complete':\n",
    "        # if not, shall we run it?\n",
    "        if run_md5 == 'md5':\n",
    "            print('md5 running for', file_id)\n",
    "            inp_f = {'input_file':a_file['@id']}\n",
    "            run_missing_wfr(step_settings('md5', 'no_organism', attributions), inp_f, file_id, my_auth, my_env, tag=\"\")\n",
    "            print()\n",
    "        # user does not want it to be run, so just report\n",
    "        else:\n",
    "            print('md5 run missing for', file_id)\n",
    "\n",
    "    elif status in [\"uploading\", \"upload failed\"] and md5_status == 'complete':\n",
    "        print(\"ERROR:\",file_id ,\"There is a successful md5 run but status not switched\")\n",
    "        # if not, shall we run it?\n",
    "        if run_md5 == 'md5':\n",
    "            print('md5 running for', file_id)\n",
    "            inp_f = {'input_file':a_file['@id']}\n",
    "            run_missing_wfr(step_settings('md5', 'no_organism', attributions), inp_f, file_id, my_auth, my_env, tag=\"\")\n",
    "            print()\n",
    "        \n",
    "    elif md5_status != 'complete':\n",
    "        if a_file.get('content_md5sum'):\n",
    "            print('md5run not linked to file')\n",
    "            if run_md5 == 'md5':\n",
    "                print('md5 running for', file_id)\n",
    "                inp_f = {'input_file':a_file['@id']}\n",
    "                run_missing_wfr(step_settings('md5', 'no_organism', attributions), inp_f, file_id, my_auth, my_env, tag=\"\")\n",
    "                print()\n",
    "        else:\n",
    "            print(file_id, status, 'switched status file does not have md5 run or content_md5sum')\n",
    "            # if not, shall we run it?\n",
    "            if run_md5 == 'md5':\n",
    "                print('md5 running for', file_id)\n",
    "                inp_f = {'input_file':a_file['@id']}\n",
    "                run_missing_wfr(step_settings('md5', 'no_organism', attributions), inp_f, file_id, my_auth, my_env, tag=\"\")\n",
    "                print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if md5 runs are in sync with file status\n",
    "import time\n",
    "from dcicutils import s3Utils\n",
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_env = 'data'\n",
    "my_key = get_key('koray_data')\n",
    "\n",
    "\n",
    "md5_runs = '/search/?run_status=complete&status=in+review+by+lab&type=WorkflowRunAwsem&workflow.title=md5'\n",
    "md5_hits = ff_utils.search_metadata(md5_runs , key=my_key)\n",
    "\n",
    "print(len(md5_hits))\n",
    "\n",
    "prob = 0\n",
    "for a_run in md5_hits:\n",
    "    f_status = a_run['input_files'][0]['value']['status']\n",
    "    if f_status != a_run['status']:\n",
    "        print(f_status, a_run['status'])\n",
    "        prob += 1\n",
    "    \n",
    "print(prob)\n",
    "\n",
    "\n",
    "patch = True\n",
    "need_patch = 0\n",
    "need_patch_run = 0\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0\n",
    "for a_run in md5_hits:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print()\n",
    "        print(counter)\n",
    "    f_status = a_run['input_files'][0]['value']['status']\n",
    "    if f_status in ['archived', 'released', 'released to project']:\n",
    "        print(f_status, a_run['status'])\n",
    "        ff_utils.patch_metadata({\"status\": f_status}, obj_id=a_run['uuid'] ,key=my_key)\n",
    "print(counter)\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
