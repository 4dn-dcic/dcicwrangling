{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 total number of sets\n",
      "0 sets completed\n",
      "4 ready for processing\n"
     ]
    }
   ],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# all usable env names\n",
    "all_envs = ['data', 'staging', 'fourfront-webdev', 'fourfront-mastertest', 'fourfront-hotseat']\n",
    "# #get admin key from s3\n",
    "# my_env = 'fourfront-webdev'\n",
    "# my_auth = ff_utils.get_authentication_with_server({}, ff_env = my_env)\n",
    "\n",
    "\n",
    "# CHIP RUNS\n",
    "set_url = '/search/?experiments_in_set.experiment_type=ChIP-seq&type=ExperimentSetReplicate&limit=all&status=pre-release&status=released&status=released%20to%20project'\n",
    "\n",
    "set_url = '/search/?award.project=4DN&experiments_in_set.experiment_type=ChIP-seq&experimentset_type=replicate&lab.display_title=Feng+Yue+Lab%2C+PSU&type=ExperimentSetReplicate&status=pre-release&status=released&status=released%20to%20project'\n",
    "# CUT&RUN RUNS\n",
    "# set_url = '/search/?experiments_in_set.experiment_type=CUT%26RUN&type=ExperimentSetReplicate&limit=all&status=pre-release&status=released&status=released%20to%20project'\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "run_sets = [i for i in all_sets if \"ENCODE_ChIP_Pipeline_1.1.1\"  not in i.get('completed_processes', [])]\n",
    "print(len(all_sets), 'total number of sets')\n",
    "print(len(all_sets)-len(run_sets), 'sets completed')\n",
    "print(len(run_sets), 'ready for processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4DNESYMCM19N human  True \n",
      "4DNEXW3RWUAH status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXMOG6F4W status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "\n",
      "4DNESSNWXHXK human  False 4DNESYMCM19N\n",
      "4DNEXYQ6TC5B status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXV57K68O status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "set ready for part2\n",
      "step2 is complete\n",
      "https://data.4dnucleome.org//files-processed/4DNFINRI6WOL/\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "\n",
      "4DNESWX32ZCG human  False 4DNESYMCM19N\n",
      "4DNEXYOW7TCB status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXBMMVBQW status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "set ready for part2\n",
      "step2 is complete\n",
      "https://data.4dnucleome.org//files-processed/4DNFIVYWZE1W/\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "\n",
      "4DNES9WNNK52 human  False 4DNESYMCM19N\n",
      "4DNEX1UOUWPM status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXD6Z69AC status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "set ready for part2\n",
      "step2 is complete\n",
      "https://data.4dnucleome.org//files-processed/4DNFI3WBAYI7/\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n"
     ]
    }
   ],
   "source": [
    "run_wfr = False\n",
    "add_pc = True\n",
    "add_tag = True\n",
    "\n",
    "for a_set in run_sets:      \n",
    "    print()\n",
    "    print(a_set['accession'], end = \" \")\n",
    "    counter += 1\n",
    "    # some feature to extract from each set\n",
    "    control = \"\"  # True or False (True if set in scope is control)\n",
    "    control_set = \"\"  # None (if no control exp is set), or the control experiment for the one in scope\n",
    "    target_type = \"\" # Histone or TF (or None for control)\n",
    "    paired = \"\" # single or paired\n",
    "    organism = \"\"\n",
    "    \n",
    "    # pass attributions to new objects\n",
    "    attributions = None\n",
    "    \n",
    "    replicate_exps = a_set['replicate_exps']\n",
    "    replicate_exps = sorted(replicate_exps, key = lambda x: [x['bio_rep_no'], x['tec_rep_no']])\n",
    "\n",
    "    # get organism, target and control from the first replicate\n",
    "    f_exp = replicate_exps[0]['replicate_exp']['uuid']\n",
    "    f_exp_resp = ff_utils.get_metadata(f_exp, key = my_auth)\n",
    "    control, control_set, target_type, organism = get_chip_info(f_exp_resp, my_auth)\n",
    "           \n",
    "    print(organism, paired, control, control_set)  \n",
    "\n",
    "    if organism not in ['mouse', 'human']:\n",
    "        print('orgamism not ready', organism)\n",
    "        continue\n",
    "\n",
    "    attributions = get_attribution(ff_utils.get_metadata(f_exp_resp['files'][0]['uuid'], key = my_auth))\n",
    "    \n",
    "    if not control:\n",
    "        if not target_type:\n",
    "            print('set is not control, but missing target type, skipping')\n",
    "            continue\n",
    "\n",
    "    ta = []\n",
    "    taxcor = []\n",
    "    # check for step1, and start if missing\n",
    "    step1_status = 'Done'\n",
    "\n",
    "    for an_exp in replicate_exps:\n",
    "        exp_id = an_exp['replicate_exp']['accession']\n",
    "        exp_resp = ff_utils.get_metadata(exp_id, my_auth)\n",
    "        \n",
    "        run_name = exp_resp['accession']\n",
    "        print(run_name, end = ' status: ')\n",
    "        exp_files, exp_obj, paired = get_chip_files(exp_resp, my_auth)\n",
    "        if len(exp_files) > 2:\n",
    "            print('WARNING More then 2 seq reps, Soo needs to have a look before we can proceed')\n",
    "            print('SKIPPING')\n",
    "            continue\n",
    "            \n",
    "        if control:\n",
    "            step1_result = get_wfr_out_file(exp_files[0][0], 'encode-chipseq-aln-ctl 1.1.1', my_auth)\n",
    "            print(step1_result['status'])\n",
    "            if step1_result['status'] == 'complete':\n",
    "                if add_pc:\n",
    "                    add_preliminary_processed_files(exp_id, [step1_result['chip.first_ta_ctl']], my_auth, run_type = 'chip')\n",
    "            elif step1_result['status'] == 'running':\n",
    "                step1_status = 'Incomplete'\n",
    "            else:\n",
    "                step1_status = 'Incomplete'                \n",
    "                if run_wfr:\n",
    "                    print('starting run')\n",
    "                    run_missing_chip1(control, step_settings('encode-chipseq-aln-ctl', organism, attributions), \n",
    "                                      organism, 'tf', paired, [exp_files], [exp_obj], my_env, my_auth, run_name)\n",
    "        else:\n",
    "            step1_result = get_wfr_out_file(exp_files[0][0], 'encode-chipseq-aln-chip 1.1.1', my_auth) \n",
    "            print(step1_result['status'])\n",
    "            if step1_result['status'] == 'complete':\n",
    "                ta.append(step1_result['chip.first_ta'])\n",
    "                taxcor.append(step1_result['chip.first_ta_xcor'])\n",
    "                if add_pc:\n",
    "                    add_preliminary_processed_files(exp_id, [step1_result['chip.first_ta']], my_auth, run_type = 'chip')\n",
    "            elif step1_result['status'] == 'running':\n",
    "                step1_status = 'Incomplete'\n",
    "            else:\n",
    "                step1_status = 'Incomplete'\n",
    "                if run_wfr:\n",
    "                    print('starting run')\n",
    "                    run_missing_chip1(control, step_settings('encode-chipseq-aln-chip', organism, attributions), \n",
    "                                      organism, target_type, paired, [exp_files], [exp_obj], my_env, my_auth, run_name)\n",
    "\n",
    "                    \n",
    "    if step1_status != 'Done':\n",
    "        continue\n",
    "        \n",
    "    # add pc files and tag for control\n",
    "    if control:\n",
    "        #add competed flag to set\n",
    "        if add_tag:\n",
    "            ff_utils.patch_metadata({\"completed_processes\":[\"ENCODE_ChIP_Pipeline_1.1.1\"]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "        # add processed files to set\n",
    "        continue\n",
    "    \n",
    "    print('set ready for part2')\n",
    "    # check if control is ready\n",
    "    ta_cnt=[]\n",
    "    control_ready = True\n",
    "    cont_set_info = ff_utils.get_metadata(control_set, key=my_auth)\n",
    "    replicate_exps_cnt = cont_set_info['replicate_exps']\n",
    "    replicate_exps_cnt = sorted(replicate_exps_cnt, key = lambda x: [x['bio_rep_no'], x['tec_rep_no']])\n",
    "    \n",
    "    for an_exp_cnt in replicate_exps_cnt:\n",
    "        exp_cnt_id = an_exp_cnt['replicate_exp']['accession']\n",
    "        exp_cnt_resp = ff_utils.get_metadata(exp_cnt_id, my_auth)\n",
    "        files_cnt, obj_key_cnt, paired_cnt = get_chip_files(exp_cnt_resp, my_auth)\n",
    "        step1_result = get_wfr_out_file(files_cnt[0][0], 'encode-chipseq-aln-ctl 1.1.1', my_auth) \n",
    "        if step1_result['status'] == 'complete':\n",
    "            ta_cnt.append(step1_result['chip.first_ta_ctl'])\n",
    "        else:\n",
    "            control_ready = False\n",
    "            break\n",
    "\n",
    "    if not control_ready:\n",
    "        print('Control not ready for second step')\n",
    "        continue\n",
    "\n",
    "    if len(ta) > 2 or len(ta_cnt) > 2:\n",
    "        ta_2 = []\n",
    "        taxcor_2 = []\n",
    "#         print('skipping more then 2 exp set')\n",
    "#         continue\n",
    "        print('Experiment has more then 2 replicates, selecting best 2')\n",
    "        ta_2 = select_best_2(ta, my_auth)\n",
    "        # xcor does not have qc, use ta indexes to find the correct files\n",
    "        for ta_f in ta_2:\n",
    "            taxcor_2.append(taxcor[ta.index(ta_f)])\n",
    "        ta = ta_2\n",
    "        taxcor = taxcor_2\n",
    "        ta_cnt = select_best_2(ta_cnt, my_auth)\n",
    "             \n",
    "    if len(ta_cnt) != len(ta):\n",
    "        print('Control and experiment have diferent number of bio reps, skipping')\n",
    "        continue\n",
    "    \n",
    "    step2_result = get_wfr_out_file(ta[0], 'encode-chipseq-postaln 1.1.1', my_auth)\n",
    "    if step2_result['status'] == 'complete':\n",
    "        print('step2 is complete')\n",
    "        print('https://data.4dnucleome.org/' + step2_result['chip.sig_fc'])\n",
    "        if add_pc:\n",
    "            add_preliminary_processed_files(a_set['accession'], \n",
    "                                            [\n",
    "                                                step2_result['chip.optimal_peak'],\n",
    "                                                step2_result['chip.conservative_peak'],\n",
    "                                                step2_result['chip.sig_fc']\n",
    "                                            ], \n",
    "                                            my_auth, run_type = 'chip')\n",
    "        if add_tag:\n",
    "            ff_utils.patch_metadata({\"completed_processes\":[\"ENCODE_ChIP_Pipeline_1.1.1\"]}, obj_id=a_set['accession'] , key=my_auth)   \n",
    "    elif step2_result['status'] == 'running':\n",
    "        print('step2 is still running')\n",
    "    else:\n",
    "        step2_status = 'Incomplete' \n",
    "        print('missing step2')\n",
    "        if run_wfr:\n",
    "            print('starting run')\n",
    "            run_ids = {'run_name': a_set['accession'],\n",
    "                       \"desc\" : a_set.get('description', ''),\n",
    "                      }\n",
    "            run_missing_chip2(control_set, step_settings('encode-chipseq-postaln', organism, attributions), \n",
    "                              organism, target_type, paired, ta, taxcor, ta_cnt, my_env, my_auth, run_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "recipe_no = 1\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "action = False\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=released&status=released%20to%20project'\n",
    "\n",
    "print(set_url)\n",
    "set_url = '/search/?award.project=4DN&experimentset_type=replicate&lab.display_title=Chuck+Murry%2C+UW&status=pre-release&type=ExperimentSetReplicate'\n",
    "\n",
    "# exp\n",
    "# set_url = '/search/?'+ \\\n",
    "#           '&'.join(['experiment_type='+i for i in exp_type])+ \\\n",
    "#           '&type=Experiment&limit=all' + \\\n",
    "#           '&status=released&status=released%20to%20project'\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "\n",
    "ready_sets_1 = [i for i in all_sets if \"HiC_Pipeline_1.1.1\" in i.get('completed_processes', [])]\n",
    "print(len(ready_sets_1))\n",
    "ready_sets_2 = []\n",
    "for a_set in ready_sets_1:\n",
    "    if a_set.get('other_processed_files'):\n",
    "        print('a')\n",
    "        print(a_set['accession'])\n",
    "        if move_title in [i['title'] for i in a_set['other_processed_files']]:\n",
    "            print('b')\n",
    "            if a_set.get('processed_files'):\n",
    "                print('c')\n",
    "                print('WARN' ,a_set['accession'], 'has items in processed files, skipping ')\n",
    "                continue\n",
    "            else:\n",
    "                ready_sets_2.append(a_set)\n",
    "print(len(ready_sets_2), 'items are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move other processed files to processed files field\n",
    "action = True\n",
    "def move_opc_to_pc(resp, move_title, con_key):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        if opc:\n",
    "            print('There are files in processed_files field, expected empty', resp['accession'])\n",
    "            return False\n",
    "        else:\n",
    "            print('it is possible that move already happened, no opc but pc', resp['accession'])\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action:\n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "print(len(ready_sets_2), 'experiment sets in scope')\n",
    "for a_set in ready_sets_2:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_auth, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_auth)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_auth, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_auth)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4DNESYMCM19N human  True \n",
      "4DNEXW3RWUAH status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXMOG6F4W status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "\n",
      "4DNESSNWXHXK human  False 4DNESYMCM19N\n",
      "4DNEXYQ6TC5B status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXV57K68O status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "set ready for part2\n",
      "step2 is complete\n",
      "https://data.4dnucleome.org//files-processed/4DNFINRI6WOL/\n",
      "\n",
      "4DNESWX32ZCG human  False 4DNESYMCM19N\n",
      "4DNEXYOW7TCB status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXBMMVBQW status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "set ready for part2\n",
      "step2 is complete\n",
      "https://data.4dnucleome.org//files-processed/4DNFIVYWZE1W/\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "\n",
      "4DNES9WNNK52 human  False 4DNESYMCM19N\n",
      "4DNEX1UOUWPM status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXD6Z69AC status: complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "set ready for part2\n",
      "step2 is complete\n",
      "https://data.4dnucleome.org//files-processed/4DNFI3WBAYI7/\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
