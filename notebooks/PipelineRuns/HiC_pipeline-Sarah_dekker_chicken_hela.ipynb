{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# different types of exps use different steps at the last step(3).\n",
    "recipe = [\n",
    "    [['in%20situ%20Hi-C', 'dilution%20Hi-C'], 'hi-c-processing-pairs'],\n",
    "    [['micro-C',          'DNase%20Hi-C'],    'hi-c-processing-pairs-nore'],\n",
    "    [['capture%20Hi-C',   'PLAC-seq'],        'hi-c-processing-pairs-nonorm'],\n",
    "    [['CHIA-pet',         'TrAC-loop'],       'hi-c-processing-pairs-nore-nonorm'],\n",
    "    [['TCC'], 'hi-c-processing-pairs'],\n",
    "    \n",
    "]\n",
    "\n",
    "# To Do assign core 8 and more memory (\"instance_type\": \"c4.4xlarge\",) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/?type=ExperimentSetReplicate&experimentset_type=replicate&sort=experiments_in_set.experiment_type&publications_of_set.uuid=84fa5633-aac7-4cb3-b53b-0f0234ea06dd\n",
      "42 total number of sets\n",
      "20 sets completed\n",
      "1 sets skipped for small size\n",
      "21 ready for processing\n",
      "\n",
      "1 4DNESCR8WQLA HindIII chicken 20\n",
      "4DNEXTFG22TO part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXTFG22TO part2 complete\n",
      "4DNESCR8WQLA is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESCR8WQLAa4b8a7b8-7f73-474d-995f-42a5244a208d' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 4DNES3EAC1H8 HindIII chicken 40\n",
      "4DNEXLD3G1LS part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXLD3G1LS part2 complete\n",
      "4DNEXJRAMX4W part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXJRAMX4W part2 complete\n",
      "part3 still running\n",
      "\n",
      "3 4DNESXDOBP9L HindIII chicken 15\n",
      "4DNEXZ1XWPPX part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXZ1XWPPX part2 complete\n",
      "4DNESXDOBP9L is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESXDOBP9L9d5216e0-ff12-4192-9b77-2580a7f50f10' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 4DNESTBTENG2 HindIII chicken 32\n",
      "4DNEX18HYGLV part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX18HYGLV part2 complete\n",
      "4DNEXEILBWYP part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXEILBWYP part2 complete\n",
      "4DNESTBTENG2 is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESTBTENG2c3a11210-3a49-4998-b28d-3847b51295b5' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 4DNESE9ZKE6Z HindIII chicken 40\n",
      "4DNEXVXQTM1S part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXVXQTM1S part2 complete\n",
      "4DNEX3Z7WCZV part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX3Z7WCZV part2 complete\n",
      "part3 still running\n",
      "\n",
      "6 4DNESU9VIEWW HindIII chicken 14\n",
      "4DNEXQEQLXHG part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXQEQLXHG part2 complete\n",
      "4DNESU9VIEWW is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESU9VIEWW8e0a2ff5-06e4-4f07-9bdc-ea45ac4c1d89' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 4DNESNWWIFZU HindIII chicken 30\n",
      "4DNEX3PXTY7I part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX3PXTY7I part2 complete\n",
      "4DNESNWWIFZU is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESNWWIFZU9b5f018b-bc2f-4750-b63b-472f326a7a01' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 4DNESLU4EMPB HindIII chicken 15\n",
      "4DNEXA2ECOH3 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXA2ECOH3 part2 complete\n",
      "4DNESLU4EMPB is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESLU4EMPB646d1fc5-668d-4742-bda8-74ca1f812563' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9 4DNES81PRZLH HindIII chicken 40\n",
      "4DNEXVC56Y69 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXVC56Y69 part2 complete\n",
      "4DNEXEO8KJE3 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXEO8KJE3 part2 complete\n",
      "part3 still running\n",
      "\n",
      "10 4DNESIR416OW HindIII chicken 25\n",
      "4DNEXMF73UXS part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXMF73UXS part2 complete\n",
      "4DNESIR416OW part3 complete\n",
      "\n",
      "11 4DNESKM5UQ2L HindIII chicken 35\n",
      "4DNEXD6T8FIR part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXD6T8FIR part2 complete\n",
      "4DNEXSVIJRMI part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXSVIJRMI part2 complete\n",
      "part3 still running\n",
      "\n",
      "12 4DNES6FARLK8 HindIII chicken 26\n",
      "4DNEX61FZW4H part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX61FZW4H part2 complete\n",
      "4DNEXBJKTWVH part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXBJKTWVH part2 complete\n",
      "part3 still running\n",
      "\n",
      "13 4DNESYIMR82X HindIII chicken 37\n",
      "4DNEXMOSRYT5 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXMOSRYT5 part2 complete\n",
      "4DNEXOE3CU5G part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXOE3CU5G part2 complete\n",
      "4DNESYIMR82X is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESYIMR82Xa076026c-1ff1-4448-a676-b2a09c3141e7' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "14 4DNES9LEZXN7 HindIII chicken 42\n",
      "4DNEXJ6TU2BU part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXJ6TU2BU part2 complete\n",
      "4DNEXAP42UGL part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXAP42UGL part2 complete\n",
      "4DNES9LEZXN7 is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNES9LEZXN713ed9bb3-e43f-460f-8caa-0768c8246da2' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 4DNES57F5K1Y HindIII chicken 32\n",
      "4DNEX9OVHMNN part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX9OVHMNN part2 complete\n",
      "4DNEXXYDF2PV part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXXYDF2PV part2 complete\n",
      "part3 still running\n",
      "\n",
      "16 4DNES4RSKMSF HindIII chicken 40\n",
      "4DNEX35W18E3 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX35W18E3 part2 complete\n",
      "4DNEXRBHYJXN part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXRBHYJXN part2 complete\n",
      "part3 still running\n",
      "\n",
      "17 4DNES1MGX3LX HindIII chicken 27\n",
      "4DNEXVYW7AW4 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXVYW7AW4 part2 complete\n",
      "4DNEXFP1CL5Y part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXFP1CL5Y part2 complete\n",
      "part3 still running\n",
      "\n",
      "18 4DNES5GUEFXM HindIII chicken 15\n",
      "4DNEX8T4SM7Q part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEX8T4SM7Q part2 complete\n",
      "4DNES5GUEFXM is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNES5GUEFXM79e91f6b-b37d-4d48-9edb-9652faa04745' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "19 4DNESN22I1UM HindIII chicken 12\n",
      "4DNEXZTSXFT3 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXZTSXFT3 part2 complete\n",
      "4DNESN22I1UM is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESN22I1UM5607b77c-1998-4518-b296-284d7c57acaa' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 4DNESY1WGMMP HindIII chicken 40\n",
      "4DNEXAZCNCNI part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXAZCNCNI part2 complete\n",
      "4DNEXCVG9D5X part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXCVG9D5X part2 complete\n",
      "part3 still running\n",
      "\n",
      "21 4DNESEC33NM7 HindIII chicken 40\n",
      "4DNEXTRJ5HVV part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXTRJ5HVV part2 complete\n",
      "4DNEXRACVO74 part1 complete\n",
      "Error - Cannot add files to opc\n",
      "The same title already in other processed files\n",
      "4DNEXRACVO74 part2 complete\n",
      "part3 still running\n",
      "1\n",
      "['4DNESIR416OW']\n"
     ]
    }
   ],
   "source": [
    "## TODO make sure set_url is compatible with the set_url sets\n",
    "\n",
    "#Choose the recipe element to run the pipeline on\n",
    "recipe_no = 0\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "\n",
    "#Choose the type of operations you want\n",
    "add_pc = True    #add processed files to 'other processed files\n",
    "add_tag = True   #add the completed process tag if done with all steps\n",
    "add_wfr = True   #start missing wfrs\n",
    "add_tag_small = True   # add skipped small tag\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=pre-release&status=released&status=released%20to%20project'\n",
    "\n",
    "\n",
    "set_url = '/search/?type=ExperimentSetReplicate&experimentset_type=replicate&sort=experiments_in_set.experiment_type&publications_of_set.uuid=84fa5633-aac7-4cb3-b53b-0f0234ea06dd'\n",
    "print(set_url)\n",
    "#set_url = '/search/?award.project=ENCODE&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "\n",
    "#set_url = '/search/?award.project=4DN&experiments_in_set.biosample.biosource.individual.organism.name=fruit-fly&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "#print set_url\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "uncompleted_sets = [i for i in all_sets if \"HiC_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "run_sets = [i for i in uncompleted_sets if \"HiC_Pipeline_0.2.5-skipped-small-set\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "print(len(all_sets), 'total number of sets')\n",
    "print(len(all_sets)-len(uncompleted_sets), 'sets completed')\n",
    "print(len(uncompleted_sets)-len(run_sets), 'sets skipped for small size')\n",
    "print(len(run_sets), 'ready for processing')\n",
    "for a_set in run_sets: \n",
    "    \n",
    "    attributions = None\n",
    "    print()\n",
    "    counter += 1     \n",
    "\n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size, lab = find_pairs(a_set, my_env)\n",
    "    # skip based on these conditions\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print(counter, a_set['accession'], organism, enzyme, 'skipping set with no chrsize/bwa index')\n",
    "        continue\n",
    "    if 'nonorm' not in step3:\n",
    "        if f_size < 4:\n",
    "            print(counter, a_set['accession'], 'skipping small file size', str(f_size))\n",
    "            if add_tag_small:\n",
    "                ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5-skipped-small-set\"]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "            continue\n",
    "            \n",
    "    if 'nore' not in step3:\n",
    "        if not enz_ref:\n",
    "            print(counter, a_set['accession'], 'skipping not ready NZ', organism, enzyme)\n",
    "            continue\n",
    "    print(counter, a_set['accession'],enzyme, organism,f_size)\n",
    "    part3 = 'done'\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments, skip the ones without usable files\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        \n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            if not attributions:\n",
    "                attributions = get_attribution(ff_utils.get_metadata(pair[0], key = my_auth))\n",
    "            step1_result = get_wfr_out(pair[0], 'bwa-mem 0.2.5', my_auth)\n",
    " \n",
    "            # if successful\n",
    "            if step1_result['status'] == 'complete':\n",
    "                exp_bams.append(step1_result['bam'])\n",
    "                continue\n",
    "            # if still running\n",
    "            elif step1_result['status'] == 'running':\n",
    "                part1 = 'not done'\n",
    "                print('part1 still running')\n",
    "                continue\n",
    "            # if run is not successful\n",
    "            else:\n",
    "                part1 = 'not done'\n",
    "                if add_wfr:\n",
    "                    # RUN PART 1\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(step_settings('bwa-mem', organism, attributions), inp_f, name_tag, my_auth, my_env)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print(exp, 'has missing Part1 runs')\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print(exp, 'part1 complete')\n",
    "           \n",
    "        #make sure all input bams went through same last step2\n",
    "        all_step2s = []\n",
    "        for bam in exp_bams:\n",
    "            step2_result = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', my_auth)\n",
    "            all_step2s.append((step2_result['status'],step2_result.get('bam')))\n",
    "        if len(list(set(all_step2s))) != 1:\n",
    "            print('inconsistent step2 run for input bams')\n",
    "            # this run will be repeated if add_wfr\n",
    "            step2_result['status'] = 'inconsistent run'\n",
    "            \n",
    "        #check if part 2 is run already, it not start the run\n",
    "        # if successful\n",
    "        if step2_result['status'] == 'complete':\n",
    "            set_pairs.append(step2_result['pairs'])\n",
    "            if add_pc:\n",
    "                add_preliminary_processed_files(exp, [step2_result['bam'],step2_result['pairs']], my_auth)\n",
    "            print(exp, 'part2 complete')\n",
    "            continue\n",
    "        # if still running\n",
    "        elif step2_result['status'] == 'running':\n",
    "            part2 = 'not done'\n",
    "            part3 = 'not ready'\n",
    "            print(exp, 'part2 still running')\n",
    "            continue\n",
    "        # if run is not successful\n",
    "        else:\n",
    "            part2 = 'not done'\n",
    "            part3 = 'not ready'\n",
    "            print(exp, 'is missing Part2')\n",
    "            if add_wfr:\n",
    "                # RUN PART 2\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(step_settings('hi-c-processing-bam', organism, attributions), inp_f, exp, my_auth, my_env) \n",
    "\n",
    "                \n",
    "    if part3 is not 'done':\n",
    "        print('Part3 not ready')\n",
    "        continue\n",
    "    if not set_pairs:\n",
    "        print('no pairs can be produced from this set')\n",
    "        continue\n",
    "\n",
    "    #make sure all input bams went through same last step3\n",
    "    all_step3s = []\n",
    "    for a_pair in set_pairs:\n",
    "        step3_result = get_wfr_out(a_pair, step3 + \" 0.2.5\", my_auth)\n",
    "        all_step3s.append((step3_result['status'], step3_result.get('mcool')))\n",
    "    if len(list(set(all_step3s))) != 1:\n",
    "        print('inconsistent step3 run for input pairs')\n",
    "        # this run will be repeated if add_wfr\n",
    "        step3_result['status'] = 'inconsistent run'\n",
    "    #check if part 3 is run already, it not start the run\n",
    "    # if successful\n",
    "    if step3_result['status'] == 'complete':\n",
    "        completed += 1\n",
    "        completed_acc.append(a_set['accession'])\n",
    "        #add competed flag to experiment\n",
    "        if add_tag:\n",
    "            ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5\"]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "        # add processed files to set\n",
    "        if add_pc:\n",
    "            add_preliminary_processed_files(a_set['accession'], \n",
    "                                            [step3_result['pairs'],\n",
    "                                             step3_result['hic'],\n",
    "                                             step3_result['mcool']], \n",
    "                                            my_auth)\n",
    "        print(a_set['accession'], 'part3 complete')\n",
    "    # if still running\n",
    "    elif step3_result['status'] == 'running':\n",
    "        print('part3 still running')\n",
    "        continue\n",
    "    # if run is not successful\n",
    "    else:\n",
    "        print(a_set['accession'], 'is missing Part3')\n",
    "        if add_wfr:\n",
    "            # RUN PART 3\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref}\n",
    "            if recipe_no in [0,2,4]:\n",
    "                inp_f['restriction_file'] = enz_ref\n",
    "            run_missing_wfr(step_settings(step3, organism, attributions), inp_f, a_set['accession'], my_auth, my_env)\n",
    "\n",
    "print(completed)\n",
    "print(completed_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3 4DNESH4UTRNL DpnII mouse 800  -  4DNEX4KRGMAQ is missing Part2 - Fails at runtaskawsem\n",
    "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-bam_4DNEX4KRGMAQ9b484528-5651-4d72-a271-a9b37a42ab05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "recipe_no = 1\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "action = False\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=released&status=released%20to%20project'\n",
    "\n",
    "print(set_url)\n",
    "set_url = '/search/?award.project=4DN&experimentset_type=replicate&lab.display_title=Chuck+Murry%2C+UW&status=pre-release&type=ExperimentSetReplicate'\n",
    "\n",
    "# exp\n",
    "# set_url = '/search/?'+ \\\n",
    "#           '&'.join(['experiment_type='+i for i in exp_type])+ \\\n",
    "#           '&type=Experiment&limit=all' + \\\n",
    "#           '&status=released&status=released%20to%20project'\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "\n",
    "ready_sets_1 = [i for i in all_sets if \"HiC_Pipeline_0.2.5\" in i.get('completed_processes', [])]\n",
    "print(len(ready_sets_1))\n",
    "ready_sets_2 = []\n",
    "for a_set in ready_sets_1:\n",
    "    if a_set.get('other_processed_files'):\n",
    "        print('a')\n",
    "        print(a_set['accession'])\n",
    "        if move_title in [i['title'] for i in a_set['other_processed_files']]:\n",
    "            print('b')\n",
    "            if a_set.get('processed_files'):\n",
    "                print('c')\n",
    "                print('WARN' ,a_set['accession'], 'has items in processed files, skipping ')\n",
    "                continue\n",
    "            else:\n",
    "                ready_sets_2.append(a_set)\n",
    "print(len(ready_sets_2), 'items are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move other processed files to processed files field\n",
    "action = True\n",
    "def move_opc_to_pc(resp, move_title, con_key):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        if opc:\n",
    "            print('There are files in processed_files field, expected empty', resp['accession'])\n",
    "            return False\n",
    "        else:\n",
    "            print('it is possible that move already happened, no opc but pc', resp['accession'])\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action:\n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "print(len(ready_sets_2), 'experiment sets in scope')\n",
    "for a_set in ready_sets_2:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_auth, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_auth)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_auth, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_auth)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
