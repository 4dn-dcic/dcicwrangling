{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/?experiments_in_set.experiment_type=ChIP-seq&type=ExperimentSetReplicate&limit=all&status=pre-release&status=released&status=released%20to%20project\n",
      "41 total number of sets\n",
      "0 sets completed\n",
      "41 ready for processing\n"
     ]
    }
   ],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# different types of exps use different steps at the last step(3).\n",
    "recipe = [\n",
    "    [['ChIP-seq'], ''],\n",
    "]\n",
    "\n",
    "#Choose the recipe element to run the pipeline on\n",
    "recipe_no = 0\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=pre-release&status=released&status=released%20to%20project'\n",
    "print(set_url)\n",
    "\n",
    "#set_url = '/search/?award.project=ENCODE&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "\n",
    "#set_url = '/search/?award.project=4DN&experiments_in_set.biosample.biosource.individual.organism.name=fruit-fly&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "#print set_url\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "run_sets = [i for i in all_sets if \"CHIP_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "print(len(all_sets), 'total number of sets')\n",
    "print(len(all_sets)-len(run_sets), 'sets completed')\n",
    "print(len(run_sets), 'ready for processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a_set in run_sets: \n",
    "#     if a_set['accession'] not in ['4DNESOYHVBL5','4DNES8F5YXK1','4DNESRHRFSFY','4DNESHFWJJJZ', '4DNESSNWXHXK',\n",
    "#                                  '4DNES2O1UDH2', '4DNESWX32ZCG', '4DNES9WNNK52']:\n",
    "#         continue\n",
    "#     print(a_set['description'])\n",
    "    \n",
    "# for a_set in  ['4DNESOYHVBL5','4DNES8F5YXK1','4DNESRHRFSFY','4DNESHFWJJJZ', '4DNESSNWXHXK',\n",
    "#                                  '4DNES2O1UDH2', '4DNESWX32ZCG', '4DNES9WNNK52']:\n",
    "#     resp = ff_utils.get_metadata(a_set, key=my_auth)\n",
    "#     print(resp['accession'])\n",
    "#     print(resp['description'])\n",
    "#     print(resp['status'])\n",
    "#     print()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "can not find target\n",
      "\n",
      "4DNESO2RRVT8 mouse single\n",
      "ChIP-seq of  CTCF-AID washed off mouse embryonic stem cells after being treated with auxin targetting H3K27me3 gene\n",
      "skipping single end read set\n",
      "\n",
      "4DNES6VO5VSG mouse single\n",
      "ChIP-seq of CTCF-AID mouse embryonic stem cells treated with Auxin for 4 days targetting H3K27me3 gene\n",
      "skipping single end read set\n",
      "\n",
      "4DNESKIB4QKT mouse single\n",
      "ChIP-seq of CTCF-AID mouse embryonic stem cells treated with Auxin for 2 days targetting H3K27me3 gene\n",
      "skipping single end read set\n",
      "\n",
      "4DNESVCBVRHM mouse single\n",
      "ChIP-seq of untreated CTCF-AID mouse embryonic stem cells targetting H3K27me3 gene\n",
      "skipping single end read set\n",
      "\n",
      "can not find target\n",
      "\n",
      "can not find target\n",
      "\n",
      "4DNES7KIE2LD mouse single\n",
      "ChIP-seq of  CTCF-AID washed off mouse embryonic stem cells after being treated with auxin\n",
      "skipping single end read set\n",
      "\n",
      "4DNES49QC878 mouse single\n",
      "ChIP-seq of  CTCF-AID mouse embryonic stem cells treated with Auxin for 2 days\n",
      "skipping single end read set\n",
      "\n",
      "4DNESIO87EN4 mouse single\n",
      "ChIP-seq of untreated CTCF-AID mouse embryonic stem cells targetting CTCF gene\n",
      "skipping single end read set\n",
      "\n",
      "4DNESPY1NI26 mouse single\n",
      "ChIP-seq of NIPBL KO hepatocytes using anti-H3K4Me3\n",
      "skipping single end read set\n",
      "\n",
      "4DNESNRB3TT6 mouse single\n",
      "ChIP-seq of NIPBL KO hepatocytes using anti-H3K27Ac\n",
      "skipping single end read set\n",
      "\n",
      "can not find target\n",
      "\n",
      "control experiment\n",
      "\n",
      "control experiment\n",
      "\n",
      "can not find target\n",
      "\n",
      "4DNESWBS1FVN mouse single\n",
      "ChIP-seq of TAM control hepatocytes using anti-CTCF\n",
      "skipping single end read set\n",
      "\n",
      "4DNESOMKLZSI mouse single\n",
      "ChIP-seq of NIPBL KO hepatocytes using anti-CTCF\n",
      "skipping single end read set\n",
      "\n",
      "4DNESG1WF34H mouse single\n",
      "ChIP-seq of TAM control hepatocytes using anti-Rad21\n",
      "skipping single end read set\n",
      "\n",
      "4DNESZ8BKGUV mouse single\n",
      "ChIP-seq of NIPBL KO hepatocytes using anti-Rad21\n",
      "skipping single end read set\n",
      "\n",
      "4DNESEZVPO8G mouse single\n",
      "ChIP-seq of TAM control hepatocytes using anti-SMC3\n",
      "skipping single end read set\n",
      "\n",
      "4DNESRIK1N34 mouse single\n",
      "ChIP-seq of NIPBL KO hepatocytes using anti-SMC3\n",
      "skipping single end read set\n",
      "\n",
      "can not find target\n",
      "\n",
      "can not find target\n",
      "\n",
      "4DNESK46EYO5 mouse single\n",
      "Chip-seq with anti-Pol2A on undifferentiated cells with JQ1\n",
      "skipping single end read set\n",
      "\n",
      "control experiment\n",
      "\n",
      "4DNESHX5CM31 mouse single\n",
      "Chip-seq with anti-Pol2A on differentiated cells with triptolide\n",
      "skipping single end read set\n",
      "\n",
      "4DNESMX5EBFU mouse single\n",
      "Chip-seq with anti-Pol2A on differentiated cells with flavopiridol\n",
      "skipping single end read set\n",
      "\n",
      "control experiment\n",
      "\n",
      "4DNESRHWL6VD mouse single\n",
      "Chip-seq with anti-Pol2A on differentiated cells with JQ1\n",
      "skipping single end read set\n",
      "\n",
      "control experiment\n",
      "\n",
      "can not find target\n",
      "\n",
      "can not find target\n",
      "\n",
      "can not find target\n",
      "\n",
      "4DNESOYHVBL5 mouse yes\n",
      "Replicates of CTCF ChIP-seq on subclone 2-4 of Patski wild-type cells\n",
      "tf\n",
      "competed\n",
      "\n",
      "4DNES8F5YXK1 mouse yes\n",
      "Replicates of CTCF ChIP-seq on CRISPR/cas9-modified Patski cells (Inv-Dxz4 clone a)\n",
      "tf\n",
      "competed\n",
      "\n",
      "4DNESRHRFSFY mouse yes\n",
      "Replicates of CTCF ChIP-seq on CRISPR/cas9-modified Patski cells (Del-hinge clone a)\n",
      "tf\n",
      "competed\n",
      "\n",
      "4DNESHFWJJJZ mouse yes\n",
      "Replicates of CTCF ChIP-seq on wild-type Patski cells\n",
      "tf\n",
      "competed\n",
      "\n",
      "4DNESSNWXHXK human yes\n",
      "Histone modification H3K27ac ChIP-seq\n",
      "histone\n",
      "wfr is still running\n",
      "\n",
      "4DNESWX32ZCG human yes\n",
      "Histone modification H3K4me3 ChIP-seq\n",
      "histone\n",
      "run can start\n",
      "\n",
      "4DNES9WNNK52 human yes\n",
      "Histone modification H3K4me1 ChIP-seq\n",
      "histone\n",
      "wfr is still running\n"
     ]
    }
   ],
   "source": [
    "# sample = [[[b1t1,b1t1],[b1t2,b1t2]],[[b2t1,b2t1],[b2t2,b2t2]]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "run_wfr = False\n",
    "\n",
    "for a_set in run_sets: \n",
    "#     if a_set['accession'] not in ['4DNESOYHVBL5','4DNES8F5YXK1','4DNESRHRFSFY','4DNESHFWJJJZ',\n",
    "#                                  '4DNES2O1UDH2', '4DNESSNWXHXK', '4DNESWX32ZCG', '4DNES9WNNK52']:\n",
    "#         continue\n",
    "    print()\n",
    "    paired = \"\"\n",
    "    attributions = None\n",
    "    counter += 1\n",
    "    replicate_exps = a_set['replicate_exps']\n",
    "    files = []\n",
    "    cont_files = []\n",
    "    obj_key = []\n",
    "    cont_obj_key = []\n",
    "    replicate_exps = sorted(replicate_exps, key = lambda x: [x['bio_rep_no'], x['tec_rep_no']])\n",
    "    \n",
    "    for i in replicate_exps:\n",
    "        exp = i['replicate_exp']['uuid']\n",
    "        exp_resp = ff_utils.get_metadata(exp, key = my_auth)\n",
    "        \n",
    "        # get target\n",
    "        target = exp_resp.get('targeted_factor')\n",
    "        if target:\n",
    "            target_n = target['display_title']\n",
    "        else:\n",
    "            target_n = None\n",
    "            break\n",
    "        \n",
    "        #get organism and control\n",
    "        biosample = exp_resp['biosample']\n",
    "        organism = list(set([bs['individual']['organism']['name'] for bs in biosample['biosource']]))[0]\n",
    "        control = ''\n",
    "        exp_relation = exp_resp.get('experiment_relation')\n",
    "        if exp_relation:\n",
    "            rel_type = [i['relationship_type'] for i in exp_relation]\n",
    "            if 'control for' in rel_type:\n",
    "                control = \"control experiment\"\n",
    "                break\n",
    "            elif 'controlled by' in rel_type:\n",
    "                controls = [i['experiment'] for i in exp_relation if i['relationship_type'] == 'controlled by']\n",
    "                if len(controls) != 1:\n",
    "                    print('multiple control experiments')\n",
    "                    break\n",
    "                else:\n",
    "                    control = controls[0]['uuid']\n",
    "        else:\n",
    "            control = 'no exp relation'\n",
    "            break\n",
    "\n",
    "                    \n",
    "        # get exp files\n",
    "        exp_files = exp_resp['files']\n",
    "        b_index = int(i['bio_rep_no']) - 1\n",
    "        t_index = int(i['tec_rep_no']) - 1\n",
    "        for a_file in exp_files:\n",
    "            f_t = []\n",
    "            o_t = []\n",
    "            file_resp = ff_utils.get_metadata(a_file['uuid'], key = my_auth)           \n",
    "            # get pair end no\n",
    "            pair_end = file_resp.get('paired_end')\n",
    "            if pair_end == '2':\n",
    "                paired = 'yes'\n",
    "                continue\n",
    "            # get paired file\n",
    "            paired_with = \"\"\n",
    "            relations = file_resp.get('related_files')\n",
    "            if not relations:\n",
    "                pass\n",
    "            else:\n",
    "                for relation in relations:\n",
    "                    if relation['relationship_type'] == 'paired with':\n",
    "                        paired = 'yes'\n",
    "                        paired_with = relation['file']['uuid']\n",
    "            # decide if data is not paired end reads\n",
    "            if not paired_with:\n",
    "                if not paired:\n",
    "                    paired = 'single'\n",
    "                else:\n",
    "                    if paired != 'single':\n",
    "                        print('inconsistent fastq pair info')\n",
    "                        continue\n",
    "                        \n",
    "                f_t.append(file_resp['uuid'])\n",
    "                o_t.append(file_resp['display_title'])\n",
    "            else:\n",
    "                f2 = ff_utils.get_metadata(paired_with, key = my_auth)\n",
    "                f_t.append(file_resp['uuid'])\n",
    "                o_t.append(file_resp['display_title'])\n",
    "                f_t.append(f2['uuid'])\n",
    "                o_t.append(f2['display_title'])\n",
    "                \n",
    "            try: \n",
    "                files[b_index]\n",
    "            except:\n",
    "                files.append([])\n",
    "            files[b_index].append(f_t)\n",
    "            files[b_index][t_index] = f_t\n",
    "            \n",
    "            try:\n",
    "                obj_key[b_index]\n",
    "            except:\n",
    "                obj_key.append([])\n",
    "            obj_key[b_index].append(o_t)\n",
    "            obj_key[b_index][t_index] = o_t\n",
    "        \n",
    "        cont_exp_resp = ff_utils.get_metadata(control, key = my_auth)\n",
    "        cont_exp_files = cont_exp_resp['files']\n",
    "        b_index = int(i['bio_rep_no']) - 1\n",
    "        t_index = int(i['tec_rep_no']) - 1\n",
    "        for a_file in cont_exp_files:\n",
    "            f_t = []\n",
    "            o_t = []\n",
    "            file_resp = ff_utils.get_metadata(a_file['uuid'], key = my_auth)           \n",
    "            # get pair end no\n",
    "            pair_end = file_resp.get('paired_end')\n",
    "            if pair_end == '2':\n",
    "                paired = 'yes'\n",
    "                continue\n",
    "            # get paired file\n",
    "            paired_with = \"\"\n",
    "            relations = file_resp.get('related_files')\n",
    "            if not relations:\n",
    "                pass\n",
    "            else:\n",
    "                for relation in relations:\n",
    "                    if relation['relationship_type'] == 'paired with':\n",
    "                        paired = 'yes'\n",
    "                        paired_with = relation['file']['uuid']\n",
    "            # decide if data is not paired end reads\n",
    "            if not paired_with:\n",
    "                if not paired:\n",
    "                    paired = 'single'\n",
    "                else:\n",
    "                    if paired != 'single':\n",
    "                        print('inconsistent fastq pair info')\n",
    "                        continue\n",
    "                        \n",
    "                f_t.append(file_resp['uuid'])\n",
    "                o_t.append(file_resp['display_title'])\n",
    "            else:\n",
    "                f2 = ff_utils.get_metadata(paired_with, key = my_auth)\n",
    "                f_t.append(file_resp['uuid'])\n",
    "                o_t.append(file_resp['display_title'])\n",
    "                f_t.append(f2['uuid'])\n",
    "                o_t.append(f2['display_title'])\n",
    "                \n",
    "            try: \n",
    "                cont_files[b_index]\n",
    "            except:\n",
    "                cont_files.append([])\n",
    "            cont_files[b_index].append(f_t)\n",
    "            cont_files[b_index][t_index] = f_t\n",
    "            \n",
    "            try:\n",
    "                cont_obj_key[b_index]\n",
    "            except:\n",
    "                cont_obj_key.append([])\n",
    "            cont_obj_key[b_index].append(o_t)\n",
    "            cont_obj_key[b_index][t_index] = o_t\n",
    "              \n",
    "    if not target_n:\n",
    "        print('can not find target')\n",
    "        continue\n",
    "        \n",
    "    if control in ['control experiment', 'no exp relation']:\n",
    "        print(control)\n",
    "        continue \n",
    "        \n",
    "    typ = 'tf'\n",
    "    if target_n.startswith('Protein:H2') or target_n.startswith('Protein:H3'):\n",
    "        typ= 'histone'\n",
    "    \n",
    "    \n",
    "                   \n",
    "    print(a_set['accession'], organism, paired)  \n",
    "    print(a_set['description'])\n",
    "    if organism not in ['mouse', 'human']:\n",
    "        print('orgamism not ready', organism)\n",
    "        continue\n",
    "    \n",
    "    if paired == 'single':\n",
    "        print('skipping single end read set')\n",
    "        continue\n",
    "        \n",
    "    attributions = get_attribution(ff_utils.get_metadata(files[0][0][0], key = my_auth))\n",
    "    \n",
    "    caller = ''\n",
    "    org = ''\n",
    "    typ = ''\n",
    "    if organism == \"human\":\n",
    "        org = 'hs'\n",
    "        typ = 'histone'\n",
    "        caller = 'mac2'\n",
    "        input_files = [{\n",
    "              \"object_key\": \"4DNFIZQB369V.bwaIndex.tar\",\n",
    "              \"rename\": \"GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.tar\",\n",
    "              \"bucket_name\": raw_bucket,\n",
    "              \"workflow_argument_name\": \"chip.bwa_idx_tar\",\n",
    "              \"uuid\": \"38077b98-3862-45cd-b4be-8e28e9494549\"\n",
    "              },\n",
    "              {\n",
    "              \"object_key\": \"4DNFIZ1TGJZR.bed.gz\",\n",
    "              \"bucket_name\": raw_bucket,\n",
    "              \"workflow_argument_name\": \"chip.blacklist\",\n",
    "              \"uuid\": \"9562ffbd-9f7a-4bd7-9c10-c335137d8966\"\n",
    "              },\n",
    "              {\n",
    "              \"object_key\": \"4DNFIZJB62D1.chrom.sizes\",\n",
    "              \"bucket_name\": raw_bucket,\n",
    "              \"workflow_argument_name\": \"chip.chrsz\",\n",
    "              \"uuid\": \"9866d158-da3c-4d9b-96a9-1d59632eabeb\"\n",
    "              }]\n",
    "          \n",
    "    elif organism == \"mouse\":\n",
    "        org = 'mm'\n",
    "        typ = 'tf'\n",
    "        caller = 'mac2'\n",
    "        input_files = [{\n",
    "              \"object_key\": \"4DNFIZ2PWCC2.bwaIndex.tar\",\n",
    "              \"rename\": \"mm10_no_alt_analysis_set_ENCODE.fasta.tar\",\n",
    "              \"bucket_name\": raw_bucket,\n",
    "              \"workflow_argument_name\": \"chip.bwa_idx_tar\",\n",
    "              \"uuid\": \"f4b63d31-65d8-437f-a76a-6bedbb52ae6f\"\n",
    "              },\n",
    "              {\n",
    "              \"object_key\": \"4DNFIZ3FBPK8.bed.gz\",\n",
    "              \"bucket_name\": raw_bucket,\n",
    "              \"workflow_argument_name\": \"chip.blacklist\",\n",
    "              \"uuid\": \"a32747a3-8a9e-4a9e-a7a1-4db0e8b65925\"\n",
    "              },\n",
    "              {\n",
    "              \"object_key\": \"4DNFIBP173GC.chrom.sizes\",\n",
    "              \"bucket_name\": raw_bucket,\n",
    "              \"workflow_argument_name\": \"chip.chrsz\",\n",
    "              \"uuid\": \"be0a9819-d2ce-4422-be4b-234fb1677dd9\"\n",
    "              }]\n",
    "        \n",
    "    input_files.append({\"object_key\": obj_key,\n",
    "                       \"bucket_name\": raw_bucket,\n",
    "                       \"workflow_argument_name\": \"chip.fastqs\",\n",
    "                       \"uuid\": files})\n",
    "    \n",
    "    input_files.append({\"object_key\": cont_obj_key,\n",
    "                       \"bucket_name\": raw_bucket,\n",
    "                       \"workflow_argument_name\": \"chip.ctl_fastqs\",\n",
    "                       \"uuid\": cont_files})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if paired == 'single':\n",
    "        chip_p = False\n",
    "    if paired == 'yes':\n",
    "        chip_p = True\n",
    "    print(typ)\n",
    "    parameters = {\n",
    "        \"chip.qc_report.desc\": a_set.get('description'),\n",
    "        \"chip.paired_end\": chip_p,\n",
    "        \"chip.bam2ta.regex_grep_v_ta\": \"chr[MUE]|random|alt\",\n",
    "        \"chip.gensz\": org,\n",
    "        \"chip.qc_report.name\": \"CHIP-seq Report\",\n",
    "        \"chip.choose_ctl.always_use_pooled_ctl\": True,\n",
    "        \"chip.pipeline_type\": typ,\n",
    "        \"chip.peak_caller\": caller}\n",
    "    \n",
    "    wf_info = step_settings('encode-chipseq',organism, attributions)\n",
    "    tag = '0.2.5'\n",
    "    run_name = a_set['accession']\n",
    "\n",
    "    \"\"\"Creates the trigger json that is used by foufront endpoint.\n",
    "    \"\"\"\n",
    "    input_json = {'input_files': input_files,\n",
    "                  'output_bucket': out_bucket,\n",
    "                  'workflow_uuid': wf_info['wf_uuid'],\n",
    "                  \"app_name\": wf_info['wf_name'],\n",
    "                  \"wfr_meta\": wf_info['wfr_meta'],\n",
    "                  \"parameters\": parameters,\n",
    "                  \"config\": wf_info['config'],\n",
    "                  \"custom_pf_fields\": wf_info['custom_pf_fields'],\n",
    "                  \"_tibanna\": {\"env\": my_env,\n",
    "                               \"run_type\": wf_info['wf_name'],\n",
    "                               \"run_id\": run_name},\n",
    "                  \"tag\": tag\n",
    "                  }\n",
    "    run_result =  get_wfr_out(files[0][0][0], 'encode-chipseq 0.2.5', my_auth)\n",
    "\n",
    "    \n",
    "    if run_result['status'] == 'running':\n",
    "        print('wfr is still running')\n",
    "        continue\n",
    "    \n",
    "    if run_result['status'] == 'complete':\n",
    "        print('competed')\n",
    "        continue\n",
    "        \n",
    "    elif run_result['status'].startswith('no'):\n",
    "        print('run can start')\n",
    "        \n",
    "    if run_wfr:     \n",
    "        r = json.dumps(input_json)\n",
    "        #print(r)\n",
    "        e = ff_utils.post_metadata(input_json, 'WorkflowRun/run', key=my_auth)\n",
    "        url = json.loads(e['input'])['_tibanna']['url']\n",
    "        display(HTML(\"<a href='{}' target='_blank'>{}</a>\".format(url, e['status'])))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3 4DNESH4UTRNL DpnII mouse 800  -  4DNEX4KRGMAQ is missing Part2 - Fails at runtaskawsem\n",
    "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-bam_4DNEX4KRGMAQ9b484528-5651-4d72-a271-a9b37a42ab05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "recipe_no = 1\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "action = False\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=released&status=released%20to%20project'\n",
    "\n",
    "print(set_url)\n",
    "set_url = '/search/?award.project=4DN&experimentset_type=replicate&lab.display_title=Chuck+Murry%2C+UW&status=pre-release&type=ExperimentSetReplicate'\n",
    "\n",
    "# exp\n",
    "# set_url = '/search/?'+ \\\n",
    "#           '&'.join(['experiment_type='+i for i in exp_type])+ \\\n",
    "#           '&type=Experiment&limit=all' + \\\n",
    "#           '&status=released&status=released%20to%20project'\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "\n",
    "ready_sets_1 = [i for i in all_sets if \"HiC_Pipeline_0.2.5\" in i.get('completed_processes', [])]\n",
    "print(len(ready_sets_1))\n",
    "ready_sets_2 = []\n",
    "for a_set in ready_sets_1:\n",
    "    if a_set.get('other_processed_files'):\n",
    "        print('a')\n",
    "        print(a_set['accession'])\n",
    "        if move_title in [i['title'] for i in a_set['other_processed_files']]:\n",
    "            print('b')\n",
    "            if a_set.get('processed_files'):\n",
    "                print('c')\n",
    "                print('WARN' ,a_set['accession'], 'has items in processed files, skipping ')\n",
    "                continue\n",
    "            else:\n",
    "                ready_sets_2.append(a_set)\n",
    "print(len(ready_sets_2), 'items are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move other processed files to processed files field\n",
    "action = True\n",
    "def move_opc_to_pc(resp, move_title, con_key):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        if opc:\n",
    "            print('There are files in processed_files field, expected empty', resp['accession'])\n",
    "            return False\n",
    "        else:\n",
    "            print('it is possible that move already happened, no opc but pc', resp['accession'])\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action:\n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "print(len(ready_sets_2), 'experiment sets in scope')\n",
    "for a_set in ready_sets_2:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_auth, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_auth)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_auth, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_auth)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
