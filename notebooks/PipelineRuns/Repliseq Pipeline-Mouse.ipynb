{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 total number of sets\n",
      "0 sets completed\n",
      "\n",
      "1 4DNESO4HIS4U None mouse\n",
      "4DNEXTX3GU66 has missing Part1 runs\n",
      "\n",
      "2 4DNESOE7IW9E None mouse\n",
      "4DNEX5732QDS part1 complete\n",
      "\n",
      "3 4DNESSQCYHJB None mouse\n",
      "4DNEXYAAVQBY part1 complete\n",
      "\n",
      "4 4DNESRX5DC6I None mouse\n",
      "4DNEX6E89VM9 part1 complete\n",
      "\n",
      "5 4DNES9IB8HW3 None mouse\n",
      "4DNEXUN22XKF part1 complete\n",
      "4DNEX7ML7KID part1 complete\n",
      "\n",
      "6 4DNESMZPCTLH None mouse\n",
      "4DNEXP6VC66C part1 complete\n",
      "4DNEXU21ER4O part1 complete\n",
      "\n",
      "7 4DNESVQW7LXZ None mouse\n",
      "4DNEXS9PR6LY part1 complete\n",
      "4DNEX7JW78MW part1 complete\n",
      "\n",
      "8 4DNESW9JK6G9 None mouse\n",
      "4DNEXE4QKHFL part1 complete\n",
      "4DNEX3E37VBC part1 complete\n",
      "\n",
      "9 4DNESPE1BXOP None mouse\n",
      "4DNEXU72BIPV part1 complete\n",
      "4DNEXSKDHYQO part1 complete\n",
      "\n",
      "10 4DNESAA7V4EC None mouse\n",
      "4DNEX8NT78XN part1 complete\n",
      "4DNEXG45T8GF part1 complete\n",
      "\n",
      "11 4DNESD6TY736 None mouse\n",
      "4DNEX72ET7J8 part1 complete\n",
      "4DNEX1AG97JZ part1 complete\n",
      "\n",
      "12 4DNESV5WY2NW None mouse\n",
      "4DNEXTLJQMDK part1 complete\n",
      "4DNEX25JIFPV part1 complete\n",
      "\n",
      "13 4DNES5CPWZO4 None mouse\n",
      "4DNEXM2UNXEN part1 complete\n",
      "4DNEXXXU3DTR part1 complete\n",
      "\n",
      "14 4DNESEIP9JB8 None mouse\n",
      "4DNEX1PNZCSE part1 complete\n",
      "4DNEXMQGS95Y part1 complete\n",
      "\n",
      "15 4DNESBH1KQ7G None mouse\n",
      "4DNEXGNXDTG9 part1 complete\n",
      "4DNEXFOCJ852 part1 complete\n",
      "\n",
      "16 4DNESVK9AIPJ None mouse\n",
      "4DNEXX87267M part1 complete\n",
      "4DNEXFDKGDSS part1 complete\n",
      "\n",
      "17 4DNES7ZVDD5G None mouse\n",
      "4DNEXLPEFEIU part1 complete\n",
      "4DNEXQLHK5EN part1 complete\n",
      "\n",
      "18 4DNESGRJK3LU None mouse\n",
      "4DNEXJNJKLUG part1 complete\n",
      "4DNEX2EXD4WB part1 complete\n",
      "\n",
      "19 4DNES5P96TIY None mouse\n",
      "4DNEXHIN8KF5 part1 complete\n",
      "4DNEXKHPKZFI part1 complete\n",
      "\n",
      "20 4DNESLIKKM2F None mouse\n",
      "4DNEXW5RQ15L part1 complete\n",
      "4DNEXH2LQR64 part1 complete\n",
      "\n",
      "21 4DNESXNJ6FWX None mouse\n",
      "4DNEX1KN1SV1 part1 complete\n",
      "4DNEX2RMNOEZ part1 complete\n",
      "\n",
      "22 4DNES1NKQNGW None mouse\n",
      "4DNEX1ASL1SF part1 complete\n",
      "4DNEXYTC9LEW part1 complete\n",
      "\n",
      "23 4DNESJCH5NIA None mouse\n",
      "4DNEXO4RRV41 part1 complete\n",
      "4DNEXIAZRUKE part1 complete\n",
      "\n",
      "24 4DNESEIOZ1JZ None mouse\n",
      "4DNEXO97VYLS part1 complete\n",
      "4DNEXT6IWWQ8 part1 complete\n",
      "\n",
      "25 4DNESQXT7DOB None mouse\n",
      "4DNEX7IY9NLE part1 complete\n",
      "4DNEXQI7U38O part1 complete\n",
      "\n",
      "26 4DNESRCO9ALV None mouse\n",
      "4DNEX6OHZSTN part1 complete\n",
      "4DNEXNKDJI6I part1 complete\n",
      "\n",
      "27 4DNESPQHCGPU None mouse\n",
      "4DNEXSNIMVF7 part1 complete\n",
      "4DNEXACA468U part1 complete\n",
      "\n",
      "28 4DNESO4WHZFT None mouse\n",
      "4DNEXHZIA1J7 part1 complete\n",
      "4DNEXPJZ4RQW part1 complete\n",
      "\n",
      "29 4DNESXUM27JA None mouse\n",
      "4DNEXL2YLP84 part1 complete\n",
      "\n",
      "30 4DNESVFSED4R None mouse\n",
      "4DNEXIOXOQ86 part1 complete\n",
      "\n",
      "31 4DNES1PHNYOP None mouse\n",
      "4DNEX14L7KXP part1 complete\n",
      "4DNEXTTY1KTG part1 complete\n",
      "\n",
      "32 4DNESWPIPVZT None mouse\n",
      "4DNEXWTU45NI part1 complete\n",
      "4DNEX91MUU81 part1 complete\n"
     ]
    }
   ],
   "source": [
    "# url for repliseq exps\n",
    "set_url = '/search/?experiments_in_set.biosample.biosource.individual.organism.name=mouse&experiments_in_set.experiment_type=Repli-seq&type=ExperimentSetReplicate'\n",
    "run_sets = ff_utils.search_metadata(set_url ,key=my_auth)\n",
    "\n",
    "add_pc = False\n",
    "add_rel = False\n",
    "add_wfr = False\n",
    "\n",
    "counter = 0\n",
    "all_sets = len(run_sets)\n",
    "print(str(all_sets)+' total number of sets')\n",
    "\n",
    "run_sets = [i for i in run_sets if \"RepliSeq_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "print(str(all_sets-len(run_sets))+ ' sets completed')\n",
    "\n",
    "\n",
    "for a_set in run_sets: \n",
    "    counter += 1\n",
    "    print()\n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size, lab = find_pairs(a_set, my_env, lookfor = 'single')\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print(counter, a_set['accession'], organism, enzyme, 'skipping set with not chrsize/bwa index')\n",
    "        continue  \n",
    "    print(counter, a_set['accession'], enzyme, organism)      \n",
    "    # cycle through the experiments\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq files')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        # part2 = 'done'\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            pair_resp = ff_utils.get_metadata(pair, key=my_auth)\n",
    "            attributions = get_attribution(pair_resp)\n",
    "            report = get_wfr_out(pair, 'repliseq-parta 0.2.5', my_auth)\n",
    "            # if run is not successful\n",
    "            if report['status'].startswith('no'):\n",
    "                part1 = 'not done'\n",
    "                if add_wfr:\n",
    "                    inp_f = {'fastq':pair, 'chromsizes':chrsize_ref, 'bwaIndex':bwa_ref}\n",
    "                    name_tag = pair.split('/')[2]\n",
    "                    run_missing_wfr(step_settings('repliseq-parta', organism, attributions), inp_f, name_tag,my_auth, my_env)\n",
    "            elif report['status'] == 'running':\n",
    "                part1 = 'still running'\n",
    "                print('part1 still running')\n",
    "            # if successful\n",
    "            else:\n",
    "                assert report['status'] == 'complete'\n",
    "                if add_pc:\n",
    "                    # TODO check if the files already in processed files field.\n",
    "                    # don't do it if they are already carried there.\n",
    "                    print('Adding files to preliminary tab')\n",
    "                    add_preliminary_processed_files(exp,\n",
    "                                                    [report['bam'], report['bg']],\n",
    "                                                    my_auth,\n",
    "                                                    run_type='repliseq')\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print(exp, 'has missing Part1 runs')\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print(exp, 'part1 complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "action = False\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_key = get_key('koray_data')\n",
    "print(my_key)\n",
    "# which sets to move data\n",
    "set_url = '/search/?experiments_in_set.experiment_type=Repli-seq&type=ExperimentSetReplicate&limit=all'\n",
    "\n",
    "# exp\n",
    "# set_url = '/search/?experiment_type=Repli-seq&type=Experiment&limit=all'\n",
    "\n",
    "\n",
    "# move other processed files to processed files field\n",
    "def move_opc_to_pc(resp, move_title, con_key):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        print('There are files in processed_files field, expected empty')\n",
    "        return False\n",
    "    # are there files in opc\n",
    "    if not opc:\n",
    "        print('there are no other processed files, skipping')\n",
    "        return False\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action: \n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "run_sets = ff_utils.search_metadata(set_url , key=my_key)\n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "#move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "move_title = \"Repli-Seq Pipeline - Preliminary Files\"\n",
    "\n",
    "print(len(run_sets), 'experiment sets in scope')\n",
    "for a_set in run_sets:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_key, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_key)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_key, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_key)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repliseq pipeline part 1 also produces a qc object on the files.\n",
    "# Change their status to the ones of the files (if the files are in processed files field)\n",
    "\n",
    "set_url = '/search/?experiments_in_set.experiment_type=Repli-seq&type=ExperimentSetReplicate&limit=all'\n",
    "run_sets = ff_utils.search_metadata(set_url , key=my_key)\n",
    "\n",
    "def release_qc(file_id, con_key):\n",
    "    file_resp = ff_utils.get_metadata(file_id, key=con_key, add_on = 'frame=raw')\n",
    "    file_status = file_resp['status']\n",
    "    # skip if file is not released/archived\n",
    "    if file_status not in ['released', 'released to project', 'archived']:\n",
    "        return\n",
    "    qc = file_resp.get('quality_metric')\n",
    "    if qc:\n",
    "        qc_resp = ff_utils.get_metadata(qc, key=con_key)\n",
    "        qc_status = qc_resp['status']\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    if qc_status != file_status:\n",
    "        ff_utils.patch_metadata({'status': file_status}, obj_id=qc, key=con_key)\n",
    "        print(qc, 'qc object updated with status', file_status)\n",
    "        return True\n",
    "    \n",
    "print(len(run_sets), 'experiment sets in scope')\n",
    "for a_set in run_sets:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_key, add_on='frame=raw')\n",
    "    if set_resp.get('processed_files'):\n",
    "        for a_pf in set_resp['processed_files']:\n",
    "            release_qc(a_pf, my_key)\n",
    "            \n",
    "    exps = set_resp['experiments_in_set']\n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_key, add_on='frame=raw')\n",
    "        if exp_resp.get('processed_files'):\n",
    "            for a_pf_e in exp_resp['processed_files']:\n",
    "                release_qc(a_pf_e, my_key)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
