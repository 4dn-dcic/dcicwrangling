{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# different types of exps use different steps at the last step(3).\n",
    "recipe = [\n",
    "    [[\n",
    "      #'in%20situ%20Hi-C', \n",
    "      'dilution%20Hi-C'\n",
    "     ], 'hi-c-processing-pairs'],\n",
    "    \n",
    "    [[#'micro-C',          \n",
    "      'DNase%20Hi-C'\n",
    "     ], 'hi-c-processing-pairs-nore'], # 2 low q dnase hi sets\n",
    "    \n",
    "    [['capture%20Hi-C',   'PLAC-seq'],        'hi-c-processing-pairs-nonorm'],\n",
    "    [['ChIA-PET',         'TrAC-loop'],       'hi-c-processing-pairs-nore-nonorm'],\n",
    "    [['TCC'], 'hi-c-processing-pairs'],\n",
    "    \n",
    "]\n",
    "\n",
    "# To Do assign core 8 and more memory (\"instance_type\": \"c4.4xlarge\",) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/?experiments_in_set.experiment_type=dilution%20Hi-C&type=ExperimentSetReplicate&limit=all&status=pre-release&status=released&status=released%20to%20project\n",
      "98 total number of sets\n",
      "45 sets completed\n",
      "3 sets skipped for small size\n",
      "50 ready for processing\n",
      "\n",
      "1 4DNESDYFTSG5 HindIII human 139\n",
      "4DNEXJTTVISJ part1 complete\n",
      "4DNEXJTTVISJ part2 still running\n",
      "4DNEXW6T5QSA part1 complete\n",
      "4DNEXW6T5QSA part2 still running\n",
      "Part3 not ready\n",
      "\n",
      "2 4DNESG9UPQLY HindIII human 68\n",
      "4DNEX9XWW3E8 part1 complete\n",
      "4DNEX9XWW3E8 part2 complete\n",
      "4DNEXZ1JAG6F part1 complete\n",
      "4DNEXZ1JAG6F part2 complete\n",
      "4DNESG9UPQLY part3 complete\n",
      "\n",
      "3 4DNESOHWXJQY HindIII human 89\n",
      "4DNEX2TH7TT7 part1 complete\n",
      "4DNEX2TH7TT7 part2 complete\n",
      "4DNEXSAUBE1B part1 complete\n",
      "4DNEXSAUBE1B part2 still running\n",
      "Part3 not ready\n",
      "\n",
      "4 4DNESQK7WJLT HindIII human 118\n",
      "4DNEXS7USB6L part1 complete\n",
      "4DNEXS7USB6L part2 still running\n",
      "4DNEXTNMDOUU part1 complete\n",
      "4DNEXTNMDOUU part2 still running\n",
      "Part3 not ready\n",
      "\n",
      "5 4DNES3HQPSLM HindIII human 74\n",
      "4DNEXHIL66E1 part1 complete\n",
      "4DNEXHIL66E1 part2 complete\n",
      "4DNEX1HYWC6B part1 complete\n",
      "4DNEX1HYWC6B part2 complete\n",
      "4DNES3HQPSLM is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNES3HQPSLM' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 4DNES3IV77UJ HindIII human 90\n",
      "4DNEXZRAD9HM part1 complete\n",
      "4DNEXZRAD9HM part2 complete\n",
      "4DNEXQ7AIQ4O part1 complete\n",
      "4DNEXQ7AIQ4O part2 complete\n",
      "4DNES3IV77UJ is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNES3IV77UJ' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 4DNESZIREYB8 HindIII human 97\n",
      "4DNEX9IKMOGL part1 complete\n",
      "4DNEX9IKMOGL part2 still running\n",
      "4DNEX9K6IIC1 part1 complete\n",
      "4DNEX9K6IIC1 part2 complete\n",
      "Part3 not ready\n",
      "\n",
      "8 4DNESQXAEPXP HindIII human 115\n",
      "4DNEXYZP675H part1 complete\n",
      "4DNEXYZP675H part2 still running\n",
      "4DNEXQE76BS6 part1 complete\n",
      "4DNEXQE76BS6 part2 still running\n",
      "Part3 not ready\n",
      "\n",
      "9 4DNESAZRVEQ8 HindIII human 93\n",
      "4DNEXCQG4BRQ part1 complete\n",
      "4DNEXCQG4BRQ part2 still running\n",
      "4DNEXLEHFN7H part1 complete\n",
      "4DNEXLEHFN7H part2 complete\n",
      "Part3 not ready\n",
      "\n",
      "10 4DNES1H2O6N7 HindIII human 118\n",
      "4DNEX1GEQHOG part1 complete\n",
      "4DNEX1GEQHOG part2 still running\n",
      "4DNEXZ2QLOQX part1 complete\n",
      "4DNEXZ2QLOQX part2 still running\n",
      "Part3 not ready\n",
      "\n",
      "11 4DNESKM5UQ2L HindIII chicken 35\n",
      "4DNEXD6T8FIR part1 complete\n",
      "4DNEXD6T8FIR part2 complete\n",
      "4DNEXSVIJRMI part1 complete\n",
      "4DNEXSVIJRMI part2 complete\n",
      "4DNESKM5UQ2L part3 complete\n",
      "\n",
      "12 4DNES1MGX3LX HindIII chicken 27\n",
      "4DNEXVYW7AW4 part1 complete\n",
      "4DNEXVYW7AW4 part2 complete\n",
      "4DNEXFP1CL5Y part1 complete\n",
      "4DNEXFP1CL5Y part2 complete\n",
      "4DNES1MGX3LX part3 complete\n",
      "\n",
      "13 4DNES6FARLK8 HindIII chicken 26\n",
      "4DNEX61FZW4H part1 complete\n",
      "4DNEX61FZW4H part2 complete\n",
      "4DNEXBJKTWVH part1 complete\n",
      "4DNEXBJKTWVH part2 complete\n",
      "inconsistent step3 run for input pairs\n",
      "4DNES6FARLK8 is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNES6FARLK8-ecd7c14d-0287-44ef-a094-203d53d6d4fa' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "14 4DNES3CEBN3H HindIII chicken 30\n",
      "4DNEXQ4RGG3Q part1 complete\n",
      "4DNEXQ4RGG3Q part2 complete\n",
      "4DNEXORTALXD part1 complete\n",
      "4DNEXORTALXD part2 complete\n",
      "4DNES3CEBN3H part3 complete\n",
      "\n",
      "15 4DNES57F5K1Y HindIII chicken 32\n",
      "4DNEXXYDF2PV part1 complete\n",
      "4DNEXXYDF2PV part2 complete\n",
      "4DNEX9OVHMNN part1 complete\n",
      "4DNEX9OVHMNN part2 complete\n",
      "part3 still running\n",
      "\n",
      "16 4DNESYIMR82X HindIII chicken 37\n",
      "4DNEXMOSRYT5 part1 complete\n",
      "4DNEXMOSRYT5 part2 complete\n",
      "4DNEXOE3CU5G part1 complete\n",
      "4DNEXOE3CU5G part2 complete\n",
      "part3 still running\n",
      "\n",
      "17 4DNESTBTENG2 HindIII chicken 32\n",
      "4DNEXEILBWYP part1 complete\n",
      "4DNEXEILBWYP part2 complete\n",
      "4DNEX18HYGLV part1 complete\n",
      "4DNEX18HYGLV part2 complete\n",
      "part3 still running\n",
      "\n",
      "18 4DNESSU8NFVC HindIII chicken 40\n",
      "4DNEXLLAUZP9 part1 complete\n",
      "4DNEXLLAUZP9 part2 complete\n",
      "4DNEXDYG6GLB part1 complete\n",
      "4DNEXDYG6GLB part2 complete\n",
      "part3 still running\n",
      "\n",
      "19 4DNES4RSKMSF HindIII chicken 40\n",
      "4DNEXRBHYJXN part1 complete\n",
      "4DNEXRBHYJXN part2 complete\n",
      "4DNEX35W18E3 part1 complete\n",
      "4DNEX35W18E3 part2 complete\n",
      "part3 still running\n",
      "\n",
      "20 4DNESE9ZKE6Z HindIII chicken 40\n",
      "4DNEXVXQTM1S part1 complete\n",
      "4DNEXVXQTM1S part2 complete\n",
      "4DNEX3Z7WCZV part1 complete\n",
      "4DNEX3Z7WCZV part2 complete\n",
      "part3 still running\n",
      "\n",
      "21 4DNES81PRZLH HindIII chicken 40\n",
      "4DNEXVC56Y69 part1 complete\n",
      "4DNEXVC56Y69 part2 complete\n",
      "4DNEXEO8KJE3 part1 complete\n",
      "4DNEXEO8KJE3 part2 complete\n",
      "part3 still running\n",
      "\n",
      "22 4DNES3EAC1H8 HindIII chicken 40\n",
      "4DNEXLD3G1LS part1 complete\n",
      "4DNEXLD3G1LS part2 complete\n",
      "4DNEXJRAMX4W part1 complete\n",
      "4DNEXJRAMX4W part2 complete\n",
      "part3 still running\n",
      "\n",
      "23 4DNESY1WGMMP HindIII chicken 40\n",
      "4DNEXAZCNCNI part1 complete\n",
      "4DNEXAZCNCNI part2 complete\n",
      "4DNEXCVG9D5X part1 complete\n",
      "4DNEXCVG9D5X part2 complete\n",
      "part3 still running\n",
      "\n",
      "24 4DNESEC33NM7 HindIII chicken 40\n",
      "4DNEXTRJ5HVV part1 complete\n",
      "4DNEXTRJ5HVV part2 complete\n",
      "4DNEXRACVO74 part1 complete\n",
      "4DNEXRACVO74 part2 complete\n",
      "4DNESEC33NM7 is missing Part3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-pairs_4DNESEC33NM7-ad931211-0cf5-4221-bc83-d06c5e403bbe' target='_blank'>RUNNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 4DNESU9VIEWW HindIII chicken 14\n",
      "4DNEXQEQLXHG part1 complete\n",
      "4DNEXQEQLXHG part2 complete\n",
      "4DNESU9VIEWW part3 complete\n",
      "\n",
      "26 4DNES3WY8A3I HindIII chicken 15\n",
      "4DNEXXNA89QO part1 complete\n",
      "4DNEXXNA89QO part2 complete\n",
      "part3 still running\n",
      "\n",
      "27 4DNES5GUEFXM HindIII chicken 15\n",
      "4DNEX8T4SM7Q part1 complete\n",
      "4DNEX8T4SM7Q part2 complete\n",
      "4DNES5GUEFXM part3 complete\n",
      "\n",
      "28 4DNESWJXT6RB HindIII chicken 31\n",
      "4DNEX32NGWEN part1 complete\n",
      "4DNEX32NGWEN part2 complete\n",
      "4DNEXBHBPTIB part1 complete\n",
      "4DNEXBHBPTIB part2 complete\n",
      "4DNESWJXT6RB part3 complete\n",
      "\n",
      "29 4DNESN22I1UM HindIII chicken 12\n",
      "4DNEXZTSXFT3 part1 complete\n",
      "4DNEXZTSXFT3 part2 complete\n",
      "4DNESN22I1UM part3 complete\n",
      "\n",
      "30 4DNESFWDJJSL HindIII chicken 13\n",
      "4DNEX82F828R part1 complete\n",
      "4DNEX82F828R part2 complete\n",
      "4DNESFWDJJSL part3 complete\n",
      "\n",
      "31 4DNES7QUTR6Z HindIII chicken 11\n",
      "4DNEXI7VXCWP part1 complete\n",
      "4DNEXI7VXCWP part2 complete\n",
      "4DNES7QUTR6Z part3 complete\n",
      "\n",
      "32 4DNESE5Q29E1 HindIII chicken 13\n",
      "4DNEXJE1QDVN part1 complete\n",
      "4DNEXJE1QDVN part2 complete\n",
      "4DNESE5Q29E1 part3 complete\n",
      "\n",
      "33 4DNESJWNFMOD HindIII chicken 13\n",
      "4DNEXAW5244B part1 complete\n",
      "4DNEXAW5244B part2 complete\n",
      "4DNESJWNFMOD part3 complete\n",
      "\n",
      "34 4DNESXDOBP9L HindIII chicken 15\n",
      "4DNEXZ1XWPPX part1 complete\n",
      "4DNEXZ1XWPPX part2 complete\n",
      "4DNESXDOBP9L part3 complete\n",
      "\n",
      "35 4DNESE3U35ZL HindIII chicken 16\n",
      "4DNEXRQ91AHM part1 complete\n",
      "4DNEXRQ91AHM part2 complete\n",
      "4DNESE3U35ZL part3 complete\n",
      "\n",
      "36 4DNES6GBBV5D HindIII chicken 16\n",
      "4DNEX79NW5UD part1 complete\n",
      "4DNEX79NW5UD part2 complete\n",
      "4DNES6GBBV5D part3 complete\n",
      "\n",
      "37 4DNESOL4SYQN HindIII chicken 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7b889afca29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattributions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mattributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mstep1_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wfr_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bwa-mem'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_auth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0.2.6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# if successful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/dcicwrangling/functions/wfr.py\u001b[0m in \u001b[0;36mget_wfr_out\u001b[0;34m(file_id, wfr_name, auth, versions, md_qc, run)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m \u001b[0many\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwill\u001b[0m \u001b[0msimply\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \"\"\"\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0memb_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0mworkflows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'workflow_run_inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mwfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(obj_id, key, ff_env, check_queue, add_on)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mget_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprocess_add_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# check the queues if check_queue is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthorized_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_response_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mauthorized_request\u001b[0;34m(url, auth, ff_env, verb, retry_fxn, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mretry_fxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_request_with_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# use the given retry function. MUST TAKE THESE PARAMS!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mretry_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_verb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mstandard_request_with_retries\u001b[0;34m(request_fxn, url, auth, verb, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_timeouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mretry\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    522\u001b[0m         }\n\u001b[1;32m    523\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 171\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## TODO make sure set_url is compatible with the set_url sets\n",
    "\n",
    "#Choose the recipe element to run the pipeline on\n",
    "recipe_no = 0\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "\n",
    "#Choose the type of operations you want\n",
    "add_pc = False    #add processed files to 'other processed files\n",
    "add_tag = False   #add the completed process tag if done with all steps\n",
    "add_wfr = True   #start missing wfrs\n",
    "add_tag_small = False   # add skipped small tag\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=pre-release&status=released&status=released%20to%20project'\n",
    "\n",
    "#print(set_url)\n",
    "\n",
    "# set_url = '/search/?experiments_in_set.experiment_type=DNase+Hi-C&experimentset_type=replicate&lab.display_title=Chuck+Murry%2C+UW&type=ExperimentSetReplicate'\n",
    "# set_url = '/search/?award.project=4DN&experiments_in_set.experiment_type=PLAC-seq&experimentset_type=replicate&status=pre-release&type=ExperimentSetReplicate'\n",
    "#set_url = '/search/?award.project=External&experiments_in_set.experiment_type=in+situ+Hi-C&experimentset_type=replicate&lab.display_title=Rafael+Casellas%2C+NIH&type=ExperimentSetReplicate'\n",
    "print(set_url)\n",
    "#set_url = '/search/?award.project=ENCODE&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "\n",
    "#set_url = '/search/?award.project=4DN&experiments_in_set.biosample.biosource.individual.organism.name=fruit-fly&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "#print set_url\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "uncompleted_sets = [i for i in all_sets if \"HiC_Pipeline_0.2.6\"  not in i.get('completed_processes', [])]\n",
    "run_sets = [i for i in uncompleted_sets if \"HiC_Pipeline_0.2.6_skipped-small-set\"  not in i.get('completed_processes', [])]\n",
    "run_sets = [i for i in run_sets if \"HiC_Pipeline_0.2.7\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "\n",
    "for i in run_sets:\n",
    "    if i.get('completed_processes'):\n",
    "        print(i['accession'], i['completed_processes'])\n",
    "print(len(all_sets), 'total number of sets')\n",
    "print(len(all_sets)-len(uncompleted_sets), 'sets completed')\n",
    "print(len(uncompleted_sets)-len(run_sets), 'sets skipped for small size')\n",
    "print(len(run_sets), 'ready for processing')\n",
    "\n",
    "\n",
    "for a_set in run_sets: \n",
    "    \n",
    "    attributions = None\n",
    "    print()\n",
    "    counter += 1\n",
    "        \n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size, lab = find_pairs(a_set, my_env)\n",
    "    # skip based on these conditions\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print(counter, a_set['accession'], organism, enzyme, 'skipping set with no chrsize/bwa index')\n",
    "        continue\n",
    "    if 'nonorm' not in step3:\n",
    "        if f_size < 4:\n",
    "            print(counter, a_set['accession'], 'skipping small file size', str(f_size))\n",
    "            if add_tag_small:\n",
    "                ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.6_skipped-small-set\"]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "                \n",
    "            continue\n",
    "    if 'nore' not in step3:\n",
    "        if not enz_ref:\n",
    "            print(counter, a_set['accession'], 'skipping not ready NZ', organism, enzyme)\n",
    "            continue\n",
    "    \n",
    "    print(counter, a_set['accession'],enzyme, organism,f_size)\n",
    "    part3 = 'done'\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments, skip the ones without usable files\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        \n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            if not attributions:\n",
    "                attributions = get_attribution(ff_utils.get_metadata(pair[0], key = my_auth))\n",
    "            step1_result = get_wfr_out(pair[0], 'bwa-mem', my_auth, ['0.2.6'])\n",
    " \n",
    "            # if successful\n",
    "            if step1_result['status'] == 'complete':\n",
    "                exp_bams.append(step1_result['bam'])\n",
    "                continue\n",
    "            # if still running\n",
    "            elif step1_result['status'] == 'running':\n",
    "                part1 = 'not done'\n",
    "                print('part1 still running')\n",
    "                continue\n",
    "            # if run is not successful\n",
    "            else:\n",
    "                part1 = 'not done'\n",
    "                if add_wfr:\n",
    "                    # RUN PART 1\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(step_settings('bwa-mem', organism, attributions), inp_f, name_tag, my_auth, my_env)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print(exp, 'has missing Part1 runs')\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print(exp, 'part1 complete')\n",
    "           \n",
    "        #make sure all input bams went through same last step2\n",
    "        all_step2s = []\n",
    "        for bam in exp_bams:\n",
    "            step2_result = get_wfr_out(bam, 'hi-c-processing-bam', my_auth, ['0.2.6'])\n",
    "            all_step2s.append((step2_result['status'],step2_result.get('bam')))\n",
    "        if len(list(set(all_step2s))) != 1:\n",
    "            print('inconsistent step2 run for input bams')\n",
    "            # this run will be repeated if add_wfr\n",
    "            step2_result['status'] = 'inconsistent run'\n",
    "            \n",
    "        #check if part 2 is run already, it not start the run\n",
    "        # if successful\n",
    "        if step2_result['status'] == 'complete':\n",
    "            set_pairs.append(step2_result['pairs'])\n",
    "            if add_pc:\n",
    "                add_preliminary_processed_files(exp, [step2_result['bam'],step2_result['pairs']], my_auth)\n",
    "            print(exp, 'part2 complete')\n",
    "            continue\n",
    "        # if still running\n",
    "        elif step2_result['status'] == 'running':\n",
    "            part2 = 'not done'\n",
    "            part3 = 'not ready'\n",
    "            print(exp, 'part2 still running')\n",
    "            continue\n",
    "        # if run is not successful\n",
    "        else:\n",
    "            part2 = 'not done'\n",
    "            part3 = 'not ready'\n",
    "            print(exp, 'is missing Part2')\n",
    "            if add_wfr:\n",
    "                # RUN PART 2\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(step_settings('hi-c-processing-bam', organism, attributions), inp_f, exp, my_auth, my_env) \n",
    "\n",
    "                \n",
    "    if part3 is not 'done':\n",
    "        print('Part3 not ready')\n",
    "        continue\n",
    "    if not set_pairs:\n",
    "        print('no pairs can be produced from this set')\n",
    "        continue\n",
    "\n",
    "    #make sure all input bams went through same last step3\n",
    "    all_step3s = []\n",
    "    for a_pair in set_pairs:\n",
    "        step3_result = get_wfr_out(a_pair, step3, my_auth, ['0.2.6', '0.2.7'])\n",
    "        all_step3s.append((step3_result['status'], step3_result.get('mcool')))\n",
    "    if len(list(set(all_step3s))) != 1:\n",
    "        print('inconsistent step3 run for input pairs')\n",
    "        # this run will be repeated if add_wfr\n",
    "        step3_result['status'] = 'inconsistent run'\n",
    "    #check if part 3 is run already, it not start the run\n",
    "    # if successful\n",
    "    if step3_result['status'] == 'complete':\n",
    "        completed += 1\n",
    "        completed_acc.append(a_set['accession'])\n",
    "        #add competed flag to experiment\n",
    "        if add_tag:\n",
    "            ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.7\"]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "        # add processed files to set\n",
    "        if add_pc:\n",
    "            add_preliminary_processed_files(a_set['accession'], \n",
    "                                            [step3_result['pairs'],\n",
    "                                             step3_result['hic'],\n",
    "                                             step3_result['mcool']], \n",
    "                                            my_auth)\n",
    "        print(a_set['accession'], 'part3 complete')\n",
    "    # if still running\n",
    "    elif step3_result['status'] == 'running':\n",
    "        print('part3 still running')\n",
    "        continue\n",
    "    # if run is not successful\n",
    "    else:\n",
    "        print(a_set['accession'], 'is missing Part3')\n",
    "        if add_wfr:\n",
    "            # RUN PART 3\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref}\n",
    "            if recipe_no in [0,2,4]:\n",
    "                inp_f['restriction_file'] = enz_ref\n",
    "            run_missing_wfr(step_settings(step3, organism, attributions), inp_f, a_set['accession'], my_auth, my_env)\n",
    "\n",
    "print(completed)\n",
    "print(completed_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3 4DNESH4UTRNL DpnII mouse 800  -  4DNEX4KRGMAQ is missing Part2 - Fails at runtaskawsem\n",
    "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-bam_4DNEX4KRGMAQ9b484528-5651-4d72-a271-a9b37a42ab05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "recipe_no = 1\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "action = False\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "\n",
    "\n",
    "set_url = '/search/?experiments_in_set.experiment_type=DNase+Hi-C&lab.display_title=Chuck+Murry%2C+UW&status=in+review+by+lab&status=pre-release&type=ExperimentSetReplicate'\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "\n",
    "ready_sets_1 = [i for i in all_sets if \"HiC_Pipeline_0.2.5\" in i.get('completed_processes', [])]\n",
    "print(len(ready_sets_1))\n",
    "ready_sets_2 = []\n",
    "for a_set in ready_sets_1:\n",
    "    if a_set.get('other_processed_files'):\n",
    "        print(a_set['accession'])\n",
    "        if move_title in [i['title'] for i in a_set['other_processed_files']]:\n",
    "            if a_set.get('processed_files'):\n",
    "                print('WARN' ,a_set['accession'], 'has items in processed files, skipping ')\n",
    "                continue\n",
    "            else:\n",
    "                ready_sets_2.append(a_set)\n",
    "print(len(ready_sets_2), 'items are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move other processed files to processed files field\n",
    "action = True\n",
    "def move_opc_to_pc(resp, move_title, con_key, action):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        if opc:\n",
    "            print('There are files in processed_files field, expected empty', resp['accession'])\n",
    "            return False\n",
    "        else:\n",
    "            print('it is possible that move already happened, no opc but pc', resp['accession'])\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action:\n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "print(len(ready_sets_2), 'experiment sets in scope')\n",
    "for a_set in ready_sets_2:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_auth, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_auth, action)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_auth, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_auth, action)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release processed files if not\n",
    "action = False\n",
    "print(len(ready_sets_2), 'experiment sets in scope')\n",
    "\n",
    "for a_set in ready_sets_1:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_auth, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    \n",
    "    set_pc = set_resp.get('processed_files')\n",
    "    if set_pc & action:\n",
    "        release_files(resp['uuid'], set_pc, con_key)\n",
    "    \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_auth, add_on='frame=raw')\n",
    "        exp_pc = exp_resp.get('processed_files')\n",
    "        if exp_pc & action:\n",
    "            release_files(exp['uuid'], exp_pc, con_key)\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
