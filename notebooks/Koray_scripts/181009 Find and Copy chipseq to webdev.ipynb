{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON https://data.4dnucleome.org \n",
      "\n",
      "dict_keys(['file_fastq', 'lab', 'individual_human', 'biosample_cell_culture', 'static_section', 'user', 'experiment_set_replicate', 'target', 'file_format', 'protocol', 'biosource', 'ontology', 'vendor', 'organism', 'award', 'ontology_term', 'antibody', 'experiment_seq', 'quality_metric_fastqc', 'biosample'])\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "### PLEASE COPY NOTEBOOKS TO YOUR FOLDERS TO PREVENT COMMIT CONFLICTS\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "import json\n",
    "\n",
    "# get key from keypairs.json\n",
    "my_env = 'data'\n",
    "my_key = get_key('koray_data')\n",
    "schema_name = get_schema_names(my_key) \n",
    "print('WORKING ON', my_key['server'], '\\n')\n",
    "\n",
    "##### COLLECT ITEMS TO Release #####\n",
    "# use either a starting item to fetch all linked items\n",
    "\n",
    "# Use a starting item to find linked ones\n",
    "# starting_items = ['46db06ad-b399-4cf4-9acc-07b3e25ef132']\n",
    "#add_items = get_query_or_linked(my_key, linked=starting_items)\n",
    "\n",
    "# or a search query\n",
    "#my_query = '/search/?q=GOLD&type=Item&limit=all'\n",
    "#add_items = get_query_or_linked(my_key, query=my_query)\n",
    "\n",
    "# if you want you can dump them to separate json files (will work as test insert)\n",
    "# dump_to_json(add_items, destination folder)\n",
    "\n",
    "# my_query = '/search/?biosample.biosource.individual.organism.name=mouse&biosample.biosource_summary=ES-E14&experiment_type=in%20situ%20Hi-C&type=ExperimentHiC'\n",
    "# store = get_query_or_linked(my_key, query=my_query)\n",
    "# print(store.keys())\n",
    "# print(len([i['uuid'] for key in store for i in store[key]]))\n",
    "# print()\n",
    "\n",
    "find_linked = ['b51eb447-e41e-4fe1-9004-cd47392eda46', '942e5220-825d-4379-b9b8-e4d7a5098130']\n",
    "store = get_query_or_linked(my_key, linked=find_linked, linked_frame='raw')\n",
    "print(store.keys())\n",
    "print(len([i['uuid'] for key in store for i in store[key]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "13 items exist on source\n",
      "user 986b362f-4eb6-4a9c-8173-3ab267307e3a can not post item\n",
      "user 7b8aa7bc-eee0-4bc4-9892-1c46bc4552c5 can not post item\n",
      "user 986b362f-4eb6-4a9c-8173-3ab267228139 can not post item\n",
      "user 7c6184f0-3198-41d2-bb71-e7af0a9a74f0 can not post item\n",
      "user 32c70fcf-f3af-4687-89e2-9bdd05cf460a can not post item\n",
      "user 900c5bf0-5b3a-4d7c-a6e6-7918faa19a77 can not post item\n",
      "user 83b5073a-069b-4162-9b30-6f42d5551e34 can not post item\n",
      "user b2ceeab8-b15b-4fdd-bcf7-49aaca674a63 can not post item\n",
      "user 986b362f-4eb6-4a9c-8173-3ab267111888 can not post item\n",
      "user e2324f87-0625-4bbc-803b-d47677aebe08 can not post item\n",
      "3 items transfered to target\n",
      "\n",
      "award\n",
      "6 items exist on source\n",
      "award a725c2ce-5be2-4933-bf56-f0b7b3f1c584 can not post item\n",
      "award b0b9c607-f8b4-4f02-93f4-9895b461334b can not post item\n",
      "award ae6c618f-7a8c-441e-a886-e30bbbe591da can not post item\n",
      "award 43fc2984-a074-49c4-a69f-c9d3f3eadeba can not post item\n",
      "2 items transfered to target\n",
      "\n",
      "lab\n",
      "8 items exist on source\n",
      "lab 6240db37-c902-4f2a-b8eb-44a3e6ccfe11 can not post item\n",
      "lab 828cd4fe-ebb0-4b36-a94a-d2e3a36cc989 can not post item\n",
      "lab 8a78f7cf-ba16-4de6-934b-845b34bc2816 can not post item\n",
      "lab 3c577664-affb-41c4-bf27-9e21c2fc1554 can not post item\n",
      "lab 83080563-722d-4f9e-a29a-c978d33f5ff1 can not post item\n",
      "3 items transfered to target\n",
      "\n",
      "static_section\n",
      "1 items exist on source\n",
      "static_section 621e8359-3885-40ce-965d-91894aa7b758 can not post item\n",
      "0 items transfered to target\n",
      "\n",
      "ontology\n",
      "2 items exist on source\n",
      "ontology 540026bc-8535-4448-903e-854af460b254 can not post item\n",
      "ontology 530006bc-8535-4448-903e-854af460b254 can not post item\n",
      "0 items transfered to target\n",
      "\n",
      "ontology_term\n",
      "10 items exist on source\n",
      "ontology_term 111189bc-8535-4448-903e-854af460a233 can not post item\n",
      "ontology_term 3a3aca22-7824-4179-ba02-9fdc68abcc2f can not post item\n",
      "ontology_term a27ad2c3-cd3b-46fe-b69b-9673eacdd9b0 can not post item\n",
      "ontology_term 111116bc-8535-4448-903e-854af460a233 can not post item\n",
      "ontology_term 111115bc-8535-4448-903e-854af460a233 can not post item\n",
      "ontology_term 111114bc-8535-4448-903e-854af460a233 can not post item\n",
      "ontology_term 111113bc-8535-4448-903e-854af460a233 can not post item\n",
      "ontology_term 111112bc-8535-4448-903e-854af460a233 can not post item\n",
      "ontology_term 111111bc-8535-4448-903e-854af460a233 can not post item\n",
      "1 items transfered to target\n",
      "\n",
      "organism\n",
      "1 items exist on source\n",
      "organism 7745b647-ff15-4ff3-9ced-b897d4e2983c can not post item\n",
      "0 items transfered to target\n",
      "\n",
      "file_format\n",
      "1 items exist on source\n",
      "file_format c13d06cf-218e-4f61-aaf0-91f226248b2c can not post item\n",
      "0 items transfered to target\n",
      "\n",
      "target\n",
      "1 items exist on source\n",
      "1 items transfered to target\n",
      "\n",
      "vendor\n",
      "2 items exist on source\n",
      "2 items transfered to target\n",
      "\n",
      "protocol\n",
      "2 items exist on source\n",
      "2 items transfered to target\n",
      "\n",
      "biosample_cell_culture\n",
      "2 items exist on source\n",
      "2 items transfered to target\n",
      "\n",
      "individual_human\n",
      "1 items exist on source\n",
      "1 items transfered to target\n",
      "\n",
      "biosource\n",
      "1 items exist on source\n",
      "1 items transfered to target\n",
      "\n",
      "antibody\n",
      "1 items exist on source\n",
      "1 items transfered to target\n",
      "\n",
      "biosample\n",
      "2 items exist on source\n",
      "2 items transfered to target\n",
      "\n",
      "quality_metric_fastqc\n",
      "8 items exist on source\n",
      "quality_metric_fastqc c311a759-b82d-4bd3-a0ce-602f5aa6175f can not post item\n",
      "quality_metric_fastqc a604b3bf-685b-4ff0-97ac-d890db318f63 can not post item\n",
      "6 items transfered to target\n",
      "\n",
      "file_fastq\n",
      "8 items exist on source\n",
      "file_fastq 38969bef-628a-41d6-bc74-c6b347c2e688 can not post item\n",
      "file_fastq 26e6a9a9-defe-46e4-bdc6-7af4675bd17a can not post item\n",
      "6 items transfered to target\n",
      "\n",
      "experiment_seq\n",
      "4 items exist on source\n",
      "4 items transfered to target\n",
      "\n",
      "experiment_set_replicate\n",
      "2 items exist on source\n",
      "2 items transfered to target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### This part should only run once!\n",
    "\n",
    "transfer_env = 'fourfront-webdev'\n",
    "transfer_key = ff_utils.get_authentication_with_server({}, ff_env=transfer_env)\n",
    "# reverse lookup dictionary for schema names\n",
    "\n",
    "rev_schema_name = {}\n",
    "for key, name in schema_name.items():\n",
    "    rev_schema_name[name] = schema_name[key]\n",
    "\n",
    "my_types = [i for i in ORDER if i in store.keys()]\n",
    "\n",
    "second_round_items = {}\n",
    "\n",
    "# Round I - only put the required - skip if exists already\n",
    "for a_type in my_types:\n",
    "    print(a_type)\n",
    "    obj_type = rev_schema_name[a_type]\n",
    "    # find required field\n",
    "    schema_info = ff_utils.get_metadata('/profiles/{}.json'.format(a_type), key=transfer_key)\n",
    "    req_fields = schema_info['required']\n",
    "    ids = schema_info['identifyingProperties']\n",
    "    first_fields = list(set(req_fields+ids))\n",
    "    remove_existing_items = []\n",
    "    counter=0\n",
    "    print(len(store[a_type]), 'items exist on source')\n",
    "    for an_item in store[a_type]:\n",
    "        counter += 1\n",
    "        #print(counter, an_item['uuid'])\n",
    "        # does the item exist\n",
    "        exists = False\n",
    "        try:\n",
    "            # TODO check with all identifiers\n",
    "            existing = ff_utils.get_metadata(an_item['uuid'], key=transfer_key)\n",
    "            exists = True\n",
    "        except:\n",
    "            exists = False\n",
    "        # skip the items that exists\n",
    "        if exists and existing:\n",
    "            remove_existing_items.append(an_item['uuid'])\n",
    "            print(\"{} {} can not post item\".format(obj_type, an_item['uuid']))\n",
    "            continue\n",
    " \n",
    "        post_first = {key:value for (key,value) in an_item.items() if key in first_fields}\n",
    "        ff_utils.post_metadata(post_first, obj_type, key = transfer_key)\n",
    "   \n",
    "    second_round_items[a_type] = [i for i in store[a_type] if i['uuid'] not in remove_existing_items]\n",
    "    print(len(second_round_items[a_type]), 'items transfered to target')\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round II - patch the rest of the metadata\n",
    "for a_type in my_types:\n",
    "    obj_type = rev_schema_name[a_type]\n",
    "    if not second_round_items[a_type]:\n",
    "        continue \n",
    "    for an_item in second_round_items[a_type]:\n",
    "        counter += 1\n",
    "        if a_type == 'file_fastq':\n",
    "            if 'extra_files' in an_item:\n",
    "                del an_item['extra_files']\n",
    "        ff_utils.patch_metadata(an_item, obj_id = an_item['uuid'], key = transfer_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attachment copied\n",
      "attachment copied\n"
     ]
    }
   ],
   "source": [
    "# Round III - move attachments\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "#source_addresses\n",
    "source_health = ff_utils.get_metadata('/health', key = my_key)\n",
    "source_raw = source_health['file_upload_bucket'] \n",
    "source_pf = source_health['processed_file_bucket'] \n",
    "source_att = source_health['blob_bucket']\n",
    "\n",
    "#target_addresses\n",
    "target_health = ff_utils.get_metadata('/health', key = transfer_key)\n",
    "target_raw = target_health['file_upload_bucket'] \n",
    "target_pf = target_health['processed_file_bucket'] \n",
    "target_att = target_health['blob_bucket'] \n",
    "\n",
    "# Round III - move attachments\n",
    "for a_type in my_types:\n",
    "    obj_type = rev_schema_name[a_type]\n",
    "    for an_item in second_round_items[a_type]:\n",
    "        if 'attachment' in an_item.keys():\n",
    "            at_key = an_item['attachment']['blob_id']\n",
    "            copy_source = {'Bucket': source_att, 'Key': at_key}\n",
    "            try:\n",
    "                s3.meta.client.copy(copy_source, target_att, at_key)\n",
    "            except:\n",
    "                print('Can not find attachment on source', an_item['uuid'])\n",
    "                continue\n",
    "            print('attachment copied')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file copied\n",
      "file copied\n",
      "file copied\n",
      "file copied\n",
      "file copied\n",
      "file copied\n"
     ]
    }
   ],
   "source": [
    "# Round IV - move files\n",
    "for a_type in my_types:\n",
    "    if a_type in ['file_processed']:\n",
    "        source_file_bucket = source_pf\n",
    "        target_file_bucket = target_pf\n",
    "    elif a_type in ['file_reference', 'file_fastq', 'file_microscopy', 'file_fasta', 'file_calibration']:\n",
    "        source_file_bucket = source_raw\n",
    "        target_file_bucket = target_raw\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    for an_item in second_round_items[a_type]:\n",
    "        # accumulate all keys from a file object to be uploaded\n",
    "        files_to_upload = []\n",
    "        file_resp = ff_utils.get_metadata(an_item['uuid'], key = my_key)\n",
    "        # add extra file keys\n",
    "        if file_resp.get('extra_files', []):\n",
    "            for an_extra_file in file_resp['extra_files']:\n",
    "                files_to_upload.append(an_extra_file['upload_key'])\n",
    "        # add main file key\n",
    "        files_to_upload.append(file_resp['upload_key'])\n",
    "        \n",
    "        for file_key in files_to_upload:\n",
    "            copy_source = {'Bucket': source_file_bucket, 'Key': file_key}\n",
    "            try:\n",
    "                s3.meta.client.copy(copy_source, target_file_bucket, file_key)\n",
    "            except:\n",
    "                print('Can not find file on source', file_key)\n",
    "                continue\n",
    "            print('file copied')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
