{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script looks at all files\n",
    "### 1) Checks deleted files for md5 related fields and clears them\n",
    "###                         for qc metric and changes status of qc metric object to deleted\n",
    "###                         clears the qc metric field\n",
    "###                         for workflows and deletes all of them\n",
    "### 2) Checks other files for workflows and deleted old workflows\n",
    "###                                     and deleted problematic ones (status or rev)\n",
    "### takes around 20 min\n",
    "\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "#env = 'data'\n",
    "my_key = get_key('koray_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at 2018-07-25 17:27:01.433136\n",
      "Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\n",
      "60 files in the system\n"
     ]
    }
   ],
   "source": [
    "print('started at', datetime.utcnow())\n",
    "delete_workflows = input(\"Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\")\n",
    "\n",
    "# what kind of files should be searched for worflow run inputs, use url compatible naming\n",
    "\n",
    "# accepted workflows\n",
    "# workflow name, accepted revision numbers (0 if none), accetable run time (hours)\n",
    "workflow_details = [\n",
    "                    ['md5', ['0'], 1],\n",
    "                    ['fastqc-0-11-4-1', ['0', '1'], 12],    \n",
    "                    ['bwa-mem 0.2.5', ['0'],50],\n",
    "                    ['pairsqc-single 0.2.5', ['0'],12],\n",
    "                    ['hi-c-processing-bam 0.2.5', ['0'],50],  \n",
    "                    ['hi-c-processing-pairs 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nore 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nonorm 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nore-nonorm 0.2.5', ['0'],100],\n",
    "                    ['repliseq-parta 0.2.5', ['0'],100],\n",
    "                   ]\n",
    "workflow_names = [i[0] for i in workflow_details]\n",
    "\n",
    "deleted_wfr_no = 0\n",
    "files_with_deleted_wfr = 0\n",
    "\n",
    "run_what = 'Custom'   # Proc or Fastq\n",
    "date_since = '2018-07-19'\n",
    "add_deleted = False\n",
    "\n",
    "file_url = \"\"\n",
    "if run_what == 'Proc':\n",
    "    file_url = '/search/?type=FileProcessed&limit=all&q=date_created%3A%3E%3D' + date_since\n",
    "    print(file_url)\n",
    "    files = ff_utils.search_metadata(file_url ,key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url ,key=my_key))\n",
    "    \n",
    "elif run_what == 'Fastq':\n",
    "    file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D' + date_since\n",
    "    files = ff_utils.search_metadata(file_url, key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url, key=my_key))\n",
    "    # grab these guys, because they accumulate losts of md5 runs\n",
    "    for a_test in ['4DNFIO67AFHV','4DNFIXH5OV2H', '4DNFI5RQBUKE']:\n",
    "        files.insert(0,ff_utils.get_metadata(a_test, key=my_key))\n",
    "\n",
    "elif run_what == 'Custom':\n",
    "    file_url = '/search/?lab.display_title=Xavier%20Darzacq%2C%20BERKELEY&limit=all&type=FileProcessed'\n",
    "    files = ff_utils.search_metadata(file_url , key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url ,key=my_key))\n",
    "\n",
    "    \n",
    "print(len(files), 'files in the system')\n",
    "deleted_wfrs = []\n",
    "counter = 0\n",
    "del_md5 = 0\n",
    "del_qc = 0\n",
    "deleted_output = 0\n",
    "for a_file in files:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(counter, files_with_deleted_wfr)\n",
    "    raw_file = a_file\n",
    "    deleted_wf = False\n",
    "    wfr_report = []\n",
    "    wfrs = raw_file.get('workflow_run_inputs')\n",
    "    \n",
    "    # Delete wfrs if file is deleted\n",
    "    if raw_file['status'] == 'deleted':\n",
    "        if delete_workflows.lower() in ['y', 'yes']:\n",
    "            # clean deleted files of md5 and qc metrics\n",
    "            for a_field in ['content_md5sum', 'md5sum']:  \n",
    "                if raw_file.get(a_field):\n",
    "                    ff_utils.delete_field(raw_file, a_field, key=my_key)\n",
    "                    del_md5 += 1\n",
    "            if raw_file.get('quality_metric'):\n",
    "                qc_uuid = raw_file['quality_metric']['uuid']\n",
    "                ff_utils.delete_field(raw_file, 'quality_metric', key=my_key)\n",
    "                # delete quality metrics object\n",
    "                patch_data = {'status': \"deleted\"}\n",
    "                ff_utils.patch_metadata(patch_data, obj_id=qc_uuid , key=my_key)\n",
    "                del_qc += 1\n",
    "        # delete all workflows for deleted files\n",
    "        if not wfrs:\n",
    "            continue\n",
    "        else:\n",
    "            wfr_report = get_wfr_report(wfrs, my_key)\n",
    "            for wfr_to_del in wfr_report:\n",
    "                if wfr_to_del['status'] != 'deleted':\n",
    "                    if wfr_to_del['wfr_name'] not in workflow_names:\n",
    "                        print('Unlisted Workflow', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                    deleted_wf = True\n",
    "                    deleted_wfr_no += 1\n",
    "                    \n",
    "                    ####################################################\n",
    "                    ## TEMPORARY PIECE##################################\n",
    "                    if wfr_to_del['status'] == 'released to project':\n",
    "                        print('saved from deletion', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                        continue\n",
    "                    if wfr_to_del['status'] == 'released':\n",
    "                        print('delete released!!!!!', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                        continue  \n",
    "                    #####################################################\n",
    "                    \n",
    "                    print(wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                    if delete_workflows.lower() in ['y', 'yes']:\n",
    "                        patch_data = {'description': \"This workflow run is deleted\", 'status': \"deleted\"}\n",
    "                        deleted_wfrs.append(wfr_to_del['wfr_uuid'])\n",
    "                        ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,key=my_key)\n",
    "                        # delete output files of the deleted workflow run\n",
    "                        if wfr_to_del['outputs']:\n",
    "                            for out_file in wfr_to_del['outputs']:\n",
    "                                deleted_output += 1\n",
    "                                ff_utils.patch_metadata({'status': \"deleted\"}, obj_id=out_file ,key=my_key)\n",
    "       \n",
    "                \n",
    "    else:\n",
    "        # get a report on all workflow_runs\n",
    "        if not wfrs:\n",
    "            continue\n",
    "        else:\n",
    "            wfr_report = get_wfr_report(wfrs, my_key)\n",
    "            # printTable(wfr_report, ['wfr_name', 'run_time', 'wfr_rev', 'run_time', 'wfr_status'])\n",
    "            \n",
    "            # check if any unlisted wfr in report\n",
    "            my_wfr_names = [i['wfr_name'] for i in wfr_report]\n",
    "            unlisted = [x for x in my_wfr_names if x not in workflow_names]\n",
    "            # report the unlisted ones\n",
    "            #if unlisted:\n",
    "                #print('Unlisted Workflow', unlisted, 'skipped in', raw_file['accession'])\n",
    "                    \n",
    "            for wf_name,accepted_rev,accepted_run_time in workflow_details:\n",
    "                #for each type of worklow make a list of old ones, and patch status and description\n",
    "                sub_wfrs = [i for i in wfr_report if i['wfr_name'] == wf_name]\n",
    "                if sub_wfrs:\n",
    "                    active_wfr = sub_wfrs[-1]\n",
    "                    old_wfrs = sub_wfrs [:-1]\n",
    "                    # check the status of the most recent workflow\n",
    "                    if active_wfr['wfr_status'] != 'complete':\n",
    "                        if active_wfr['wfr_status'] in ['running', 'started'] and active_wfr['run_time'] < accepted_run_time:\n",
    "                            print(wf_name,'still running for', a_file['accession'])\n",
    "                        else:\n",
    "                            old_wfrs.append(active_wfr)\n",
    "                    elif active_wfr['wfr_rev'] not in accepted_rev:\n",
    "                        old_wfrs.append(active_wfr)\n",
    "                    if old_wfrs:\n",
    "                        for wfr_to_del in old_wfrs:\n",
    "                            if wfr_to_del['status'] != 'deleted':\n",
    "                                deleted_wf = True\n",
    "                                deleted_wfr_no += 1 \n",
    "                                \n",
    "                                ####################################################\n",
    "                                ## TEMPORARY PIECE\n",
    "                                if wfr_to_del['status'] == 'released to project':\n",
    "                                    print('saved from deletion',wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                    continue\n",
    "                                if wfr_to_del['status'] == 'released':\n",
    "                                    print('delete released????',wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                    continue\n",
    "                                ####################################################\n",
    "\n",
    "                                print(wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                \n",
    "                                if delete_workflows.lower() in ['y', 'yes']:\n",
    "                                    patch_data = {'description': \"This workflow run is deleted\", 'status': \"deleted\"}\n",
    "                                    deleted_wfrs.append(wfr_to_del['wfr_uuid'])\n",
    "                                    \n",
    "                                    ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,key=my_key)\n",
    "                                    # delete output files of the deleted workflow run\n",
    "                                    if wfr_to_del['outputs']:\n",
    "                                        for out_file in wfr_to_del['outputs']:\n",
    "                                            deleted_output += 1\n",
    "                                            ff_utils.patch_metadata({'status': \"deleted\"}, obj_id=out_file ,key=my_key)\n",
    "    if deleted_wf:\n",
    "        files_with_deleted_wfr += 1\n",
    "        \n",
    "\n",
    "\n",
    "if delete_workflows.lower() in ['y', 'yes']:\n",
    "    print(str(deleted_wfr_no),\"workflowruns from\", str(files_with_deleted_wfr), \"files deleted\")\n",
    "else:\n",
    "    print(str(deleted_wfr_no),\"workflowruns from\", str(files_with_deleted_wfr), \"files need to be deleted\")\n",
    "\n",
    "print(len(deleted_wfrs))\n",
    "print(del_md5, 'md5 fields deleted')\n",
    "print(del_qc, 'qc metrics deleted')\n",
    "print(deleted_output, 'deleted output files')\n",
    "print('finished at', datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
