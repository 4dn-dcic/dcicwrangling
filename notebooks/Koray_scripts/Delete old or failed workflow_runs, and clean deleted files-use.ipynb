{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script looks at all files\n",
    "### 1) Checks deleted files for md5 related fields and clears them\n",
    "###                         for qc metric and changes status of qc metric object to deleted\n",
    "###                         clears the qc metric field\n",
    "###                         for workflows and deletes all of them\n",
    "### 2) Checks other files for workflows and deleted old workflows\n",
    "###                                     and deleted problematic ones (status or rev)\n",
    "### takes around 20 min\n",
    "\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "#env = 'data'\n",
    "my_key = get_key('koray_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at 2018-11-30 05:26:20.869257\n",
      "2428 files in the system\n"
     ]
    }
   ],
   "source": [
    "print('started at', datetime.utcnow())\n",
    "\n",
    "# what kind of files should be searched for worflow run inputs, use url compatible naming\n",
    "\n",
    "# accepted workflows\n",
    "# workflow name, accepted revision numbers (0 if none), accetable run time (hours)\n",
    "workflow_details = [\n",
    "                    ['md5', ['0'], 12],\n",
    "                    ['fastqc-0-11-4-1', ['0', '1'], 24],    \n",
    "                    ['bwa-mem 0.2.5', ['0'],50],\n",
    "                    ['pairsqc-single 0.2.5', ['0'],12],\n",
    "                    ['hi-c-processing-bam 0.2.5', ['0'],50],  \n",
    "                    ['hi-c-processing-pairs 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nore 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nonorm 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nore-nonorm 0.2.5', ['0'],100],\n",
    "                    ['repliseq-parta 0.2.5', ['0'],100],\n",
    "                    ['bedGraphToBigWig',['0'], 12]\n",
    "                   ]\n",
    "workflow_names = [i[0] for i in workflow_details]\n",
    "\n",
    "deleted_wfr_no = 0\n",
    "files_with_deleted_wfr = 0\n",
    "\n",
    "run_what = 'Custom_no_date'   # Proc or Fastq\n",
    "date_since = '2018-10-01'\n",
    "add_deleted = False\n",
    "\n",
    "file_url = \"\"\n",
    "if run_what == 'Proc':\n",
    "    file_url = '/search/?type=FileProcessed&limit=all&q=date_created%3A%3E%3D' + date_since\n",
    "    print(file_url)\n",
    "    files = ff_utils.search_metadata(file_url ,key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url ,key=my_key))\n",
    "    \n",
    "elif run_what == 'Fastq':\n",
    "    file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D' + date_since\n",
    "    files = ff_utils.search_metadata(file_url, key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url, key=my_key))\n",
    "    # grab these guys, because they accumulate losts of md5 runs\n",
    "    for a_test in ['4DNFIO67AFHV','4DNFIXH5OV2H', '4DNFI5RQBUKE']:\n",
    "        files.insert(0,ff_utils.get_metadata(a_test, key=my_key))\n",
    "\n",
    "elif run_what == 'Custom':\n",
    "    file_url = '/search/?type=FileProcessed&limit=all&status=deleted&q=date_created%3A%3E%3D' + date_since\n",
    "    files = ff_utils.search_metadata(file_url , key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url ,key=my_key))\n",
    "        \n",
    "elif run_what == 'Custom_no_date':\n",
    "    file_url = '/search/?award.project=External&experiments.biosample.biosource.individual.organism.name=chicken&lab.display_title=Job+Dekker%2C+UMMS&type=FileFastq'\n",
    "    files = ff_utils.search_metadata(file_url, key=my_key)    \n",
    "    \n",
    "    \n",
    "print(len(files), 'files in the system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2428 files in the system\n",
      "Do you want to delete old workflowruns (if not, only report will be displayed (y/n))y\n",
      "100 0\n",
      "200 0\n",
      "300 0\n",
      "400 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7590e2b74496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mwfr_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wfr_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;31m# printTable(wfr_report, ['wfr_name', 'run_time', 'wfr_rev', 'run_time', 'wfr_status'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# check if any unlisted wfr in report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/dcicwrangling/functions/notebook_functions.py\u001b[0m in \u001b[0;36mget_wfr_report\u001b[0;34m(wfrs, con_key)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;34m\"\"\"For a given workflow_run item, grabs details, uuid, run_status, wfr name, date, and run time\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mwfr_uuid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfr_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mwfr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwfr_uuid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mwfr_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfr_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(obj_id, key, ff_env, check_queue, add_on)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mget_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprocess_add_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# check the queues if check_queue is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthorized_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_response_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mauthorized_request\u001b[0;34m(url, auth, ff_env, verb, retry_fxn, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mretry_fxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_request_with_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# use the given retry function. MUST TAKE THESE PARAMS!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mretry_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_verb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/dcicutils/ff_utils.py\u001b[0m in \u001b[0;36mstandard_request_with_retries\u001b[0;34m(request_fxn, url, auth, verb, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_timeouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_fxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mretry\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    510\u001b[0m         }\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/wrangling/lib/python3.5/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_cert_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcertfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: OpenSSL with enabled SNI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     warnings.warn(\n",
      "\u001b[0;32m/usr/local/Cellar/python35/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    375\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                          _context=self)\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     def wrap_bio(self, incoming, outgoing, server_side=False,\n",
      "\u001b[0;32m/usr/local/Cellar/python35/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[1;32m    750\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python35/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python35/3.5.2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(files), 'files in the system')\n",
    "delete_workflows = input(\"Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\")\n",
    "counter = 0\n",
    "del_md5 = 0\n",
    "del_qc = 0\n",
    "deleted_output = 0\n",
    "deleted_wfrs = []\n",
    "for a_file in files:\n",
    "    counter += 1  \n",
    "    if counter % 100 == 0:\n",
    "        print(counter, files_with_deleted_wfr)\n",
    "    raw_file = a_file\n",
    "    deleted_wf = False\n",
    "    wfr_report = []\n",
    "    wfrs = raw_file.get('workflow_run_inputs')\n",
    "    \n",
    "    # look for md5s\n",
    "    # to do add more single input runs\n",
    "    if not wfrs:\n",
    "        wfrs_url = '/search/?type=WorkflowRun&type=WorkflowRun&workflow.title=md5&input_files.value.accession='+ a_file['accession']\n",
    "        wfrs = ff_utils.search_metadata(wfrs_url , key=my_key)\n",
    "#         if len(wfrs)==0:\n",
    "#             continue\n",
    "#             #print('file has no wfr', a_file['accession'])\n",
    "            \n",
    "    # Delete wfrs if file is deleted\n",
    "    if raw_file['status'] == 'deleted':\n",
    "        if delete_workflows.lower() in ['y', 'yes']:\n",
    "            # clean deleted files of md5 and qc metrics\n",
    "            for a_field in ['content_md5sum', 'md5sum']:  \n",
    "                if raw_file.get(a_field):\n",
    "                    ff_utils.delete_field(raw_file, a_field, key=my_key)\n",
    "                    del_md5 += 1\n",
    "            if raw_file.get('quality_metric'):\n",
    "                qc_uuid = raw_file['quality_metric']['uuid']\n",
    "                ff_utils.delete_field(raw_file, 'quality_metric', key=my_key)\n",
    "                # delete quality metrics object\n",
    "                patch_data = {'status': \"deleted\"}\n",
    "                ff_utils.patch_metadata(patch_data, obj_id=qc_uuid , key=my_key)\n",
    "                del_qc += 1\n",
    "                \n",
    "        # delete all workflows for deleted files\n",
    "        if not wfrs:\n",
    "            continue\n",
    "        else:\n",
    "            wfr_report = get_wfr_report(wfrs, my_key)\n",
    "            for wfr_to_del in wfr_report:\n",
    "                if wfr_to_del['status'] != 'deleted':\n",
    "                    if wfr_to_del['wfr_name'] not in workflow_names:\n",
    "                        print('Unlisted Workflow', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                    deleted_wf = True\n",
    "                    deleted_wfr_no += 1\n",
    "                    \n",
    "                    ####################################################\n",
    "                    ## TEMPORARY PIECE##################################\n",
    "                    if wfr_to_del['status'] == 'released to project':\n",
    "                        print('saved from deletion', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                        continue\n",
    "                    if wfr_to_del['status'] == 'released':\n",
    "                        print('delete released!!!!!', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                        continue  \n",
    "                    #####################################################\n",
    "                    \n",
    "                    print(wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                    if delete_workflows.lower() in ['y', 'yes']:\n",
    "                        patch_data = {'description': \"This workflow run is deleted\", 'status': \"deleted\"}\n",
    "                        deleted_wfrs.append(wfr_to_del['wfr_uuid'])\n",
    "                        ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,key=my_key)\n",
    "                        # delete output files of the deleted workflow run\n",
    "                        if wfr_to_del['outputs']:\n",
    "                            for out_file in wfr_to_del['outputs']:\n",
    "                                deleted_output += 1\n",
    "                                ff_utils.patch_metadata({'status': \"deleted\"}, obj_id=out_file ,key=my_key)\n",
    "       \n",
    "                \n",
    "    else:\n",
    "        # get a report on all workflow_runs\n",
    "        if not wfrs:\n",
    "            continue\n",
    "        else:\n",
    "            wfr_report = get_wfr_report(wfrs, my_key)\n",
    "            # printTable(wfr_report, ['wfr_name', 'run_time', 'wfr_rev', 'run_time', 'wfr_status'])\n",
    "            # check if any unlisted wfr in report\n",
    "            my_wfr_names = [i['wfr_name'] for i in wfr_report]\n",
    "            unlisted = [x for x in my_wfr_names if x not in workflow_names]\n",
    "            # report the unlisted ones\n",
    "            #if unlisted:\n",
    "                #print('Unlisted Workflow', unlisted, 'skipped in', raw_file['accession'])\n",
    "                    \n",
    "            for wf_name,accepted_rev,accepted_run_time in workflow_details:\n",
    "                #for each type of worklow make a list of old ones, and patch status and description\n",
    "                sub_wfrs = [i for i in wfr_report if i['wfr_name'] == wf_name]\n",
    "                if sub_wfrs:\n",
    "                    active_wfr = sub_wfrs[-1]\n",
    "                    old_wfrs = sub_wfrs [:-1]\n",
    "                    # check the status of the most recent workflow\n",
    "                    if active_wfr['wfr_status'] != 'complete':\n",
    "                        if active_wfr['wfr_status'] in ['running', 'started'] and active_wfr['run_time'] < accepted_run_time:\n",
    "                            print(wf_name,'still running for', a_file['accession'])\n",
    "                        else:\n",
    "                            old_wfrs.append(active_wfr)\n",
    "                    elif active_wfr['wfr_rev'] not in accepted_rev:\n",
    "                        old_wfrs.append(active_wfr)\n",
    "                    if old_wfrs:\n",
    "                        for wfr_to_del in old_wfrs:\n",
    "                            if wfr_to_del['status'] != 'deleted':\n",
    "                                deleted_wf = True\n",
    "                                deleted_wfr_no += 1 \n",
    "                                \n",
    "                                ####################################################\n",
    "                                ## TEMPORARY PIECE\n",
    "                                if wfr_to_del['status'] == 'released to project':\n",
    "                                    print('saved from deletion',wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                    continue\n",
    "                                if wfr_to_del['status'] == 'released':\n",
    "                                    print('delete released????',wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                    continue\n",
    "                                ####################################################\n",
    "\n",
    "                                print(wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                \n",
    "                                if delete_workflows.lower() in ['y', 'yes']:\n",
    "                                    patch_data = {'description': \"This workflow run is deleted\", 'status': \"deleted\"}\n",
    "                                    deleted_wfrs.append(wfr_to_del['wfr_uuid'])\n",
    "                                    \n",
    "                                    ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,key=my_key)\n",
    "                                    # delete output files of the deleted workflow run\n",
    "                                    if wfr_to_del['outputs']:\n",
    "                                        for out_file in wfr_to_del['outputs']:\n",
    "                                            deleted_output += 1\n",
    "                                            ff_utils.patch_metadata({'status': \"deleted\"}, obj_id=out_file ,key=my_key)\n",
    "    if deleted_wf:\n",
    "        files_with_deleted_wfr += 1\n",
    "\n",
    "\n",
    "\n",
    "if delete_workflows.lower() in ['y', 'yes']:\n",
    "    print(str(deleted_wfr_no),\"workflowruns from\", str(files_with_deleted_wfr), \"files deleted\")\n",
    "else:\n",
    "    print(str(deleted_wfr_no),\"workflowruns from\", str(files_with_deleted_wfr), \"files need to be deleted\")\n",
    "\n",
    "print(len(deleted_wfrs))\n",
    "print(del_md5, 'md5 fields deleted')\n",
    "print(del_qc, 'qc metrics deleted')\n",
    "print(deleted_output, 'deleted output files')\n",
    "print('finished at', datetime.utcnow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing trigger and accumulating runs\n",
    "\n",
    "There are many runs where we are running out of option to utilize the exisiting tool sets\n",
    "for this cases I would like to implement a new checker, which will be used for testing \n",
    "existing frame works and also make sure that newly implemented tools are working in synch with\n",
    "them.\n",
    "\n",
    "This are the minor details that we should pay attention to while building complex tools that wrap many components\n",
    "that are also dynamic. Even a simple version menagement can become problematic when different package management tools \n",
    "are used in combination.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
