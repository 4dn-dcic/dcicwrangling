{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='/Users/luisa/bedtomultivec/Data/wgEncodeAwgSegmentationChromhmmGm12878.bed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x112a5e668>\n"
     ]
    }
   ],
   "source": [
    "new_list = []\n",
    "states_list = []\n",
    "x = 0\n",
    "with open(filepath, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter = '\\n')\n",
    "    print(reader)\n",
    "    \n",
    "    for line in reader:\n",
    "        x = x + 1\n",
    "        if x != 1: #Remove header from file\n",
    "            for i in line:\n",
    "                new_line_list = []\n",
    "                new_line = i.split('\\t')\n",
    "                new_line_list.append(new_line[0])\n",
    "                new_line_list.append(new_line[1])\n",
    "                new_line_list.append(new_line[2])\n",
    "                new_line_list.append(new_line[3])\n",
    "                new_line_list.append(new_line[4])\n",
    "                new_line_list.append(new_line[5])\n",
    "                new_line_list.append(new_line[6])\n",
    "                new_line_list.append(new_line[7])\n",
    "                new_line_list.append(new_line[8])\n",
    "                states_list.append(new_line[3])\n",
    "                new_list.append(new_line_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for item in states_list:\n",
    "    if item not in states:\n",
    "        states.append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FaireW', 'Low', 'Pol2', \"Gen3'\", 'Elon', 'Quies', 'Ctcf', 'EnhW', 'EnhWF', 'ElonW', 'PromF', 'TssF', 'Tss', 'H4K20', 'DnaseU', \"Gen5'\", 'ReprW', 'Repr', 'CtcfO', 'DnaseD', 'ReprD', 'Art', 'PromP', 'EnhF', 'Enh']\n"
     ]
    }
   ],
   "source": [
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaireW\n"
     ]
    }
   ],
   "source": [
    "print(states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('row_infos_wgEncode_chr1.txt', 'w', newline = '') as outfile:\n",
    "    for i in states:\n",
    "        outfile.write(i)\n",
    "        outfile.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redo file without header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E001_15_coreMarks_dense_wo_header.bed', 'w', newline = '\\n') as outfile:\n",
    "    file = csv.writer(outfile, delimiter= '\\t')\n",
    "    for i in new_list: \n",
    "        file.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 = ['colorx'] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx', 'colorx']\n"
     ]
    }
   ],
   "source": [
    "print(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = []\n",
    "new_line = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(states)):\n",
    "    new_line.append(states[x])\n",
    "    new_line.append(col2[x])\n",
    "    new_file.append(new_line)\n",
    "    new_line = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['FaireW', 'colorx'], ['Low', 'colorx'], ['Pol2', 'colorx'], [\"Gen3'\", 'colorx'], ['Elon', 'colorx'], ['Quies', 'colorx'], ['Ctcf', 'colorx'], ['EnhW', 'colorx'], ['EnhWF', 'colorx'], ['ElonW', 'colorx'], ['PromF', 'colorx'], ['TssF', 'colorx'], ['Tss', 'colorx'], ['H4K20', 'colorx'], ['DnaseU', 'colorx'], [\"Gen5'\", 'colorx'], ['ReprW', 'colorx'], ['Repr', 'colorx'], ['CtcfO', 'colorx'], ['DnaseD', 'colorx'], ['ReprD', 'colorx'], ['Art', 'colorx'], ['PromP', 'colorx'], ['EnhF', 'colorx'], ['Enh', 'colorx']]\n"
     ]
    }
   ],
   "source": [
    "print(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0] = '\\t'.join(col2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\to\tl\to\tr\tx\n"
     ]
    }
   ],
   "source": [
    "print(states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for ele in new_file:\n",
    "    new_file[x] = '\\t'.join(ele)\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FaireW\\tcolorx', 'Low\\tcolorx', 'Pol2\\tcolorx', \"Gen3'\\tcolorx\", 'Elon\\tcolorx', 'Quies\\tcolorx', 'Ctcf\\tcolorx', 'EnhW\\tcolorx', 'EnhWF\\tcolorx', 'ElonW\\tcolorx', 'PromF\\tcolorx', 'TssF\\tcolorx', 'Tss\\tcolorx', 'H4K20\\tcolorx', 'DnaseU\\tcolorx', \"Gen5'\\tcolorx\", 'ReprW\\tcolorx', 'Repr\\tcolorx', 'CtcfO\\tcolorx', 'DnaseD\\tcolorx', 'ReprD\\tcolorx', 'Art\\tcolorx', 'PromP\\tcolorx', 'EnhF\\tcolorx', 'Enh\\tcolorx']\n"
     ]
    }
   ],
   "source": [
    "print(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('row_infos_wgEncode_2col.txt', 'w', newline = '\\n') as outfile:\n",
    "    file = csv.writer(outfile, delimiter='\\t')\n",
    "    for i in new_file:\n",
    "        file.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "my_dic = {states[x]:col2[x] for x in range(0, len(states))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FaireW': 'colorx', 'Low': 'colorx', 'Pol2': 'colorx', \"Gen3'\": 'colorx', 'Elon': 'colorx', 'Quies': 'colorx', 'Ctcf': 'colorx', 'EnhW': 'colorx', 'EnhWF': 'colorx', 'ElonW': 'colorx', 'PromF': 'colorx', 'TssF': 'colorx', 'Tss': 'colorx', 'H4K20': 'colorx', 'DnaseU': 'colorx', \"Gen5'\": 'colorx', 'ReprW': 'colorx', 'Repr': 'colorx', 'CtcfO': 'colorx', 'DnaseD': 'colorx', 'ReprD': 'colorx', 'Art': 'colorx', 'PromP': 'colorx', 'EnhF': 'colorx', 'Enh': 'colorx'}\n"
     ]
    }
   ],
   "source": [
    "print(my_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FaireW': 'colorx', 'Low': 'colorx', 'Pol2': 'colorx', \"Gen3'\": 'colorx', 'Elon': 'colorx', 'Quies': 'colorx', 'Ctcf': 'colorx', 'EnhW': 'colorx', 'EnhWF': 'colorx', 'ElonW': 'colorx', 'PromF': 'colorx', 'TssF': 'colorx', 'Tss': 'colorx', 'H4K20': 'colorx', 'DnaseU': 'colorx', \"Gen5'\": 'colorx', 'ReprW': 'colorx', 'Repr': 'colorx', 'CtcfO': 'colorx', 'DnaseD': 'colorx', 'ReprD': 'colorx', 'Art': 'colorx', 'PromP': 'colorx', 'EnhF': 'colorx', 'Enh': 'colorx'}\n"
     ]
    }
   ],
   "source": [
    "print(my_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'generator' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-53fc426a400f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'row_infos_wgEncode_2col.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'generator' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('row_infos_wgEncode_2col.txt', 'w', newline = '') as outfile:\n",
    "    outfile.write(json.dumps(my_dic[key] for key in my_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
